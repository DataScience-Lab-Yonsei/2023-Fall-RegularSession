{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "c4cb21b1-5f3a-4dee-c6b1-683251b80f62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오기\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "28ff34a7-ea69-4adc-ada0-8ed16bc7c171"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2.7196145057678223\n",
            "1: 2.284837007522583\n",
            "2: 2.15211820602417\n",
            "3: 2.147310495376587\n",
            "4: 2.0967254638671875\n",
            "5: 2.149860143661499\n",
            "6: 2.0819973945617676\n",
            "7: 2.1099071502685547\n",
            "8: 2.0962393283843994\n",
            "9: 2.098416328430176\n",
            "10: 2.10199236869812\n",
            "11: 2.070236921310425\n",
            "12: 2.047194719314575\n",
            "13: 2.0633225440979004\n",
            "14: 2.047189235687256\n",
            "15: 2.0333993434906006\n",
            "16: 2.0334208011627197\n",
            "17: 2.0230162143707275\n",
            "18: 1.9932204484939575\n",
            "19: 1.9907764196395874\n",
            "20: 1.9742019176483154\n",
            "21: 1.9829375743865967\n",
            "22: 1.9801832437515259\n",
            "23: 1.9742459058761597\n",
            "24: 1.986448884010315\n",
            "25: 1.9328001737594604\n",
            "26: 1.9459468126296997\n",
            "27: 1.916403889656067\n",
            "28: 1.9224090576171875\n",
            "29: 1.9260005950927734\n",
            "30: 1.9006342887878418\n",
            "31: 1.9036284685134888\n",
            "32: 1.8902479410171509\n",
            "33: 1.9224823713302612\n",
            "34: 1.8789132833480835\n",
            "35: 1.9032633304595947\n",
            "36: 1.8926374912261963\n",
            "37: 1.8730021715164185\n",
            "38: 1.875799536705017\n",
            "39: 1.8661211729049683\n",
            "40: 1.840732216835022\n",
            "41: 1.8586337566375732\n",
            "42: 1.863901972770691\n",
            "43: 1.8689433336257935\n",
            "44: 1.8384051322937012\n",
            "45: 1.7678885459899902\n",
            "46: 1.8341485261917114\n",
            "47: 1.8071928024291992\n",
            "48: 1.8414509296417236\n",
            "49: 1.7924660444259644\n",
            "50: 1.8280889987945557\n",
            "51: 1.7536182403564453\n",
            "52: 1.8230866193771362\n",
            "53: 1.8032478094100952\n",
            "54: 1.7864984273910522\n",
            "55: 1.77510666847229\n",
            "56: 1.7665650844573975\n",
            "57: 1.7973161935806274\n",
            "58: 1.7884678840637207\n",
            "59: 1.784791350364685\n",
            "60: 1.7597599029541016\n",
            "61: 1.745511770248413\n",
            "62: 1.7363702058792114\n",
            "63: 1.7838208675384521\n",
            "64: 1.7346076965332031\n",
            "65: 1.7295184135437012\n",
            "66: 1.7464444637298584\n",
            "67: 1.750063419342041\n",
            "68: 1.7489114999771118\n",
            "69: 1.7389672994613647\n",
            "70: 1.697604775428772\n",
            "71: 1.658491611480713\n",
            "72: 1.7496771812438965\n",
            "73: 1.6930323839187622\n",
            "74: 1.7070232629776\n",
            "75: 1.6926876306533813\n",
            "76: 1.6835224628448486\n",
            "77: 1.7145049571990967\n",
            "78: 1.7058570384979248\n",
            "79: 1.7193142175674438\n",
            "80: 1.730015754699707\n",
            "81: 1.698754072189331\n",
            "82: 1.6934800148010254\n",
            "83: 1.6467533111572266\n",
            "84: 1.7191418409347534\n",
            "85: 1.6701778173446655\n",
            "86: 1.677971601486206\n",
            "87: 1.6541907787322998\n",
            "88: 1.6938787698745728\n",
            "89: 1.64963698387146\n",
            "90: 1.6590608358383179\n",
            "91: 1.6773957014083862\n",
            "92: 1.6604268550872803\n",
            "93: 1.6364185810089111\n",
            "94: 1.680082082748413\n",
            "95: 1.6213101148605347\n",
            "96: 1.645481824874878\n",
            "97: 1.6344467401504517\n",
            "98: 1.662914752960205\n",
            "99: 1.6260833740234375\n",
            "100: 1.610176920890808\n",
            "input:   tensor([[3, 2, 5, 4, 4, 5, 3, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 3, 5, 3, 5, 4, 3]], device='cuda:0')\n",
            "incorrects: 7\n",
            "101: 1.6101298332214355\n",
            "102: 1.614903450012207\n",
            "103: 1.6351321935653687\n",
            "104: 1.5731992721557617\n",
            "105: 1.599648118019104\n",
            "106: 1.6021360158920288\n",
            "107: 1.6231449842453003\n",
            "108: 1.5921554565429688\n",
            "109: 1.6455762386322021\n",
            "110: 1.5785294771194458\n",
            "111: 1.6176105737686157\n",
            "112: 1.6126712560653687\n",
            "113: 1.6223753690719604\n",
            "114: 1.5840660333633423\n",
            "115: 1.5695807933807373\n",
            "116: 1.594844102859497\n",
            "117: 1.5932539701461792\n",
            "118: 1.5810867547988892\n",
            "119: 1.5578629970550537\n",
            "120: 1.5747551918029785\n",
            "121: 1.5885872840881348\n",
            "122: 1.5654082298278809\n",
            "123: 1.5761178731918335\n",
            "124: 1.5691897869110107\n",
            "125: 1.5839972496032715\n",
            "126: 1.5617270469665527\n",
            "127: 1.529090166091919\n",
            "128: 1.5808172225952148\n",
            "129: 1.5565595626831055\n",
            "130: 1.5116032361984253\n",
            "131: 1.5367242097854614\n",
            "132: 1.5140247344970703\n",
            "133: 1.4908742904663086\n",
            "134: 1.5106773376464844\n",
            "135: 1.528929591178894\n",
            "136: 1.5213302373886108\n",
            "137: 1.5281453132629395\n",
            "138: 1.501159429550171\n",
            "139: 1.5437990427017212\n",
            "140: 1.520605444908142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  14%|█▍        | 143/1000 [00:10<01:00, 14.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141: 1.5288606882095337\n",
            "142: 1.5209015607833862\n",
            "143: 1.505415916442871\n",
            "144: 1.4561697244644165\n",
            "145: 1.4986673593521118\n",
            "146: 1.45909583568573\n",
            "147: 1.5112956762313843\n",
            "148: 1.4633703231811523\n",
            "149: 1.4910372495651245\n",
            "150: 1.4954378604888916\n",
            "151: 1.4372719526290894\n",
            "152: 1.4554929733276367\n",
            "153: 1.4624873399734497\n",
            "154: 1.4488707780838013\n",
            "155: 1.4531646966934204\n",
            "156: 1.4654322862625122\n",
            "157: 1.4674087762832642\n",
            "158: 1.472261905670166\n",
            "159: 1.4595696926116943\n",
            "160: 1.4696125984191895\n",
            "161: 1.44108247756958\n",
            "162: 1.4641079902648926\n",
            "163: 1.4450774192810059\n",
            "164: 1.4595260620117188\n",
            "165: 1.4700955152511597\n",
            "166: 1.451647162437439\n",
            "167: 1.4227265119552612\n",
            "168: 1.4423176050186157\n",
            "169: 1.4113271236419678\n",
            "170: 1.4474937915802002\n",
            "171: 1.4112871885299683\n",
            "172: 1.4351924657821655\n",
            "173: 1.3865132331848145\n",
            "174: 1.405417799949646\n",
            "175: 1.3534640073776245\n",
            "176: 1.367796540260315\n",
            "177: 1.4156488180160522\n",
            "178: 1.3797411918640137\n",
            "179: 1.3862048387527466\n",
            "180: 1.3958663940429688\n",
            "181: 1.4196858406066895\n",
            "182: 1.3976317644119263\n",
            "183: 1.3921388387680054\n",
            "184: 1.4501795768737793\n",
            "185: 1.3925504684448242\n",
            "186: 1.4497504234313965\n",
            "187: 1.3763842582702637\n",
            "188: 1.3923323154449463\n",
            "189: 1.336977481842041\n",
            "190: 1.3626148700714111\n",
            "191: 1.3551380634307861\n",
            "192: 1.3455443382263184\n",
            "193: 1.3945980072021484\n",
            "194: 1.3734878301620483\n",
            "195: 1.3272243738174438\n",
            "196: 1.3429921865463257\n",
            "197: 1.3521578311920166\n",
            "198: 1.313633680343628\n",
            "199: 1.3329261541366577\n",
            "200: 1.3249759674072266\n",
            "input:   tensor([[5, 3, 3, 3, 5, 2, 3, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 3, 5, 3, 4, 3, 2, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "201: 1.285481572151184\n",
            "202: 1.2876324653625488\n",
            "203: 1.3544803857803345\n",
            "204: 1.3139897584915161\n",
            "205: 1.3122533559799194\n",
            "206: 1.337026596069336\n",
            "207: 1.3287532329559326\n",
            "208: 1.3054351806640625\n",
            "209: 1.3238571882247925\n",
            "210: 1.2850627899169922\n",
            "211: 1.3257298469543457\n",
            "212: 1.2776970863342285\n",
            "213: 1.2827932834625244\n",
            "214: 1.286909580230713\n",
            "215: 1.3399101495742798\n",
            "216: 1.2687716484069824\n",
            "217: 1.2944731712341309\n",
            "218: 1.2211763858795166\n",
            "219: 1.2695701122283936\n",
            "220: 1.2378833293914795\n",
            "221: 1.2712376117706299\n",
            "222: 1.256296992301941\n",
            "223: 1.2784899473190308\n",
            "224: 1.2642210721969604\n",
            "225: 1.2859593629837036\n",
            "226: 1.2563743591308594\n",
            "227: 1.2640246152877808\n",
            "228: 1.2356964349746704\n",
            "229: 1.2647274732589722\n",
            "230: 1.2359182834625244\n",
            "231: 1.2181055545806885\n",
            "232: 1.2641645669937134\n",
            "233: 1.2477309703826904\n",
            "234: 1.20600163936615\n",
            "235: 1.2500206232070923\n",
            "236: 1.2281917333602905\n",
            "237: 1.2416740655899048\n",
            "238: 1.217316746711731\n",
            "239: 1.2004305124282837\n",
            "240: 1.1695778369903564\n",
            "241: 1.2069222927093506\n",
            "242: 1.188524842262268\n",
            "243: 1.1296473741531372\n",
            "244: 1.192347526550293\n",
            "245: 1.1829948425292969\n",
            "246: 1.2030256986618042\n",
            "247: 1.1954598426818848\n",
            "248: 1.1558648347854614\n",
            "249: 1.1538344621658325\n",
            "250: 1.1278834342956543\n",
            "251: 1.1613730192184448\n",
            "252: 1.163506031036377\n",
            "253: 1.2030649185180664\n",
            "254: 1.1639034748077393\n",
            "255: 1.1474041938781738\n",
            "256: 1.1206200122833252\n",
            "257: 1.1457985639572144\n",
            "258: 1.1374925374984741\n",
            "259: 1.1077075004577637\n",
            "260: 1.1309926509857178\n",
            "261: 1.1393100023269653\n",
            "262: 1.1036758422851562\n",
            "263: 1.1650010347366333\n",
            "264: 1.1716115474700928\n",
            "265: 1.1456749439239502\n",
            "266: 1.1214158535003662\n",
            "267: 1.1194567680358887\n",
            "268: 1.0960332155227661\n",
            "269: 1.1152358055114746\n",
            "270: 1.0967588424682617\n",
            "271: 1.1458059549331665\n",
            "272: 1.0922751426696777\n",
            "273: 1.1060587167739868\n",
            "274: 1.0750702619552612\n",
            "275: 1.09920072555542\n",
            "276: 1.100433588027954\n",
            "277: 1.1598690748214722\n",
            "278: 1.104637861251831\n",
            "279: 1.1655981540679932\n",
            "280: 1.1011439561843872\n",
            "281: 1.130117654800415\n",
            "282: 1.082952857017517\n",
            "283: 1.0882922410964966\n",
            "284: 1.0941952466964722\n",
            "285: 1.0611621141433716\n",
            "286: 1.1178828477859497\n",
            "287: 1.0596754550933838\n",
            "288: 1.0422191619873047\n",
            "289: 1.12173330783844\n",
            "290: 1.030547857284546\n",
            "291: 1.0522620677947998\n",
            "292: 1.0756170749664307\n",
            "293: 1.0536134243011475\n",
            "294: 1.0228711366653442\n",
            "295: 1.022217035293579\n",
            "296: 1.0581505298614502\n",
            "297: 1.0003682374954224\n",
            "298: 1.0216419696807861\n",
            "299: 1.004125714302063\n",
            "300: 1.0019252300262451\n",
            "input:   tensor([[3, 2, 3, 5, 5, 2, 3, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 2, 3, 5, 3, 4, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "301: 1.0385397672653198\n",
            "302: 0.9853765368461609\n",
            "303: 0.9987713694572449\n",
            "304: 0.9809694290161133\n",
            "305: 0.9719866514205933\n",
            "306: 1.0133609771728516\n",
            "307: 0.9772154092788696\n",
            "308: 0.9705229997634888\n",
            "309: 1.0420671701431274\n",
            "310: 0.9786117672920227\n",
            "311: 1.0333818197250366\n",
            "312: 0.9498918652534485\n",
            "313: 0.9974234700202942\n",
            "314: 0.9874771237373352\n",
            "315: 0.9344419240951538\n",
            "316: 0.9981685280799866\n",
            "317: 0.9050111174583435\n",
            "318: 0.9460314512252808\n",
            "319: 0.9719163179397583\n",
            "320: 0.8999882936477661\n",
            "321: 0.9501190185546875\n",
            "322: 0.9406324028968811\n",
            "323: 0.9474138021469116\n",
            "324: 0.9446657299995422\n",
            "325: 0.9727209806442261\n",
            "326: 0.9379559755325317\n",
            "327: 0.9337329864501953\n",
            "328: 0.9496400356292725\n",
            "329: 0.9322828054428101\n",
            "330: 0.8869767785072327\n",
            "331: 0.9046906232833862\n",
            "332: 0.902510404586792\n",
            "333: 0.9244949817657471\n",
            "334: 0.9301975965499878\n",
            "335: 0.8681876063346863\n",
            "336: 0.8922069072723389\n",
            "337: 0.8845188021659851\n",
            "338: 0.9003556370735168\n",
            "339: 0.9149081707000732\n",
            "340: 0.8800739049911499\n",
            "341: 0.8903829455375671\n",
            "342: 0.921716570854187\n",
            "343: 0.8887568116188049\n",
            "344: 0.9007329344749451\n",
            "345: 0.8806284070014954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  35%|███▌      | 351/1000 [00:20<00:35, 18.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "346: 0.8528451323509216\n",
            "347: 0.8183538913726807\n",
            "348: 0.9028303623199463\n",
            "349: 0.8341947197914124\n",
            "350: 0.8934822082519531\n",
            "351: 0.8699567317962646\n",
            "352: 0.8651015758514404\n",
            "353: 0.8736851215362549\n",
            "354: 0.8287045359611511\n",
            "355: 0.8762385249137878\n",
            "356: 0.8497115969657898\n",
            "357: 0.9022618532180786\n",
            "358: 0.8974716663360596\n",
            "359: 0.9242638349533081\n",
            "360: 0.9049992561340332\n",
            "361: 0.9600681066513062\n",
            "362: 0.9470364451408386\n",
            "363: 0.8991883993148804\n",
            "364: 0.9256433844566345\n",
            "365: 0.8903313875198364\n",
            "366: 0.8511799573898315\n",
            "367: 0.8590328693389893\n",
            "368: 0.9029624462127686\n",
            "369: 0.9416267275810242\n",
            "370: 0.8302051424980164\n",
            "371: 0.8672866821289062\n",
            "372: 0.9034883379936218\n",
            "373: 0.8598299026489258\n",
            "374: 0.8510544896125793\n",
            "375: 0.8718454837799072\n",
            "376: 0.861213743686676\n",
            "377: 0.7928309440612793\n",
            "378: 0.8292728066444397\n",
            "379: 0.841499924659729\n",
            "380: 0.8327513337135315\n",
            "381: 0.7830634713172913\n",
            "382: 0.7733782529830933\n",
            "383: 0.8576073050498962\n",
            "384: 0.7993869185447693\n",
            "385: 0.8125122785568237\n",
            "386: 0.8507531881332397\n",
            "387: 0.7654100656509399\n",
            "388: 0.8338898420333862\n",
            "389: 0.8072220087051392\n",
            "390: 0.8056128621101379\n",
            "391: 0.8294602632522583\n",
            "392: 0.7830569744110107\n",
            "393: 0.7511493563652039\n",
            "394: 0.7714634537696838\n",
            "395: 0.8349294066429138\n",
            "396: 0.8042672276496887\n",
            "397: 0.7689870595932007\n",
            "398: 0.7996523976325989\n",
            "399: 0.7794187664985657\n",
            "400: 0.7585986256599426\n",
            "input:   tensor([[2, 2, 5, 4, 2, 2, 2, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 4, 2, 2, 2, 2, 5, 4]], device='cuda:0')\n",
            "incorrects: 5\n",
            "401: 0.7620314359664917\n",
            "402: 0.7547965049743652\n",
            "403: 0.7847124338150024\n",
            "404: 0.7355021238327026\n",
            "405: 0.7747281789779663\n",
            "406: 0.7486477494239807\n",
            "407: 0.7488016486167908\n",
            "408: 0.725608229637146\n",
            "409: 0.7712554335594177\n",
            "410: 0.70343416929245\n",
            "411: 0.7339879274368286\n",
            "412: 0.7227774858474731\n",
            "413: 0.7271945476531982\n",
            "414: 0.746744692325592\n",
            "415: 0.7137681245803833\n",
            "416: 0.7064989805221558\n",
            "417: 0.7433838248252869\n",
            "418: 0.6872178316116333\n",
            "419: 0.6997765302658081\n",
            "420: 0.6969612836837769\n",
            "421: 0.7331435084342957\n",
            "422: 0.6894856095314026\n",
            "423: 0.7364832758903503\n",
            "424: 0.7064782381057739\n",
            "425: 0.6987234354019165\n",
            "426: 0.712458074092865\n",
            "427: 0.7039505839347839\n",
            "428: 0.6989691257476807\n",
            "429: 0.6809658408164978\n",
            "430: 0.6901395320892334\n",
            "431: 0.7016264796257019\n",
            "432: 0.6822922825813293\n",
            "433: 0.6742249727249146\n",
            "434: 0.6786092519760132\n",
            "435: 0.6917246580123901\n",
            "436: 0.6648287773132324\n",
            "437: 0.6536253690719604\n",
            "438: 0.6882267594337463\n",
            "439: 0.6783448457717896\n",
            "440: 0.6360402703285217\n",
            "441: 0.6512582302093506\n",
            "442: 0.7020175457000732\n",
            "443: 0.6871352791786194\n",
            "444: 0.6535531878471375\n",
            "445: 0.7178632616996765\n",
            "446: 0.6643330454826355\n",
            "447: 0.715789258480072\n",
            "448: 0.6649670600891113\n",
            "449: 0.7528440952301025\n",
            "450: 0.6877326965332031\n",
            "451: 0.6842586994171143\n",
            "452: 0.6760430335998535\n",
            "453: 0.6755014061927795\n",
            "454: 0.6691596508026123\n",
            "455: 0.7416716814041138\n",
            "456: 0.6593801975250244\n",
            "457: 0.7567924857139587\n",
            "458: 0.6772595047950745\n",
            "459: 0.7247763276100159\n",
            "460: 0.6957204937934875\n",
            "461: 0.7255809903144836\n",
            "462: 0.6995640397071838\n",
            "463: 0.6922832727432251\n",
            "464: 0.6930536031723022\n",
            "465: 0.6799083352088928\n",
            "466: 0.6605010032653809\n",
            "467: 0.6918743848800659\n",
            "468: 0.6680058836936951\n",
            "469: 0.671396791934967\n",
            "470: 0.7154136896133423\n",
            "471: 0.6521763801574707\n",
            "472: 0.6360357999801636\n",
            "473: 0.6653053164482117\n",
            "474: 0.6400754451751709\n",
            "475: 0.6768852472305298\n",
            "476: 0.6588117480278015\n",
            "477: 0.6335472464561462\n",
            "478: 0.6519622206687927\n",
            "479: 0.6290387511253357\n",
            "480: 0.6684215068817139\n",
            "481: 0.6100753545761108\n",
            "482: 0.6387684941291809\n",
            "483: 0.6353183388710022\n",
            "484: 0.5969610810279846\n",
            "485: 0.6317246556282043\n",
            "486: 0.6152952313423157\n",
            "487: 0.6292199492454529\n",
            "488: 0.6118264198303223\n",
            "489: 0.5916345715522766\n",
            "490: 0.6200636625289917\n",
            "491: 0.6044420599937439\n",
            "492: 0.6121225357055664\n",
            "493: 0.6087201833724976\n",
            "494: 0.5802938342094421\n",
            "495: 0.5761348605155945\n",
            "496: 0.6174871921539307\n",
            "497: 0.6180640459060669\n",
            "498: 0.6086621880531311\n",
            "499: 0.6057175993919373\n",
            "500: 0.5805460214614868\n",
            "input:   tensor([[2, 3, 3, 2, 4, 2, 3, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 3, 2, 5, 3, 4, 2, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "501: 0.603734016418457\n",
            "502: 0.5844122767448425\n",
            "503: 0.6056253910064697\n",
            "504: 0.6047593355178833\n",
            "505: 0.6005200147628784\n",
            "506: 0.5796096324920654\n",
            "507: 0.6141217947006226\n",
            "508: 0.5867310762405396\n",
            "509: 0.5811938047409058\n",
            "510: 0.5580178499221802\n",
            "511: 0.5853055715560913\n",
            "512: 0.5829669237136841\n",
            "513: 0.5745025873184204\n",
            "514: 0.5793905258178711\n",
            "515: 0.5979449152946472\n",
            "516: 0.5854832530021667\n",
            "517: 0.634030818939209\n",
            "518: 0.5850576758384705\n",
            "519: 0.6566614508628845\n",
            "520: 0.5853623747825623\n",
            "521: 0.617091178894043\n",
            "522: 0.600171685218811\n",
            "523: 0.6279202103614807\n",
            "524: 0.5927712917327881\n",
            "525: 0.6349663138389587\n",
            "526: 0.5630495548248291\n",
            "527: 0.6029595732688904\n",
            "528: 0.5856173634529114\n",
            "529: 0.6058676242828369\n",
            "530: 0.5668902397155762\n",
            "531: 0.6283074021339417\n",
            "532: 0.558381199836731\n",
            "533: 0.621521532535553\n",
            "534: 0.5655050873756409\n",
            "535: 0.6336765289306641\n",
            "536: 0.5781072974205017\n",
            "537: 0.5914496779441833\n",
            "538: 0.5961394906044006\n",
            "539: 0.6520593762397766\n",
            "540: 0.5764648914337158\n",
            "541: 0.6927140355110168\n",
            "542: 0.6228166222572327\n",
            "543: 0.642994225025177\n",
            "544: 0.6318897604942322\n",
            "545: 0.6790561676025391\n",
            "546: 0.5421775579452515\n",
            "547: 0.6175965070724487\n",
            "548: 0.6614603996276855\n",
            "549: 0.5947984457015991\n",
            "550: 0.6053687930107117\n",
            "551: 0.6270229816436768\n",
            "552: 0.5827178955078125\n",
            "553: 0.6141262054443359\n",
            "554: 0.614672839641571\n",
            "555: 0.5710188150405884\n",
            "556: 0.5776875019073486\n",
            "557: 0.5855100750923157\n",
            "558: 0.5656600594520569\n",
            "559: 0.5754770636558533\n",
            "560: 0.5915115475654602\n",
            "561: 0.562480628490448\n",
            "562: 0.5512377619743347\n",
            "563: 0.5595564842224121\n",
            "564: 0.5806550979614258\n",
            "565: 0.5709826946258545\n",
            "566: 0.5612391233444214\n",
            "567: 0.5419331789016724\n",
            "568: 0.6002638339996338\n",
            "569: 0.5940414667129517\n",
            "570: 0.5504832863807678\n",
            "571: 0.5808854103088379\n",
            "572: 0.5499005913734436\n",
            "573: 0.5434521436691284\n",
            "574: 0.5333716869354248\n",
            "575: 0.5604274272918701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  58%|█████▊    | 578/1000 [00:30<00:20, 20.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "576: 0.5562976002693176\n",
            "577: 0.5637539625167847\n",
            "578: 0.5308570861816406\n",
            "579: 0.5877580642700195\n",
            "580: 0.5619627833366394\n",
            "581: 0.5200582146644592\n",
            "582: 0.5524949431419373\n",
            "583: 0.5551047325134277\n",
            "584: 0.544207751750946\n",
            "585: 0.5270990133285522\n",
            "586: 0.5486636757850647\n",
            "587: 0.5428414344787598\n",
            "588: 0.5285195708274841\n",
            "589: 0.527692973613739\n",
            "590: 0.5373461246490479\n",
            "591: 0.5385679602622986\n",
            "592: 0.5309513807296753\n",
            "593: 0.5382928252220154\n",
            "594: 0.547231137752533\n",
            "595: 0.5126953125\n",
            "596: 0.5374917387962341\n",
            "597: 0.5291644334793091\n",
            "598: 0.5258398056030273\n",
            "599: 0.5142088532447815\n",
            "600: 0.5338625311851501\n",
            "input:   tensor([[5, 4, 5, 5, 2, 4, 5, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 5, 4, 3, 5, 4, 5, 2]], device='cuda:0')\n",
            "incorrects: 5\n",
            "601: 0.5370497107505798\n",
            "602: 0.5244868993759155\n",
            "603: 0.5186803340911865\n",
            "604: 0.508577823638916\n",
            "605: 0.5324913859367371\n",
            "606: 0.4968973994255066\n",
            "607: 0.5166393518447876\n",
            "608: 0.5355000495910645\n",
            "609: 0.5252708196640015\n",
            "610: 0.5147669911384583\n",
            "611: 0.524306058883667\n",
            "612: 0.5070359110832214\n",
            "613: 0.5354838967323303\n",
            "614: 0.5015408992767334\n",
            "615: 0.501979649066925\n",
            "616: 0.5498045682907104\n",
            "617: 0.5144930481910706\n",
            "618: 0.4994050860404968\n",
            "619: 0.5147981643676758\n",
            "620: 0.5070712566375732\n",
            "621: 0.49259278178215027\n",
            "622: 0.5154324173927307\n",
            "623: 0.5098323822021484\n",
            "624: 0.5147740840911865\n",
            "625: 0.5198572874069214\n",
            "626: 0.5112966299057007\n",
            "627: 0.493146151304245\n",
            "628: 0.49633851647377014\n",
            "629: 0.5023665428161621\n",
            "630: 0.5001473426818848\n",
            "631: 0.4847165048122406\n",
            "632: 0.5077664256095886\n",
            "633: 0.5011894702911377\n",
            "634: 0.5271821618080139\n",
            "635: 0.510546863079071\n",
            "636: 0.4985368251800537\n",
            "637: 0.5215820074081421\n",
            "638: 0.5006226897239685\n",
            "639: 0.5225142240524292\n",
            "640: 0.4973641037940979\n",
            "641: 0.48919761180877686\n",
            "642: 0.5200144052505493\n",
            "643: 0.48851221799850464\n",
            "644: 0.5153792500495911\n",
            "645: 0.5118539333343506\n",
            "646: 0.4771086573600769\n",
            "647: 0.48846200108528137\n",
            "648: 0.5632068514823914\n",
            "649: 0.5169373154640198\n",
            "650: 0.5265804529190063\n",
            "651: 0.5305509567260742\n",
            "652: 0.516089677810669\n",
            "653: 0.504801332950592\n",
            "654: 0.5008183717727661\n",
            "655: 0.4960930645465851\n",
            "656: 0.5039817690849304\n",
            "657: 0.5093801021575928\n",
            "658: 0.5009917616844177\n",
            "659: 0.48086485266685486\n",
            "660: 0.5017983317375183\n",
            "661: 0.48510733246803284\n",
            "662: 0.5185319185256958\n",
            "663: 0.49677136540412903\n",
            "664: 0.5041294097900391\n",
            "665: 0.48192134499549866\n",
            "666: 0.5444510579109192\n",
            "667: 0.5105597972869873\n",
            "668: 0.4995613098144531\n",
            "669: 0.4789596199989319\n",
            "670: 0.4909805953502655\n",
            "671: 0.5205967426300049\n",
            "672: 0.48955148458480835\n",
            "673: 0.4976174533367157\n",
            "674: 0.467720091342926\n",
            "675: 0.4868053197860718\n",
            "676: 0.5063631534576416\n",
            "677: 0.5173415541648865\n",
            "678: 0.49035948514938354\n",
            "679: 0.46962398290634155\n",
            "680: 0.551211953163147\n",
            "681: 0.4875863194465637\n",
            "682: 0.49945685267448425\n",
            "683: 0.5115444660186768\n",
            "684: 0.5507908463478088\n",
            "685: 0.529273271560669\n",
            "686: 0.5305604934692383\n",
            "687: 0.5362933874130249\n",
            "688: 0.5360649228096008\n",
            "689: 0.519348680973053\n",
            "690: 0.5602145195007324\n",
            "691: 0.5183899998664856\n",
            "692: 0.5992886424064636\n",
            "693: 0.4939926564693451\n",
            "694: 0.5635528564453125\n",
            "695: 0.5129650235176086\n",
            "696: 0.5073428153991699\n",
            "697: 0.5341421961784363\n",
            "698: 0.5839452147483826\n",
            "699: 0.5237156748771667\n",
            "700: 0.5092230439186096\n",
            "input:   tensor([[3, 4, 3, 4, 2, 2, 3, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 2, 2, 4, 3, 3, 3, 4]], device='cuda:0')\n",
            "incorrects: 5\n",
            "701: 0.5814309120178223\n",
            "702: 0.5293887853622437\n",
            "703: 0.5039640069007874\n",
            "704: 0.5166225433349609\n",
            "705: 0.4909971356391907\n",
            "706: 0.5457016825675964\n",
            "707: 0.4969128966331482\n",
            "708: 0.45883825421333313\n",
            "709: 0.48241832852363586\n",
            "710: 0.46082279086112976\n",
            "711: 0.4978422522544861\n",
            "712: 0.5073451995849609\n",
            "713: 0.4651544988155365\n",
            "714: 0.49807804822921753\n",
            "715: 0.5000695586204529\n",
            "716: 0.4519686996936798\n",
            "717: 0.4903099238872528\n",
            "718: 0.45767244696617126\n",
            "719: 0.49397963285446167\n",
            "720: 0.4946404695510864\n",
            "721: 0.49851489067077637\n",
            "722: 0.5100762248039246\n",
            "723: 0.4845293462276459\n",
            "724: 0.4615873396396637\n",
            "725: 0.4615488052368164\n",
            "726: 0.4604977071285248\n",
            "727: 0.47754737734794617\n",
            "728: 0.4625891447067261\n",
            "729: 0.46576523780822754\n",
            "730: 0.45185840129852295\n",
            "731: 0.47725218534469604\n",
            "732: 0.47007277607917786\n",
            "733: 0.46967193484306335\n",
            "734: 0.45302826166152954\n",
            "735: 0.44111132621765137\n",
            "736: 0.4690753221511841\n",
            "737: 0.47650328278541565\n",
            "738: 0.46272778511047363\n",
            "739: 0.4757708013057709\n",
            "740: 0.46329984068870544\n",
            "741: 0.4346793293952942\n",
            "742: 0.44812995195388794\n",
            "743: 0.4463479518890381\n",
            "744: 0.473410427570343\n",
            "745: 0.4706602394580841\n",
            "746: 0.4422213137149811\n",
            "747: 0.4489176273345947\n",
            "748: 0.450461745262146\n",
            "749: 0.46992483735084534\n",
            "750: 0.4853396415710449\n",
            "751: 0.46787428855895996\n",
            "752: 0.43446996808052063\n",
            "753: 0.4502246677875519\n",
            "754: 0.44513022899627686\n",
            "755: 0.4632994532585144\n",
            "756: 0.452175110578537\n",
            "757: 0.44659334421157837\n",
            "758: 0.4344690442085266\n",
            "759: 0.46111729741096497\n",
            "760: 0.48571234941482544\n",
            "761: 0.43701010942459106\n",
            "762: 0.4415569007396698\n",
            "763: 0.4578535258769989\n",
            "764: 0.44805288314819336\n",
            "765: 0.455211341381073\n",
            "766: 0.46081745624542236\n",
            "767: 0.44818195700645447\n",
            "768: 0.4432898461818695\n",
            "769: 0.4934122562408447\n",
            "770: 0.4753568470478058\n",
            "771: 0.4804500639438629\n",
            "772: 0.4548793137073517\n",
            "773: 0.4493422508239746\n",
            "774: 0.46811455488204956\n",
            "775: 0.47650331258773804\n",
            "776: 0.45530807971954346\n",
            "777: 0.4631926715373993\n",
            "778: 0.45939114689826965\n",
            "779: 0.4660399258136749\n",
            "780: 0.4942290186882019\n",
            "781: 0.4562169909477234\n",
            "782: 0.46663686633110046\n",
            "783: 0.4393203854560852\n",
            "784: 0.45154279470443726\n",
            "785: 0.4588067829608917\n",
            "786: 0.44162240624427795\n",
            "787: 0.4367801249027252\n",
            "788: 0.40671080350875854\n",
            "789: 0.447907030582428\n",
            "790: 0.4649508595466614\n",
            "791: 0.447559118270874\n",
            "792: 0.4650932550430298\n",
            "793: 0.451231449842453\n",
            "794: 0.44411763548851013\n",
            "795: 0.4457460343837738\n",
            "796: 0.4423503875732422\n",
            "797: 0.46038079261779785\n",
            "798: 0.4355151653289795\n",
            "799: 0.4495246410369873\n",
            "800: 0.4403100311756134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 805/1000 [00:41<00:09, 20.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input:   tensor([[4, 3, 2, 3, 3, 3, 3, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 2, 3, 3, 4, 3, 2, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "801: 0.3985729515552521\n",
            "802: 0.44731712341308594\n",
            "803: 0.45375990867614746\n",
            "804: 0.4487120807170868\n",
            "805: 0.4801049828529358\n",
            "806: 0.4315362274646759\n",
            "807: 0.43499043583869934\n",
            "808: 0.4882591962814331\n",
            "809: 0.4848472774028778\n",
            "810: 0.5357328057289124\n",
            "811: 0.48897626996040344\n",
            "812: 0.5590566992759705\n",
            "813: 0.47789520025253296\n",
            "814: 0.5115637183189392\n",
            "815: 0.5622873306274414\n",
            "816: 0.5216833353042603\n",
            "817: 0.47438275814056396\n",
            "818: 0.49852705001831055\n",
            "819: 0.5240309238433838\n",
            "820: 0.5389979481697083\n",
            "821: 0.4651407301425934\n",
            "822: 0.4875665307044983\n",
            "823: 0.5122313499450684\n",
            "824: 0.48469099402427673\n",
            "825: 0.4869903028011322\n",
            "826: 0.5012809038162231\n",
            "827: 0.4606001377105713\n",
            "828: 0.49124082922935486\n",
            "829: 0.4412807822227478\n",
            "830: 0.48682868480682373\n",
            "831: 0.4718887507915497\n",
            "832: 0.45571276545524597\n",
            "833: 0.4839143455028534\n",
            "834: 0.4618336856365204\n",
            "835: 0.4736320674419403\n",
            "836: 0.49661770462989807\n",
            "837: 0.4248833656311035\n",
            "838: 0.4478635787963867\n",
            "839: 0.4574739933013916\n",
            "840: 0.45085951685905457\n",
            "841: 0.4271239936351776\n",
            "842: 0.46740567684173584\n",
            "843: 0.47673967480659485\n",
            "844: 0.43195831775665283\n",
            "845: 0.4504920542240143\n",
            "846: 0.47834721207618713\n",
            "847: 0.4311075806617737\n",
            "848: 0.4111481308937073\n",
            "849: 0.4621739685535431\n",
            "850: 0.455961674451828\n",
            "851: 0.4346781075000763\n",
            "852: 0.4332551658153534\n",
            "853: 0.46024462580680847\n",
            "854: 0.439909964799881\n",
            "855: 0.4547562301158905\n",
            "856: 0.4588913917541504\n",
            "857: 0.4523553252220154\n",
            "858: 0.44560080766677856\n",
            "859: 0.43045368790626526\n",
            "860: 0.42581549286842346\n",
            "861: 0.40663519501686096\n",
            "862: 0.43675658106803894\n",
            "863: 0.4329002797603607\n",
            "864: 0.41866549849510193\n",
            "865: 0.42623788118362427\n",
            "866: 0.42662912607192993\n",
            "867: 0.4038080871105194\n",
            "868: 0.42194533348083496\n",
            "869: 0.42582881450653076\n",
            "870: 0.4185675084590912\n",
            "871: 0.43335819244384766\n",
            "872: 0.4154571294784546\n",
            "873: 0.4646989107131958\n",
            "874: 0.4056900441646576\n",
            "875: 0.4136715531349182\n",
            "876: 0.40967869758605957\n",
            "877: 0.40676096081733704\n",
            "878: 0.43181583285331726\n",
            "879: 0.4353836178779602\n",
            "880: 0.40521320700645447\n",
            "881: 0.43389445543289185\n",
            "882: 0.4213160276412964\n",
            "883: 0.41500601172447205\n",
            "884: 0.43726399540901184\n",
            "885: 0.4657694399356842\n",
            "886: 0.42531049251556396\n",
            "887: 0.43741798400878906\n",
            "888: 0.45862647891044617\n",
            "889: 0.45147478580474854\n",
            "890: 0.40642842650413513\n",
            "891: 0.45856717228889465\n",
            "892: 0.44980770349502563\n",
            "893: 0.3971561789512634\n",
            "894: 0.4425801634788513\n",
            "895: 0.4229618310928345\n",
            "896: 0.41079655289649963\n",
            "897: 0.41906312108039856\n",
            "898: 0.4231826961040497\n",
            "899: 0.49018681049346924\n",
            "900: 0.4512818157672882\n",
            "input:   tensor([[4, 2, 5, 3, 3, 4, 2, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 4, 2, 3, 5, 2, 3]], device='cuda:0')\n",
            "incorrects: 4\n",
            "901: 0.48762181401252747\n",
            "902: 0.4359721541404724\n",
            "903: 0.48318958282470703\n",
            "904: 0.4349643886089325\n",
            "905: 0.4163787364959717\n",
            "906: 0.4867910146713257\n",
            "907: 0.4599802494049072\n",
            "908: 0.39953896403312683\n",
            "909: 0.4507770836353302\n",
            "910: 0.45382851362228394\n",
            "911: 0.4341099262237549\n",
            "912: 0.4364672601222992\n",
            "913: 0.45947834849357605\n",
            "914: 0.45921748876571655\n",
            "915: 0.4608719050884247\n",
            "916: 0.4240696430206299\n",
            "917: 0.43770962953567505\n",
            "918: 0.4219561517238617\n",
            "919: 0.4388275742530823\n",
            "920: 0.41423702239990234\n",
            "921: 0.4523259997367859\n",
            "922: 0.4240366518497467\n",
            "923: 0.41969478130340576\n",
            "924: 0.4227750897407532\n",
            "925: 0.421854704618454\n",
            "926: 0.4551284611225128\n",
            "927: 0.4102321267127991\n",
            "928: 0.3901066184043884\n",
            "929: 0.4175833463668823\n",
            "930: 0.4003485143184662\n",
            "931: 0.4212797284126282\n",
            "932: 0.40609022974967957\n",
            "933: 0.4175258278846741\n",
            "934: 0.41878649592399597\n",
            "935: 0.4131515324115753\n",
            "936: 0.39374440908432007\n",
            "937: 0.39590269327163696\n",
            "938: 0.40799784660339355\n",
            "939: 0.40726611018180847\n",
            "940: 0.38471683859825134\n",
            "941: 0.397693932056427\n",
            "942: 0.39565107226371765\n",
            "943: 0.39043423533439636\n",
            "944: 0.38423702120780945\n",
            "945: 0.38365745544433594\n",
            "946: 0.3951673209667206\n",
            "947: 0.3993666172027588\n",
            "948: 0.3891112804412842\n",
            "949: 0.39852839708328247\n",
            "950: 0.3921341001987457\n",
            "951: 0.4148111343383789\n",
            "952: 0.3838604986667633\n",
            "953: 0.3668746054172516\n",
            "954: 0.3769364356994629\n",
            "955: 0.38988107442855835\n",
            "956: 0.37612441182136536\n",
            "957: 0.4065161347389221\n",
            "958: 0.3653993606567383\n",
            "959: 0.38087689876556396\n",
            "960: 0.39425432682037354\n",
            "961: 0.38049477338790894\n",
            "962: 0.3626370131969452\n",
            "963: 0.35856643319129944\n",
            "964: 0.3710649013519287\n",
            "965: 0.35758402943611145\n",
            "966: 0.40763306617736816\n",
            "967: 0.38205859065055847\n",
            "968: 0.3897956609725952\n",
            "969: 0.3808545470237732\n",
            "970: 0.39877137541770935\n",
            "971: 0.3752707242965698\n",
            "972: 0.3675190806388855\n",
            "973: 0.38790640234947205\n",
            "974: 0.4194679260253906\n",
            "975: 0.4085635244846344\n",
            "976: 0.3787514865398407\n",
            "977: 0.3871442377567291\n",
            "978: 0.4091123640537262\n",
            "979: 0.410101979970932\n",
            "980: 0.39315858483314514\n",
            "981: 0.3805767595767975\n",
            "982: 0.41119349002838135\n",
            "983: 0.38819560408592224\n",
            "984: 0.3639625310897827\n",
            "985: 0.4173297584056854\n",
            "986: 0.38119080662727356\n",
            "987: 0.403197705745697\n",
            "988: 0.4334849417209625\n",
            "989: 0.40453001856803894\n",
            "990: 0.3846084475517273\n",
            "991: 0.423211008310318\n",
            "992: 0.386527955532074\n",
            "993: 0.4045846462249756\n",
            "994: 0.4006761312484741\n",
            "995: 0.3804522752761841\n",
            "996: 0.3892824053764343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:50<00:00, 19.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "997: 0.4017289876937866\n",
            "998: 0.3946918547153473\n",
            "999: 0.368343323469162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "5dcab8e4-bf8e-4ce0-ddd3-2c5b74ea240f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 87.5%\n"
          ]
        }
      ]
    }
  ]
}