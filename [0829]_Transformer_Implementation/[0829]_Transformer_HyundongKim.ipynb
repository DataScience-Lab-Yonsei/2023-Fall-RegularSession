{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "043252f8-d54d-4854-bfda-43a8342ec073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "1af6b0ad-a87b-4003-c060-0cfc8858ec5f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2.727139949798584\n",
            "1: 2.256948709487915\n",
            "2: 2.101267099380493\n",
            "3: 2.083951234817505\n",
            "4: 2.06235933303833\n",
            "5: 2.0390946865081787\n",
            "6: 2.0413966178894043\n",
            "7: 1.996823787689209\n",
            "8: 1.9823178052902222\n",
            "9: 2.0146498680114746\n",
            "10: 1.9566376209259033\n",
            "11: 1.957607388496399\n",
            "12: 1.984459638595581\n",
            "13: 1.9396376609802246\n",
            "14: 1.9336129426956177\n",
            "15: 1.9199473857879639\n",
            "16: 1.9103516340255737\n",
            "17: 1.8849718570709229\n",
            "18: 1.857194185256958\n",
            "19: 1.9075984954833984\n",
            "20: 1.931187391281128\n",
            "21: 1.8467379808425903\n",
            "22: 1.8843120336532593\n",
            "23: 1.862120509147644\n",
            "24: 1.8483104705810547\n",
            "25: 1.8629496097564697\n",
            "26: 1.8523776531219482\n",
            "27: 1.8244199752807617\n",
            "28: 1.8437343835830688\n",
            "29: 1.8581794500350952\n",
            "30: 1.8063095808029175\n",
            "31: 1.816646695137024\n",
            "32: 1.8436893224716187\n",
            "33: 1.780761957168579\n",
            "34: 1.8331599235534668\n",
            "35: 1.7513445615768433\n",
            "36: 1.7589415311813354\n",
            "37: 1.776625394821167\n",
            "38: 1.7697721719741821\n",
            "39: 1.7656141519546509\n",
            "40: 1.7993988990783691\n",
            "41: 1.6931922435760498\n",
            "42: 1.7161262035369873\n",
            "43: 1.7516365051269531\n",
            "44: 1.7560690641403198\n",
            "45: 1.7226296663284302\n",
            "46: 1.8002873659133911\n",
            "47: 1.7172341346740723\n",
            "48: 1.7499535083770752\n",
            "49: 1.7785110473632812\n",
            "50: 1.7537097930908203\n",
            "51: 1.7200666666030884\n",
            "52: 1.672487735748291\n",
            "53: 1.7262744903564453\n",
            "54: 1.7334610223770142\n",
            "55: 1.7349066734313965\n",
            "56: 1.6847678422927856\n",
            "57: 1.6990535259246826\n",
            "58: 1.6708722114562988\n",
            "59: 1.7198526859283447\n",
            "60: 1.6902183294296265\n",
            "61: 1.6340774297714233\n",
            "62: 1.6682173013687134\n",
            "63: 1.6750802993774414\n",
            "64: 1.712425708770752\n",
            "65: 1.673352837562561\n",
            "66: 1.6516246795654297\n",
            "67: 1.6884267330169678\n",
            "68: 1.7399868965148926\n",
            "69: 1.626024842262268\n",
            "70: 1.64698326587677\n",
            "71: 1.6216739416122437\n",
            "72: 1.6560635566711426\n",
            "73: 1.667967438697815\n",
            "74: 1.6271072626113892\n",
            "75: 1.6448041200637817\n",
            "76: 1.67316472530365\n",
            "77: 1.5864912271499634\n",
            "78: 1.632915735244751\n",
            "79: 1.6384421586990356\n",
            "80: 1.626173734664917\n",
            "81: 1.6379503011703491\n",
            "82: 1.6672168970108032\n",
            "83: 1.6090222597122192\n",
            "84: 1.6508104801177979\n",
            "85: 1.6464446783065796\n",
            "86: 1.6160342693328857\n",
            "87: 1.6182388067245483\n",
            "88: 1.6492464542388916\n",
            "89: 1.6279205083847046\n",
            "90: 1.6119334697723389\n",
            "91: 1.598313808441162\n",
            "92: 1.6287282705307007\n",
            "93: 1.6137973070144653\n",
            "94: 1.5508114099502563\n",
            "95: 1.5699962377548218\n",
            "96: 1.5799752473831177\n",
            "97: 1.6146092414855957\n",
            "98: 1.522253155708313\n",
            "99: 1.5925886631011963\n",
            "100: 1.618334174156189\n",
            "input:   tensor([[5, 5, 5, 2, 3, 2, 3, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 5, 5, 3, 5, 3, 2, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "101: 1.5545424222946167\n",
            "102: 1.5367343425750732\n",
            "103: 1.5896296501159668\n",
            "104: 1.5681312084197998\n",
            "105: 1.514138102531433\n",
            "106: 1.5264259576797485\n",
            "107: 1.5575164556503296\n",
            "108: 1.554581880569458\n",
            "109: 1.5747562646865845\n",
            "110: 1.557647705078125\n",
            "111: 1.5428818464279175\n",
            "112: 1.5532798767089844\n",
            "113: 1.5365140438079834\n",
            "114: 1.525771141052246\n",
            "115: 1.5258724689483643\n",
            "116: 1.5056986808776855\n",
            "117: 1.5180213451385498\n",
            "118: 1.4758082628250122\n",
            "119: 1.5300251245498657\n",
            "120: 1.4735356569290161\n",
            "121: 1.494642972946167\n",
            "122: 1.4978508949279785\n",
            "123: 1.4848015308380127\n",
            "124: 1.458815574645996\n",
            "125: 1.4710417985916138\n",
            "126: 1.4925040006637573\n",
            "127: 1.4938501119613647\n",
            "128: 1.4714453220367432\n",
            "129: 1.484639286994934\n",
            "130: 1.4214298725128174\n",
            "131: 1.4771263599395752\n",
            "132: 1.4111958742141724\n",
            "133: 1.4735432863235474\n",
            "134: 1.4075963497161865\n",
            "135: 1.4694569110870361\n",
            "136: 1.4433729648590088\n",
            "137: 1.4627147912979126\n",
            "138: 1.5502772331237793\n",
            "139: 1.4894880056381226\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  14%|█▍        | 144/1000 [00:10<00:59, 14.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140: 1.43464994430542\n",
            "141: 1.4628949165344238\n",
            "142: 1.4320179224014282\n",
            "143: 1.4127565622329712\n",
            "144: 1.430187463760376\n",
            "145: 1.4286540746688843\n",
            "146: 1.4170945882797241\n",
            "147: 1.39911687374115\n",
            "148: 1.4257041215896606\n",
            "149: 1.3905481100082397\n",
            "150: 1.4044239521026611\n",
            "151: 1.3863444328308105\n",
            "152: 1.3849811553955078\n",
            "153: 1.418110966682434\n",
            "154: 1.4091557264328003\n",
            "155: 1.441887378692627\n",
            "156: 1.3906947374343872\n",
            "157: 1.4362726211547852\n",
            "158: 1.370867133140564\n",
            "159: 1.3843990564346313\n",
            "160: 1.361920952796936\n",
            "161: 1.3906621932983398\n",
            "162: 1.3923856019973755\n",
            "163: 1.3891807794570923\n",
            "164: 1.3539760112762451\n",
            "165: 1.337084174156189\n",
            "166: 1.3391385078430176\n",
            "167: 1.3581598997116089\n",
            "168: 1.3848265409469604\n",
            "169: 1.3302966356277466\n",
            "170: 1.3587265014648438\n",
            "171: 1.3496084213256836\n",
            "172: 1.3205713033676147\n",
            "173: 1.2768058776855469\n",
            "174: 1.3003612756729126\n",
            "175: 1.3401587009429932\n",
            "176: 1.3159152269363403\n",
            "177: 1.3198906183242798\n",
            "178: 1.3073817491531372\n",
            "179: 1.3209714889526367\n",
            "180: 1.3838685750961304\n",
            "181: 1.4120445251464844\n",
            "182: 1.301859974861145\n",
            "183: 1.3937010765075684\n",
            "184: 1.3035157918930054\n",
            "185: 1.3452411890029907\n",
            "186: 1.3017387390136719\n",
            "187: 1.3006004095077515\n",
            "188: 1.3372735977172852\n",
            "189: 1.321678876876831\n",
            "190: 1.3134419918060303\n",
            "191: 1.315360426902771\n",
            "192: 1.2992351055145264\n",
            "193: 1.229638934135437\n",
            "194: 1.3256741762161255\n",
            "195: 1.2758744955062866\n",
            "196: 1.2537040710449219\n",
            "197: 1.2454875707626343\n",
            "198: 1.244681715965271\n",
            "199: 1.2875093221664429\n",
            "200: 1.2330737113952637\n",
            "input:   tensor([[3, 4, 2, 4, 5, 4, 2, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 4, 4, 5, 2, 4, 4, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "201: 1.2548527717590332\n",
            "202: 1.2514147758483887\n",
            "203: 1.237777590751648\n",
            "204: 1.2470676898956299\n",
            "205: 1.1902384757995605\n",
            "206: 1.2130078077316284\n",
            "207: 1.2625069618225098\n",
            "208: 1.2157602310180664\n",
            "209: 1.356573224067688\n",
            "210: 1.2104414701461792\n",
            "211: 1.2877277135849\n",
            "212: 1.2618051767349243\n",
            "213: 1.201404094696045\n",
            "214: 1.2369327545166016\n",
            "215: 1.2444195747375488\n",
            "216: 1.191953420639038\n",
            "217: 1.2440075874328613\n",
            "218: 1.2246010303497314\n",
            "219: 1.1954927444458008\n",
            "220: 1.1671024560928345\n",
            "221: 1.2287644147872925\n",
            "222: 1.1625131368637085\n",
            "223: 1.1907135248184204\n",
            "224: 1.210404634475708\n",
            "225: 1.161618709564209\n",
            "226: 1.2265903949737549\n",
            "227: 1.1757442951202393\n",
            "228: 1.1995478868484497\n",
            "229: 1.207423210144043\n",
            "230: 1.1940778493881226\n",
            "231: 1.2086395025253296\n",
            "232: 1.1707688570022583\n",
            "233: 1.177922248840332\n",
            "234: 1.1318126916885376\n",
            "235: 1.1368041038513184\n",
            "236: 1.1556041240692139\n",
            "237: 1.1234662532806396\n",
            "238: 1.1860816478729248\n",
            "239: 1.1373082399368286\n",
            "240: 1.1242417097091675\n",
            "241: 1.1449707746505737\n",
            "242: 1.1205286979675293\n",
            "243: 1.173176884651184\n",
            "244: 1.1339974403381348\n",
            "245: 1.1347949504852295\n",
            "246: 1.1093337535858154\n",
            "247: 1.1098191738128662\n",
            "248: 1.088836908340454\n",
            "249: 1.073209285736084\n",
            "250: 1.1308014392852783\n",
            "251: 1.1043397188186646\n",
            "252: 1.093675971031189\n",
            "253: 1.0983911752700806\n",
            "254: 1.1069785356521606\n",
            "255: 1.0921649932861328\n",
            "256: 1.068893551826477\n",
            "257: 1.124351143836975\n",
            "258: 1.0645915269851685\n",
            "259: 1.092012882232666\n",
            "260: 1.0851988792419434\n",
            "261: 1.0326333045959473\n",
            "262: 1.0905239582061768\n",
            "263: 1.0367988348007202\n",
            "264: 1.0637671947479248\n",
            "265: 1.126747965812683\n",
            "266: 1.1210227012634277\n",
            "267: 1.1637625694274902\n",
            "268: 1.0757825374603271\n",
            "269: 1.1420503854751587\n",
            "270: 1.1192631721496582\n",
            "271: 1.0574074983596802\n",
            "272: 1.074225664138794\n",
            "273: 1.055101752281189\n",
            "274: 1.0542160272598267\n",
            "275: 1.0554999113082886\n",
            "276: 1.0992138385772705\n",
            "277: 1.0863572359085083\n",
            "278: 1.1167118549346924\n",
            "279: 1.0707465410232544\n",
            "280: 1.0798654556274414\n",
            "281: 1.0222116708755493\n",
            "282: 1.0240412950515747\n",
            "283: 1.0393778085708618\n",
            "284: 1.0277259349822998\n",
            "285: 1.0151816606521606\n",
            "286: 0.9722975492477417\n",
            "287: 0.9879601001739502\n",
            "288: 0.9476068019866943\n",
            "289: 0.9948173761367798\n",
            "290: 0.998976469039917\n",
            "291: 0.9705955982208252\n",
            "292: 0.9546225070953369\n",
            "293: 0.9522101283073425\n",
            "294: 0.9665297865867615\n",
            "295: 0.9795275926589966\n",
            "296: 0.9695396423339844\n",
            "297: 0.9353083372116089\n",
            "298: 0.9471198916435242\n",
            "299: 0.9427942037582397\n",
            "300: 0.9592011570930481\n",
            "input:   tensor([[5, 3, 3, 3, 3, 3, 4, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 3, 3, 4, 5, 3, 5, 3]], device='cuda:0')\n",
            "incorrects: 5\n",
            "301: 0.929275631904602\n",
            "302: 0.9135910272598267\n",
            "303: 0.9452885389328003\n",
            "304: 0.9432969689369202\n",
            "305: 1.0121816396713257\n",
            "306: 0.933154284954071\n",
            "307: 0.9815561771392822\n",
            "308: 0.9370554089546204\n",
            "309: 0.9764394760131836\n",
            "310: 1.071768879890442\n",
            "311: 1.0416638851165771\n",
            "312: 0.9355458617210388\n",
            "313: 0.9726161360740662\n",
            "314: 0.9394028186798096\n",
            "315: 0.9697229862213135\n",
            "316: 0.9988450407981873\n",
            "317: 0.9336430430412292\n",
            "318: 0.9263361692428589\n",
            "319: 0.8988722562789917\n",
            "320: 0.9126002192497253\n",
            "321: 0.9454139471054077\n",
            "322: 0.9297606348991394\n",
            "323: 0.9183282852172852\n",
            "324: 0.8988204002380371\n",
            "325: 0.9456899166107178\n",
            "326: 0.8825076818466187\n",
            "327: 0.880400538444519\n",
            "328: 0.9012410044670105\n",
            "329: 0.8790408968925476\n",
            "330: 0.9159183502197266\n",
            "331: 0.8710939884185791\n",
            "332: 0.9186816215515137\n",
            "333: 0.8732482194900513\n",
            "334: 0.8606772422790527\n",
            "335: 0.974763810634613\n",
            "336: 0.8917421698570251\n",
            "337: 0.8716545701026917\n",
            "338: 0.929654061794281\n",
            "339: 0.8586795330047607\n",
            "340: 0.926003098487854\n",
            "341: 0.9068870544433594\n",
            "342: 0.8580566048622131\n",
            "343: 0.8926264643669128\n",
            "344: 0.8553001880645752\n",
            "345: 0.8389157056808472\n",
            "346: 0.9551120400428772\n",
            "347: 0.8285747170448303\n",
            "348: 0.8571071624755859\n",
            "349: 0.8616859316825867\n",
            "350: 0.8664047122001648\n",
            "351: 0.8332911729812622\n",
            "352: 0.8681802153587341\n",
            "353: 0.8956694006919861\n",
            "354: 0.8727905750274658\n",
            "355: 0.8784927129745483\n",
            "356: 0.9268547892570496\n",
            "357: 0.8376120328903198\n",
            "358: 0.8517029881477356\n",
            "359: 0.9089211225509644\n",
            "360: 0.8356009721755981\n",
            "361: 0.8963991403579712\n",
            "362: 0.8039265871047974\n",
            "363: 0.8062338829040527\n",
            "364: 0.9045975208282471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 369/1000 [00:20<00:32, 19.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "365: 0.8893011212348938\n",
            "366: 0.8483202457427979\n",
            "367: 0.8959168195724487\n",
            "368: 0.891314685344696\n",
            "369: 0.8538379669189453\n",
            "370: 0.9257286190986633\n",
            "371: 0.812914252281189\n",
            "372: 0.8709568977355957\n",
            "373: 0.8290241956710815\n",
            "374: 0.8217141628265381\n",
            "375: 0.8195197582244873\n",
            "376: 0.859210729598999\n",
            "377: 0.8245171904563904\n",
            "378: 0.8434295058250427\n",
            "379: 1.017173171043396\n",
            "380: 0.804629921913147\n",
            "381: 0.8959485292434692\n",
            "382: 0.8631798028945923\n",
            "383: 0.8479448556900024\n",
            "384: 0.9668976664543152\n",
            "385: 0.8670132160186768\n",
            "386: 0.8206992149353027\n",
            "387: 0.8500629663467407\n",
            "388: 0.8203577995300293\n",
            "389: 0.8099605441093445\n",
            "390: 0.903663158416748\n",
            "391: 0.8553762435913086\n",
            "392: 0.903647243976593\n",
            "393: 0.8206267952919006\n",
            "394: 0.8315045237541199\n",
            "395: 0.8247908353805542\n",
            "396: 0.8399472832679749\n",
            "397: 0.8258156180381775\n",
            "398: 0.7626250386238098\n",
            "399: 0.7667422294616699\n",
            "400: 0.7754154801368713\n",
            "input:   tensor([[2, 5, 2, 5, 5, 4, 4, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 5, 2, 4, 5, 4, 2, 5]], device='cuda:0')\n",
            "incorrects: 3\n",
            "401: 0.7627094388008118\n",
            "402: 0.8043432831764221\n",
            "403: 0.7879214882850647\n",
            "404: 0.8183260560035706\n",
            "405: 0.772221028804779\n",
            "406: 0.7571249008178711\n",
            "407: 0.7791079878807068\n",
            "408: 0.7449818253517151\n",
            "409: 0.7570724487304688\n",
            "410: 0.7154229283332825\n",
            "411: 0.7368960976600647\n",
            "412: 0.7466599345207214\n",
            "413: 0.7508184313774109\n",
            "414: 0.7527124881744385\n",
            "415: 0.7412600517272949\n",
            "416: 0.7566262483596802\n",
            "417: 0.7145739197731018\n",
            "418: 0.7320742011070251\n",
            "419: 0.7654625177383423\n",
            "420: 0.6894917488098145\n",
            "421: 0.7063268423080444\n",
            "422: 0.6958159804344177\n",
            "423: 0.7060719728469849\n",
            "424: 0.6951070427894592\n",
            "425: 0.6974671483039856\n",
            "426: 0.7233676314353943\n",
            "427: 0.6760321855545044\n",
            "428: 0.6823040843009949\n",
            "429: 0.6989723443984985\n",
            "430: 0.655677318572998\n",
            "431: 0.7368038296699524\n",
            "432: 0.7179450392723083\n",
            "433: 0.7926746606826782\n",
            "434: 0.6976724863052368\n",
            "435: 0.6769646406173706\n",
            "436: 0.705996572971344\n",
            "437: 0.7378401160240173\n",
            "438: 0.7417939305305481\n",
            "439: 0.7076683044433594\n",
            "440: 0.6769319176673889\n",
            "441: 0.6965593695640564\n",
            "442: 0.6943675875663757\n",
            "443: 0.6821990609169006\n",
            "444: 0.7248985767364502\n",
            "445: 0.6681074500083923\n",
            "446: 0.6929433941841125\n",
            "447: 0.6962173581123352\n",
            "448: 0.702160656452179\n",
            "449: 0.6488950252532959\n",
            "450: 0.6832824945449829\n",
            "451: 0.6935373544692993\n",
            "452: 0.7153583765029907\n",
            "453: 0.6775681376457214\n",
            "454: 0.7044036984443665\n",
            "455: 0.7075445055961609\n",
            "456: 0.6517429947853088\n",
            "457: 0.6659883856773376\n",
            "458: 0.6699660420417786\n",
            "459: 0.6686978936195374\n",
            "460: 0.682482123374939\n",
            "461: 0.6391201615333557\n",
            "462: 0.6130130887031555\n",
            "463: 0.6775757074356079\n",
            "464: 0.6321188807487488\n",
            "465: 0.660165011882782\n",
            "466: 0.6455371975898743\n",
            "467: 0.6950979828834534\n",
            "468: 0.6518969535827637\n",
            "469: 0.6394251585006714\n",
            "470: 0.6431204080581665\n",
            "471: 0.6518989205360413\n",
            "472: 0.6464115381240845\n",
            "473: 0.6727890968322754\n",
            "474: 0.6610242128372192\n",
            "475: 0.660813570022583\n",
            "476: 0.6287843585014343\n",
            "477: 0.6268178820610046\n",
            "478: 0.645089864730835\n",
            "479: 0.6677933931350708\n",
            "480: 0.6301490664482117\n",
            "481: 0.6519884467124939\n",
            "482: 0.6233822703361511\n",
            "483: 0.6177213788032532\n",
            "484: 0.6246183514595032\n",
            "485: 0.6059034466743469\n",
            "486: 0.621812105178833\n",
            "487: 0.6173021793365479\n",
            "488: 0.6030538082122803\n",
            "489: 0.6357991099357605\n",
            "490: 0.5933060646057129\n",
            "491: 0.6404925584793091\n",
            "492: 0.5991367101669312\n",
            "493: 0.6019867658615112\n",
            "494: 0.5908826589584351\n",
            "495: 0.6015247702598572\n",
            "496: 0.6163123846054077\n",
            "497: 0.6200740933418274\n",
            "498: 0.6457114219665527\n",
            "499: 0.5929059386253357\n",
            "500: 0.6249090433120728\n",
            "input:   tensor([[4, 2, 4, 3, 5, 5, 2, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 4, 2, 5, 5, 3, 4, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "501: 0.6027359962463379\n",
            "502: 0.589008092880249\n",
            "503: 0.6375480890274048\n",
            "504: 0.5557243824005127\n",
            "505: 0.6527584195137024\n",
            "506: 0.615810751914978\n",
            "507: 0.6004124283790588\n",
            "508: 0.6050690412521362\n",
            "509: 0.6356064081192017\n",
            "510: 0.605972945690155\n",
            "511: 0.5827633142471313\n",
            "512: 0.6067352890968323\n",
            "513: 0.588234007358551\n",
            "514: 0.6553949117660522\n",
            "515: 0.60886549949646\n",
            "516: 0.6284298896789551\n",
            "517: 0.6155964136123657\n",
            "518: 0.6227115988731384\n",
            "519: 0.6558746099472046\n",
            "520: 0.5898964405059814\n",
            "521: 0.6010316610336304\n",
            "522: 0.625925600528717\n",
            "523: 0.624975323677063\n",
            "524: 0.6161738038063049\n",
            "525: 0.6140903830528259\n",
            "526: 0.5907902121543884\n",
            "527: 0.5995137691497803\n",
            "528: 0.5660338997840881\n",
            "529: 0.6159584522247314\n",
            "530: 0.6388692259788513\n",
            "531: 0.5859766006469727\n",
            "532: 0.5979582071304321\n",
            "533: 0.5725852251052856\n",
            "534: 0.5986997485160828\n",
            "535: 0.5692729949951172\n",
            "536: 0.6226878762245178\n",
            "537: 0.572806715965271\n",
            "538: 0.5940999984741211\n",
            "539: 0.5547488927841187\n",
            "540: 0.5768239498138428\n",
            "541: 0.5880665183067322\n",
            "542: 0.6008137464523315\n",
            "543: 0.607340931892395\n",
            "544: 0.5582934617996216\n",
            "545: 0.5872612595558167\n",
            "546: 0.620408833026886\n",
            "547: 0.5865774750709534\n",
            "548: 0.59493488073349\n",
            "549: 0.581502377986908\n",
            "550: 0.6455042362213135\n",
            "551: 0.5942129492759705\n",
            "552: 0.5954036712646484\n",
            "553: 0.5851241946220398\n",
            "554: 0.5535724759101868\n",
            "555: 0.5664111971855164\n",
            "556: 0.5760178565979004\n",
            "557: 0.5732735395431519\n",
            "558: 0.6023871302604675\n",
            "559: 0.6028607487678528\n",
            "560: 0.5473554730415344\n",
            "561: 0.5571007132530212\n",
            "562: 0.5247648358345032\n",
            "563: 0.5685830116271973\n",
            "564: 0.5546808838844299\n",
            "565: 0.5548992156982422\n",
            "566: 0.5851527452468872\n",
            "567: 0.5297266244888306\n",
            "568: 0.6053164005279541\n",
            "569: 0.5511952042579651\n",
            "570: 0.5434796810150146\n",
            "571: 0.5720633268356323\n",
            "572: 0.5569197535514832\n",
            "573: 0.5573428273200989\n",
            "574: 0.5936205983161926\n",
            "575: 0.5449923276901245\n",
            "576: 0.583870530128479\n",
            "577: 0.5501222014427185\n",
            "578: 0.5110117793083191\n",
            "579: 0.5648576617240906\n",
            "580: 0.5808888077735901\n",
            "581: 0.5289257764816284\n",
            "582: 0.5449621081352234\n",
            "583: 0.5117287635803223\n",
            "584: 0.5393871068954468\n",
            "585: 0.5615346431732178\n",
            "586: 0.5552611351013184\n",
            "587: 0.5524144172668457\n",
            "588: 0.5287889242172241\n",
            "589: 0.5276529788970947\n",
            "590: 0.5286828875541687\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  59%|█████▉    | 594/1000 [00:30<00:19, 20.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "591: 0.5493804216384888\n",
            "592: 0.517044186592102\n",
            "593: 0.554677426815033\n",
            "594: 0.5148018598556519\n",
            "595: 0.529457688331604\n",
            "596: 0.5528676509857178\n",
            "597: 0.5247458219528198\n",
            "598: 0.5132182240486145\n",
            "599: 0.5382312536239624\n",
            "600: 0.5319815278053284\n",
            "input:   tensor([[5, 3, 5, 2, 3, 2, 4, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 2, 4, 3, 5, 2, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "601: 0.5138307213783264\n",
            "602: 0.6018282175064087\n",
            "603: 0.5056847929954529\n",
            "604: 0.5540526509284973\n",
            "605: 0.5414960384368896\n",
            "606: 0.5732665061950684\n",
            "607: 0.5130674242973328\n",
            "608: 0.6075820922851562\n",
            "609: 0.5329014658927917\n",
            "610: 0.6369239091873169\n",
            "611: 0.5592753291130066\n",
            "612: 0.5520699620246887\n",
            "613: 0.6331421136856079\n",
            "614: 0.5753402709960938\n",
            "615: 0.5838153958320618\n",
            "616: 0.6405737400054932\n",
            "617: 0.5442283749580383\n",
            "618: 0.5899227261543274\n",
            "619: 0.5522559285163879\n",
            "620: 0.7064933180809021\n",
            "621: 0.5815100073814392\n",
            "622: 0.617612361907959\n",
            "623: 0.5768929123878479\n",
            "624: 0.6110059022903442\n",
            "625: 0.5863382816314697\n",
            "626: 0.5145580768585205\n",
            "627: 0.545590877532959\n",
            "628: 0.5639299154281616\n",
            "629: 0.5742323994636536\n",
            "630: 0.6109615564346313\n",
            "631: 0.5630388855934143\n",
            "632: 0.5491216778755188\n",
            "633: 0.6093146204948425\n",
            "634: 0.5460915565490723\n",
            "635: 0.630748450756073\n",
            "636: 0.5449517965316772\n",
            "637: 0.5964291095733643\n",
            "638: 0.5923144817352295\n",
            "639: 0.5013389587402344\n",
            "640: 0.5766800045967102\n",
            "641: 0.5376869440078735\n",
            "642: 0.5589287877082825\n",
            "643: 0.5483913421630859\n",
            "644: 0.5232326984405518\n",
            "645: 0.5318549275398254\n",
            "646: 0.5412167310714722\n",
            "647: 0.5172535181045532\n",
            "648: 0.5366294980049133\n",
            "649: 0.5174281001091003\n",
            "650: 0.5326012372970581\n",
            "651: 0.5089777112007141\n",
            "652: 0.5206245183944702\n",
            "653: 0.5233132839202881\n",
            "654: 0.49508407711982727\n",
            "655: 0.4830457866191864\n",
            "656: 0.4899292588233948\n",
            "657: 0.4787748456001282\n",
            "658: 0.5095240473747253\n",
            "659: 0.5053176283836365\n",
            "660: 0.47194233536720276\n",
            "661: 0.46677082777023315\n",
            "662: 0.5051850080490112\n",
            "663: 0.500257134437561\n",
            "664: 0.49998244643211365\n",
            "665: 0.48594143986701965\n",
            "666: 0.46136045455932617\n",
            "667: 0.5150247812271118\n",
            "668: 0.5066508650779724\n",
            "669: 0.5124889016151428\n",
            "670: 0.5111491084098816\n",
            "671: 0.4977834224700928\n",
            "672: 0.5066518187522888\n",
            "673: 0.49341264367103577\n",
            "674: 0.46994107961654663\n",
            "675: 0.47749730944633484\n",
            "676: 0.49179115891456604\n",
            "677: 0.48874491453170776\n",
            "678: 0.4720773696899414\n",
            "679: 0.48699870705604553\n",
            "680: 0.48855355381965637\n",
            "681: 0.4853740632534027\n",
            "682: 0.5172494649887085\n",
            "683: 0.49504783749580383\n",
            "684: 0.48386138677597046\n",
            "685: 0.488926500082016\n",
            "686: 0.5247406363487244\n",
            "687: 0.488213449716568\n",
            "688: 0.4792834222316742\n",
            "689: 0.5017878413200378\n",
            "690: 0.49555206298828125\n",
            "691: 0.4767675995826721\n",
            "692: 0.4765375256538391\n",
            "693: 0.5049934387207031\n",
            "694: 0.4787362813949585\n",
            "695: 0.47291696071624756\n",
            "696: 0.4770255386829376\n",
            "697: 0.46360933780670166\n",
            "698: 0.4986809492111206\n",
            "699: 0.507714033126831\n",
            "700: 0.49545106291770935\n",
            "input:   tensor([[3, 2, 2, 5, 3, 5, 5, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 5, 3, 5, 5, 2, 3, 2]], device='cuda:0')\n",
            "incorrects: 7\n",
            "701: 0.45919710397720337\n",
            "702: 0.45533815026283264\n",
            "703: 0.4872734844684601\n",
            "704: 0.4933781921863556\n",
            "705: 0.4913153350353241\n",
            "706: 0.46558070182800293\n",
            "707: 0.47637730836868286\n",
            "708: 0.47308868169784546\n",
            "709: 0.4707518219947815\n",
            "710: 0.45762139558792114\n",
            "711: 0.4829217493534088\n",
            "712: 0.4755130410194397\n",
            "713: 0.4652206599712372\n",
            "714: 0.45682016015052795\n",
            "715: 0.4711039066314697\n",
            "716: 0.45002228021621704\n",
            "717: 0.47120335698127747\n",
            "718: 0.4686245322227478\n",
            "719: 0.4680655896663666\n",
            "720: 0.46486106514930725\n",
            "721: 0.46778160333633423\n",
            "722: 0.4520295560359955\n",
            "723: 0.48070523142814636\n",
            "724: 0.4652573764324188\n",
            "725: 0.45990392565727234\n",
            "726: 0.4519670903682709\n",
            "727: 0.4822138547897339\n",
            "728: 0.45288366079330444\n",
            "729: 0.47959449887275696\n",
            "730: 0.4912784695625305\n",
            "731: 0.524039089679718\n",
            "732: 0.4633793532848358\n",
            "733: 0.6536630392074585\n",
            "734: 0.48521745204925537\n",
            "735: 0.7944677472114563\n",
            "736: 0.5079329013824463\n",
            "737: 0.5231272578239441\n",
            "738: 0.607962429523468\n",
            "739: 0.5619917511940002\n",
            "740: 0.5278876423835754\n",
            "741: 0.603161633014679\n",
            "742: 0.5702949166297913\n",
            "743: 0.562126874923706\n",
            "744: 0.5559465885162354\n",
            "745: 0.5656425356864929\n",
            "746: 0.5413334965705872\n",
            "747: 0.5574342608451843\n",
            "748: 0.5072186589241028\n",
            "749: 0.5561161637306213\n",
            "750: 0.5349624156951904\n",
            "751: 0.5405802130699158\n",
            "752: 0.5661165714263916\n",
            "753: 0.5318843722343445\n",
            "754: 0.4911232590675354\n",
            "755: 0.5184311866760254\n",
            "756: 0.5002487301826477\n",
            "757: 0.5012883543968201\n",
            "758: 0.49633607268333435\n",
            "759: 0.4974169433116913\n",
            "760: 0.4851319193840027\n",
            "761: 0.5135648846626282\n",
            "762: 0.4977683126926422\n",
            "763: 0.4791226387023926\n",
            "764: 0.449602335691452\n",
            "765: 0.4994492530822754\n",
            "766: 0.5001304745674133\n",
            "767: 0.4932016134262085\n",
            "768: 0.4441778361797333\n",
            "769: 0.4484736919403076\n",
            "770: 0.48639512062072754\n",
            "771: 0.46339017152786255\n",
            "772: 0.4784933030605316\n",
            "773: 0.46317020058631897\n",
            "774: 0.4502916634082794\n",
            "775: 0.45613935589790344\n",
            "776: 0.4452288746833801\n",
            "777: 0.46454256772994995\n",
            "778: 0.46398043632507324\n",
            "779: 0.41660255193710327\n",
            "780: 0.452089786529541\n",
            "781: 0.47308552265167236\n",
            "782: 0.4470541179180145\n",
            "783: 0.4234718680381775\n",
            "784: 0.4568057656288147\n",
            "785: 0.45563751459121704\n",
            "786: 0.43823882937431335\n",
            "787: 0.4594951272010803\n",
            "788: 0.43686991930007935\n",
            "789: 0.4562382102012634\n",
            "790: 0.4272378981113434\n",
            "791: 0.46215829253196716\n",
            "792: 0.44207078218460083\n",
            "793: 0.4836428761482239\n",
            "794: 0.4415868818759918\n",
            "795: 0.44409024715423584\n",
            "796: 0.41969698667526245\n",
            "797: 0.440314382314682\n",
            "798: 0.44267386198043823\n",
            "799: 0.4448416531085968\n",
            "800: 0.4477790594100952\n",
            "input:   tensor([[4, 2, 2, 4, 5, 4, 4, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 2, 4, 5, 4, 2, 5, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "801: 0.42919379472732544\n",
            "802: 0.43261265754699707\n",
            "803: 0.4630220830440521\n",
            "804: 0.4197280704975128\n",
            "805: 0.42701536417007446\n",
            "806: 0.44356316328048706\n",
            "807: 0.43669795989990234\n",
            "808: 0.4188978970050812\n",
            "809: 0.44123420119285583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  82%|████████▏ | 815/1000 [00:40<00:08, 20.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810: 0.4580574929714203\n",
            "811: 0.458659827709198\n",
            "812: 0.4141996502876282\n",
            "813: 0.43730872869491577\n",
            "814: 0.4399748146533966\n",
            "815: 0.44886574149131775\n",
            "816: 0.43412986397743225\n",
            "817: 0.42146769165992737\n",
            "818: 0.42971786856651306\n",
            "819: 0.4362533390522003\n",
            "820: 0.4237402677536011\n",
            "821: 0.45426926016807556\n",
            "822: 0.4386739134788513\n",
            "823: 0.4317070245742798\n",
            "824: 0.42801493406295776\n",
            "825: 0.42091861367225647\n",
            "826: 0.44224226474761963\n",
            "827: 0.42656320333480835\n",
            "828: 0.44456785917282104\n",
            "829: 0.4375540018081665\n",
            "830: 0.43150416016578674\n",
            "831: 0.4452114403247833\n",
            "832: 0.43491289019584656\n",
            "833: 0.4311659336090088\n",
            "834: 0.4449954032897949\n",
            "835: 0.41446709632873535\n",
            "836: 0.4260168671607971\n",
            "837: 0.4070156514644623\n",
            "838: 0.42055824398994446\n",
            "839: 0.44950681924819946\n",
            "840: 0.4371493458747864\n",
            "841: 0.4398782551288605\n",
            "842: 0.45634356141090393\n",
            "843: 0.41753992438316345\n",
            "844: 0.43883994221687317\n",
            "845: 0.4442380368709564\n",
            "846: 0.4560803174972534\n",
            "847: 0.4322143495082855\n",
            "848: 0.4433416426181793\n",
            "849: 0.4294085204601288\n",
            "850: 0.41208475828170776\n",
            "851: 0.43979933857917786\n",
            "852: 0.4314338266849518\n",
            "853: 0.4673592150211334\n",
            "854: 0.4067190885543823\n",
            "855: 0.41686493158340454\n",
            "856: 0.4192410409450531\n",
            "857: 0.4089524447917938\n",
            "858: 0.4243084490299225\n",
            "859: 0.44654032588005066\n",
            "860: 0.42233213782310486\n",
            "861: 0.4569963812828064\n",
            "862: 0.4291433095932007\n",
            "863: 0.40831857919692993\n",
            "864: 0.45691075921058655\n",
            "865: 0.40723487734794617\n",
            "866: 0.43148255348205566\n",
            "867: 0.46541449427604675\n",
            "868: 0.4348612427711487\n",
            "869: 0.4337061941623688\n",
            "870: 0.4916090965270996\n",
            "871: 0.46019208431243896\n",
            "872: 0.4501379132270813\n",
            "873: 0.472228467464447\n",
            "874: 0.45596227049827576\n",
            "875: 0.48429805040359497\n",
            "876: 0.44695553183555603\n",
            "877: 0.4424653649330139\n",
            "878: 0.4375956058502197\n",
            "879: 0.4146454632282257\n",
            "880: 0.44678089022636414\n",
            "881: 0.44112661480903625\n",
            "882: 0.4398118257522583\n",
            "883: 0.4515891373157501\n",
            "884: 0.4410257935523987\n",
            "885: 0.4609851539134979\n",
            "886: 0.49456143379211426\n",
            "887: 0.45323505997657776\n",
            "888: 0.5627878308296204\n",
            "889: 0.5087817311286926\n",
            "890: 0.41512978076934814\n",
            "891: 0.47486311197280884\n",
            "892: 0.4391401410102844\n",
            "893: 0.4360428750514984\n",
            "894: 0.41647011041641235\n",
            "895: 0.45104077458381653\n",
            "896: 0.4331253468990326\n",
            "897: 0.42774903774261475\n",
            "898: 0.45348039269447327\n",
            "899: 0.456280380487442\n",
            "900: 0.4244634509086609\n",
            "input:   tensor([[3, 4, 5, 3, 4, 2, 2, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 4, 5, 2, 3, 2, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "901: 0.44491320848464966\n",
            "902: 0.4020536541938782\n",
            "903: 0.4638657569885254\n",
            "904: 0.42688554525375366\n",
            "905: 0.4230385422706604\n",
            "906: 0.4346538484096527\n",
            "907: 0.40616846084594727\n",
            "908: 0.44861268997192383\n",
            "909: 0.4264772832393646\n",
            "910: 0.4320455491542816\n",
            "911: 0.4674324095249176\n",
            "912: 0.4428059160709381\n",
            "913: 0.43554893136024475\n",
            "914: 0.4283244013786316\n",
            "915: 0.44470736384391785\n",
            "916: 0.4554576873779297\n",
            "917: 0.410550057888031\n",
            "918: 0.4330528974533081\n",
            "919: 0.40702080726623535\n",
            "920: 0.42368659377098083\n",
            "921: 0.4113364815711975\n",
            "922: 0.4613308906555176\n",
            "923: 0.4262414574623108\n",
            "924: 0.40465018153190613\n",
            "925: 0.42898494005203247\n",
            "926: 0.4556276798248291\n",
            "927: 0.41229483485221863\n",
            "928: 0.433337539434433\n",
            "929: 0.4010448455810547\n",
            "930: 0.42247021198272705\n",
            "931: 0.4326149821281433\n",
            "932: 0.41152381896972656\n",
            "933: 0.397880882024765\n",
            "934: 0.46503520011901855\n",
            "935: 0.4079417586326599\n",
            "936: 0.4491588771343231\n",
            "937: 0.4492500126361847\n",
            "938: 0.4365817904472351\n",
            "939: 0.4225632846355438\n",
            "940: 0.4711917042732239\n",
            "941: 0.4364757537841797\n",
            "942: 0.42025327682495117\n",
            "943: 0.4490453898906708\n",
            "944: 0.465280145406723\n",
            "945: 0.41656091809272766\n",
            "946: 0.454643577337265\n",
            "947: 0.41339385509490967\n",
            "948: 0.4324501156806946\n",
            "949: 0.4333930015563965\n",
            "950: 0.39842015504837036\n",
            "951: 0.4303383231163025\n",
            "952: 0.46269458532333374\n",
            "953: 0.42632317543029785\n",
            "954: 0.4503006935119629\n",
            "955: 0.42553573846817017\n",
            "956: 0.45317351818084717\n",
            "957: 0.41047629714012146\n",
            "958: 0.4364175796508789\n",
            "959: 0.47011828422546387\n",
            "960: 0.4307914674282074\n",
            "961: 0.43358635902404785\n",
            "962: 0.4334166646003723\n",
            "963: 0.48107850551605225\n",
            "964: 0.406952440738678\n",
            "965: 0.4360809624195099\n",
            "966: 0.4435371458530426\n",
            "967: 0.43247443437576294\n",
            "968: 0.42195838689804077\n",
            "969: 0.4216589033603668\n",
            "970: 0.41628098487854004\n",
            "971: 0.41534361243247986\n",
            "972: 0.4608670473098755\n",
            "973: 0.42049935460090637\n",
            "974: 0.4163995385169983\n",
            "975: 0.4026760458946228\n",
            "976: 0.40673330426216125\n",
            "977: 0.40674257278442383\n",
            "978: 0.43228620290756226\n",
            "979: 0.4148920476436615\n",
            "980: 0.40998467803001404\n",
            "981: 0.4206930696964264\n",
            "982: 0.40229353308677673\n",
            "983: 0.41128087043762207\n",
            "984: 0.40057075023651123\n",
            "985: 0.39045947790145874\n",
            "986: 0.4213091731071472\n",
            "987: 0.39668208360671997\n",
            "988: 0.4132188558578491\n",
            "989: 0.41672903299331665\n",
            "990: 0.3832677900791168\n",
            "991: 0.40367206931114197\n",
            "992: 0.41684967279434204\n",
            "993: 0.3996537923812866\n",
            "994: 0.37586212158203125\n",
            "995: 0.3868417739868164\n",
            "996: 0.38183513283729553\n",
            "997: 0.3848976194858551\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:49<00:00, 20.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998: 0.4015270173549652\n",
            "999: 0.44203439354896545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "1a04292a-52f1-4994-e09e-c2b26553840a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 81.25%\n"
          ]
        }
      ]
    }
  ]
}