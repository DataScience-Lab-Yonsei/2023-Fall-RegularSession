{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "885b8bba-81ff-4432-d915-d8e9924fdff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "f8154851-3044-4c5e-9740-3181ba6064fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 3.1176939010620117\n",
            "1: 2.4334042072296143\n",
            "2: 2.280622959136963\n",
            "3: 2.2220051288604736\n",
            "4: 2.1654574871063232\n",
            "5: 2.148639440536499\n",
            "6: 2.1320667266845703\n",
            "7: 2.145817518234253\n",
            "8: 2.107740879058838\n",
            "9: 2.1001980304718018\n",
            "10: 2.1098666191101074\n",
            "11: 2.1100387573242188\n",
            "12: 2.0546813011169434\n",
            "13: 2.062079429626465\n",
            "14: 2.048654556274414\n",
            "15: 2.0194900035858154\n",
            "16: 2.022160053253174\n",
            "17: 2.018693447113037\n",
            "18: 2.042724847793579\n",
            "19: 1.9899821281433105\n",
            "20: 1.9965746402740479\n",
            "21: 1.991740345954895\n",
            "22: 2.0088353157043457\n",
            "23: 1.9996373653411865\n",
            "24: 1.9766826629638672\n",
            "25: 1.9871537685394287\n",
            "26: 1.9633435010910034\n",
            "27: 1.969401478767395\n",
            "28: 1.953279733657837\n",
            "29: 1.9461917877197266\n",
            "30: 1.9303209781646729\n",
            "31: 1.9100186824798584\n",
            "32: 1.9359009265899658\n",
            "33: 1.9420424699783325\n",
            "34: 1.9267436265945435\n",
            "35: 1.898440957069397\n",
            "36: 1.8982547521591187\n",
            "37: 1.904006004333496\n",
            "38: 1.884267807006836\n",
            "39: 1.902586817741394\n",
            "40: 1.8877873420715332\n",
            "41: 1.8649033308029175\n",
            "42: 1.8482123613357544\n",
            "43: 1.9159338474273682\n",
            "44: 1.8572776317596436\n",
            "45: 1.9132232666015625\n",
            "46: 1.8621543645858765\n",
            "47: 1.8922488689422607\n",
            "48: 1.8335274457931519\n",
            "49: 1.8478366136550903\n",
            "50: 1.871130347251892\n",
            "51: 1.8637844324111938\n",
            "52: 1.822427749633789\n",
            "53: 1.8705980777740479\n",
            "54: 1.8431050777435303\n",
            "55: 1.8550664186477661\n",
            "56: 1.8116636276245117\n",
            "57: 1.8226007223129272\n",
            "58: 1.8391889333724976\n",
            "59: 1.833634614944458\n",
            "60: 1.783706545829773\n",
            "61: 1.7783775329589844\n",
            "62: 1.790653109550476\n",
            "63: 1.7848889827728271\n",
            "64: 1.7932190895080566\n",
            "65: 1.8162095546722412\n",
            "66: 1.7408108711242676\n",
            "67: 1.7909555435180664\n",
            "68: 1.7615240812301636\n",
            "69: 1.7984724044799805\n",
            "70: 1.7732068300247192\n",
            "71: 1.753664255142212\n",
            "72: 1.742759108543396\n",
            "73: 1.7286964654922485\n",
            "74: 1.7247917652130127\n",
            "75: 1.763414740562439\n",
            "76: 1.7271978855133057\n",
            "77: 1.7578494548797607\n",
            "78: 1.7565971612930298\n",
            "79: 1.740984559059143\n",
            "80: 1.7086986303329468\n",
            "81: 1.7363667488098145\n",
            "82: 1.7322698831558228\n",
            "83: 1.7320513725280762\n",
            "84: 1.7338119745254517\n",
            "85: 1.7238011360168457\n",
            "86: 1.669106364250183\n",
            "87: 1.7150448560714722\n",
            "88: 1.671156883239746\n",
            "89: 1.7131472826004028\n",
            "90: 1.6518440246582031\n",
            "91: 1.6654515266418457\n",
            "92: 1.6954541206359863\n",
            "93: 1.6347248554229736\n",
            "94: 1.6824257373809814\n",
            "95: 1.67949378490448\n",
            "96: 1.6603635549545288\n",
            "97: 1.6982312202453613\n",
            "98: 1.6550590991973877\n",
            "99: 1.6822313070297241\n",
            "100: 1.6298068761825562\n",
            "input:   tensor([[5, 4, 3, 2, 2, 2, 5, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 3, 5, 3, 5, 3, 5, 3]], device='cuda:0')\n",
            "incorrects: 5\n",
            "101: 1.6361677646636963\n",
            "102: 1.6091351509094238\n",
            "103: 1.6378161907196045\n",
            "104: 1.6194535493850708\n",
            "105: 1.6398111581802368\n",
            "106: 1.5948796272277832\n",
            "107: 1.5979903936386108\n",
            "108: 1.613027811050415\n",
            "109: 1.5972158908843994\n",
            "110: 1.5978566408157349\n",
            "111: 1.6118650436401367\n",
            "112: 1.5921248197555542\n",
            "113: 1.5942810773849487\n",
            "114: 1.5621721744537354\n",
            "115: 1.5829030275344849\n",
            "116: 1.596537709236145\n",
            "117: 1.56637704372406\n",
            "118: 1.5833239555358887\n",
            "119: 1.5461747646331787\n",
            "120: 1.5687282085418701\n",
            "121: 1.5546202659606934\n",
            "122: 1.595931053161621\n",
            "123: 1.5923399925231934\n",
            "124: 1.6018707752227783\n",
            "125: 1.5568805932998657\n",
            "126: 1.5113588571548462\n",
            "127: 1.587113857269287\n",
            "128: 1.5702760219573975\n",
            "129: 1.5057497024536133\n",
            "130: 1.5495953559875488\n",
            "131: 1.6028674840927124\n",
            "132: 1.518689751625061\n",
            "133: 1.5290793180465698\n",
            "134: 1.511751651763916\n",
            "135: 1.5499975681304932\n",
            "136: 1.496559739112854\n",
            "137: 1.558030366897583\n",
            "138: 1.5072402954101562\n",
            "139: 1.523314118385315\n",
            "140: 1.505828619003296\n",
            "141: 1.5327283143997192\n",
            "142: 1.499311089515686\n",
            "143: 1.4603606462478638\n",
            "144: 1.5220292806625366\n",
            "145: 1.4939005374908447\n",
            "146: 1.4877914190292358\n",
            "147: 1.4853938817977905\n",
            "148: 1.455304741859436\n",
            "149: 1.4903043508529663\n",
            "150: 1.469519853591919\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  16%|█▌        | 156/1000 [00:10<00:54, 15.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151: 1.4449341297149658\n",
            "152: 1.4689693450927734\n",
            "153: 1.4529794454574585\n",
            "154: 1.4415712356567383\n",
            "155: 1.4423469305038452\n",
            "156: 1.4338527917861938\n",
            "157: 1.4616342782974243\n",
            "158: 1.4288718700408936\n",
            "159: 1.4360359907150269\n",
            "160: 1.4214022159576416\n",
            "161: 1.4197133779525757\n",
            "162: 1.3872158527374268\n",
            "163: 1.400247573852539\n",
            "164: 1.4215264320373535\n",
            "165: 1.3795506954193115\n",
            "166: 1.407945990562439\n",
            "167: 1.3610520362854004\n",
            "168: 1.3699232339859009\n",
            "169: 1.3541046380996704\n",
            "170: 1.3737233877182007\n",
            "171: 1.4321997165679932\n",
            "172: 1.3738764524459839\n",
            "173: 1.333970308303833\n",
            "174: 1.4193971157073975\n",
            "175: 1.4283690452575684\n",
            "176: 1.380033016204834\n",
            "177: 1.3820531368255615\n",
            "178: 1.3477119207382202\n",
            "179: 1.3541285991668701\n",
            "180: 1.375797152519226\n",
            "181: 1.3430936336517334\n",
            "182: 1.3454482555389404\n",
            "183: 1.3438425064086914\n",
            "184: 1.3175123929977417\n",
            "185: 1.377790093421936\n",
            "186: 1.2953691482543945\n",
            "187: 1.3370099067687988\n",
            "188: 1.251798391342163\n",
            "189: 1.3478540182113647\n",
            "190: 1.3235260248184204\n",
            "191: 1.2642221450805664\n",
            "192: 1.3068963289260864\n",
            "193: 1.2760944366455078\n",
            "194: 1.2810852527618408\n",
            "195: 1.3022634983062744\n",
            "196: 1.3046350479125977\n",
            "197: 1.2803126573562622\n",
            "198: 1.2689235210418701\n",
            "199: 1.2789216041564941\n",
            "200: 1.2708083391189575\n",
            "input:   tensor([[2, 2, 5, 3, 3, 2, 5, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 2, 2, 3, 4, 3, 2, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "201: 1.2487146854400635\n",
            "202: 1.2903728485107422\n",
            "203: 1.2342979907989502\n",
            "204: 1.2399897575378418\n",
            "205: 1.2637628316879272\n",
            "206: 1.2287447452545166\n",
            "207: 1.2207145690917969\n",
            "208: 1.2299871444702148\n",
            "209: 1.2055763006210327\n",
            "210: 1.2292009592056274\n",
            "211: 1.2216416597366333\n",
            "212: 1.16819167137146\n",
            "213: 1.2270729541778564\n",
            "214: 1.1801323890686035\n",
            "215: 1.2214710712432861\n",
            "216: 1.181877851486206\n",
            "217: 1.1974033117294312\n",
            "218: 1.192453145980835\n",
            "219: 1.174971342086792\n",
            "220: 1.2022838592529297\n",
            "221: 1.174905776977539\n",
            "222: 1.1599887609481812\n",
            "223: 1.1604257822036743\n",
            "224: 1.167051911354065\n",
            "225: 1.1659753322601318\n",
            "226: 1.1311354637145996\n",
            "227: 1.1732560396194458\n",
            "228: 1.1205071210861206\n",
            "229: 1.136265754699707\n",
            "230: 1.1414836645126343\n",
            "231: 1.1224130392074585\n",
            "232: 1.1301355361938477\n",
            "233: 1.1524300575256348\n",
            "234: 1.1573396921157837\n",
            "235: 1.1145167350769043\n",
            "236: 1.149118423461914\n",
            "237: 1.1380871534347534\n",
            "238: 1.1382650136947632\n",
            "239: 1.1198451519012451\n",
            "240: 1.082069754600525\n",
            "241: 1.1210254430770874\n",
            "242: 1.0998162031173706\n",
            "243: 1.0881974697113037\n",
            "244: 1.095716953277588\n",
            "245: 1.19339120388031\n",
            "246: 1.0922224521636963\n",
            "247: 1.0851287841796875\n",
            "248: 1.1070505380630493\n",
            "249: 1.1055302619934082\n",
            "250: 1.1183711290359497\n",
            "251: 1.0829416513442993\n",
            "252: 1.073935627937317\n",
            "253: 1.103149175643921\n",
            "254: 1.0861155986785889\n",
            "255: 1.0970696210861206\n",
            "256: 1.081226110458374\n",
            "257: 1.0403938293457031\n",
            "258: 1.0798637866973877\n",
            "259: 1.0816844701766968\n",
            "260: 1.0545613765716553\n",
            "261: 1.0501675605773926\n",
            "262: 1.0309971570968628\n",
            "263: 1.0098764896392822\n",
            "264: 1.056086778640747\n",
            "265: 1.0232740640640259\n",
            "266: 1.097306251525879\n",
            "267: 1.024979591369629\n",
            "268: 1.1230003833770752\n",
            "269: 1.0190268754959106\n",
            "270: 1.0138311386108398\n",
            "271: 1.073344349861145\n",
            "272: 1.0389641523361206\n",
            "273: 1.0151225328445435\n",
            "274: 1.0568194389343262\n",
            "275: 0.9874305129051208\n",
            "276: 1.0383648872375488\n",
            "277: 1.0761405229568481\n",
            "278: 1.0638853311538696\n",
            "279: 0.9812685251235962\n",
            "280: 0.9996774196624756\n",
            "281: 1.002021074295044\n",
            "282: 0.9951534867286682\n",
            "283: 0.999605119228363\n",
            "284: 1.0090813636779785\n",
            "285: 0.9619415998458862\n",
            "286: 0.9979740381240845\n",
            "287: 0.9297072291374207\n",
            "288: 0.9304381012916565\n",
            "289: 0.9984328150749207\n",
            "290: 0.9688048362731934\n",
            "291: 0.9553966522216797\n",
            "292: 0.9241388440132141\n",
            "293: 0.9291924834251404\n",
            "294: 0.9352837204933167\n",
            "295: 0.9299332499504089\n",
            "296: 0.9316859841346741\n",
            "297: 0.9562777280807495\n",
            "298: 0.9122869968414307\n",
            "299: 0.9865478873252869\n",
            "300: 0.9307337403297424\n",
            "input:   tensor([[4, 5, 5, 3, 2, 2, 4, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 5, 4, 2, 5, 3, 2, 4]], device='cuda:0')\n",
            "incorrects: 5\n",
            "301: 0.9039121866226196\n",
            "302: 0.9411158561706543\n",
            "303: 0.9237867593765259\n",
            "304: 0.9025196433067322\n",
            "305: 0.9349263906478882\n",
            "306: 0.9092835187911987\n",
            "307: 0.8821390271186829\n",
            "308: 0.9037671685218811\n",
            "309: 0.9382744431495667\n",
            "310: 0.9224714636802673\n",
            "311: 0.9352618455886841\n",
            "312: 0.9127843379974365\n",
            "313: 0.8850662708282471\n",
            "314: 0.8635929822921753\n",
            "315: 0.8624095916748047\n",
            "316: 0.9078831672668457\n",
            "317: 0.9655571579933167\n",
            "318: 0.9354540109634399\n",
            "319: 0.8982176780700684\n",
            "320: 0.9276854991912842\n",
            "321: 0.8982560038566589\n",
            "322: 0.8870093822479248\n",
            "323: 0.9339455366134644\n",
            "324: 0.8984382152557373\n",
            "325: 0.9794124960899353\n",
            "326: 0.8565701842308044\n",
            "327: 0.9134344458580017\n",
            "328: 0.8747462034225464\n",
            "329: 0.9292504191398621\n",
            "330: 0.9424049854278564\n",
            "331: 0.8930466771125793\n",
            "332: 0.8873275518417358\n",
            "333: 0.8955017924308777\n",
            "334: 0.8929862976074219\n",
            "335: 0.8992429971694946\n",
            "336: 0.8639295101165771\n",
            "337: 0.8849504590034485\n",
            "338: 0.8347086310386658\n",
            "339: 0.9028888940811157\n",
            "340: 0.8757434487342834\n",
            "341: 0.9338985681533813\n",
            "342: 0.8233596682548523\n",
            "343: 0.8556355834007263\n",
            "344: 0.910194993019104\n",
            "345: 0.8510164022445679\n",
            "346: 0.8293156027793884\n",
            "347: 0.912771463394165\n",
            "348: 0.9017109870910645\n",
            "349: 0.8140090703964233\n",
            "350: 0.9559032917022705\n",
            "351: 0.8042166233062744\n",
            "352: 0.9164034128189087\n",
            "353: 0.852006196975708\n",
            "354: 0.9263569116592407\n",
            "355: 0.8561620116233826\n",
            "356: 0.9126232862472534\n",
            "357: 0.8404579162597656\n",
            "358: 0.8449051976203918\n",
            "359: 0.8239763975143433\n",
            "360: 0.8317916393280029\n",
            "361: 0.8275171518325806\n",
            "362: 0.849905252456665\n",
            "363: 0.8113090395927429\n",
            "364: 0.8262741565704346\n",
            "365: 0.8653576970100403\n",
            "366: 0.7886070609092712\n",
            "367: 0.7846817374229431\n",
            "368: 0.7673931121826172\n",
            "369: 0.7953748106956482\n",
            "370: 0.7802914381027222\n",
            "371: 0.7801726460456848\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  37%|███▋      | 373/1000 [00:20<00:32, 19.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "372: 0.7209097743034363\n",
            "373: 0.7858580946922302\n",
            "374: 0.7784229516983032\n",
            "375: 0.7791374921798706\n",
            "376: 0.7299410700798035\n",
            "377: 0.8176723122596741\n",
            "378: 0.7813855409622192\n",
            "379: 0.7661973237991333\n",
            "380: 0.7518871426582336\n",
            "381: 0.7738476991653442\n",
            "382: 0.8435282111167908\n",
            "383: 0.787021815776825\n",
            "384: 0.7448912858963013\n",
            "385: 0.7270357608795166\n",
            "386: 0.7456527352333069\n",
            "387: 0.7399094104766846\n",
            "388: 0.7429004311561584\n",
            "389: 0.7698313593864441\n",
            "390: 0.7554579377174377\n",
            "391: 0.741539478302002\n",
            "392: 0.7733910083770752\n",
            "393: 0.7367152571678162\n",
            "394: 0.8059340715408325\n",
            "395: 0.7375515103340149\n",
            "396: 0.7327673435211182\n",
            "397: 0.726486086845398\n",
            "398: 0.7043448090553284\n",
            "399: 0.70052170753479\n",
            "400: 0.7533358931541443\n",
            "input:   tensor([[3, 3, 5, 2, 5, 4, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 3, 2, 4, 3, 3, 5]], device='cuda:0')\n",
            "incorrects: 5\n",
            "401: 0.7263174057006836\n",
            "402: 0.6913563013076782\n",
            "403: 0.6887167096138\n",
            "404: 0.6767765879631042\n",
            "405: 0.7023733854293823\n",
            "406: 0.6662542819976807\n",
            "407: 0.7183203101158142\n",
            "408: 0.6771349906921387\n",
            "409: 0.6894608736038208\n",
            "410: 0.6871453523635864\n",
            "411: 0.6936360597610474\n",
            "412: 0.6494806408882141\n",
            "413: 0.6447570323944092\n",
            "414: 0.7102836966514587\n",
            "415: 0.6649016737937927\n",
            "416: 0.6888875365257263\n",
            "417: 0.6942912340164185\n",
            "418: 0.6648988723754883\n",
            "419: 0.6639577150344849\n",
            "420: 0.6720600128173828\n",
            "421: 0.6555302143096924\n",
            "422: 0.6397901773452759\n",
            "423: 0.6767141819000244\n",
            "424: 0.6600997447967529\n",
            "425: 0.6840757131576538\n",
            "426: 0.6353031992912292\n",
            "427: 0.6669855117797852\n",
            "428: 0.6123821139335632\n",
            "429: 0.6694603562355042\n",
            "430: 0.6524285078048706\n",
            "431: 0.6499884724617004\n",
            "432: 0.7029498815536499\n",
            "433: 0.6274415254592896\n",
            "434: 0.6432735323905945\n",
            "435: 0.6918646693229675\n",
            "436: 0.6204637289047241\n",
            "437: 0.6475253701210022\n",
            "438: 0.6350366473197937\n",
            "439: 0.6428285241127014\n",
            "440: 0.6252641081809998\n",
            "441: 0.6314058899879456\n",
            "442: 0.6212427616119385\n",
            "443: 0.6264528036117554\n",
            "444: 0.6436195373535156\n",
            "445: 0.6274199485778809\n",
            "446: 0.6217536926269531\n",
            "447: 0.6188915371894836\n",
            "448: 0.6288630962371826\n",
            "449: 0.630687415599823\n",
            "450: 0.6133344173431396\n",
            "451: 0.6018671989440918\n",
            "452: 0.6238964200019836\n",
            "453: 0.6399625539779663\n",
            "454: 0.6225023865699768\n",
            "455: 0.6002412438392639\n",
            "456: 0.6386435627937317\n",
            "457: 0.6081051826477051\n",
            "458: 0.6526437401771545\n",
            "459: 0.6611634492874146\n",
            "460: 0.6597263216972351\n",
            "461: 0.5934031009674072\n",
            "462: 0.5890058279037476\n",
            "463: 0.6650196313858032\n",
            "464: 0.6034399271011353\n",
            "465: 0.6214280724525452\n",
            "466: 0.6323398947715759\n",
            "467: 0.6971076726913452\n",
            "468: 0.6195041537284851\n",
            "469: 0.6407366991043091\n",
            "470: 0.618710994720459\n",
            "471: 0.6548857688903809\n",
            "472: 0.5870370268821716\n",
            "473: 0.6287786364555359\n",
            "474: 0.6115775108337402\n",
            "475: 0.620787501335144\n",
            "476: 0.6239218711853027\n",
            "477: 0.6131792068481445\n",
            "478: 0.6146801114082336\n",
            "479: 0.5952396988868713\n",
            "480: 0.5811399817466736\n",
            "481: 0.5993896126747131\n",
            "482: 0.59577476978302\n",
            "483: 0.573982298374176\n",
            "484: 0.5736936926841736\n",
            "485: 0.5979756712913513\n",
            "486: 0.5783619284629822\n",
            "487: 0.5973755121231079\n",
            "488: 0.5785797834396362\n",
            "489: 0.5867056846618652\n",
            "490: 0.6042425632476807\n",
            "491: 0.5835050344467163\n",
            "492: 0.5763228535652161\n",
            "493: 0.5579946637153625\n",
            "494: 0.5673016309738159\n",
            "495: 0.5627329349517822\n",
            "496: 0.5652115941047668\n",
            "497: 0.5590535998344421\n",
            "498: 0.5555816292762756\n",
            "499: 0.5550284385681152\n",
            "500: 0.5619687438011169\n",
            "input:   tensor([[4, 4, 3, 3, 3, 3, 5, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 3, 4, 3, 3, 5, 4, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "501: 0.5362019538879395\n",
            "502: 0.5508208870887756\n",
            "503: 0.5297211408615112\n",
            "504: 0.5631576776504517\n",
            "505: 0.5393835306167603\n",
            "506: 0.5289369821548462\n",
            "507: 0.5393283367156982\n",
            "508: 0.5423218607902527\n",
            "509: 0.5333439707756042\n",
            "510: 0.5513293743133545\n",
            "511: 0.5283166766166687\n",
            "512: 0.5319787263870239\n",
            "513: 0.5455396175384521\n",
            "514: 0.5497229695320129\n",
            "515: 0.5127109289169312\n",
            "516: 0.531965970993042\n",
            "517: 0.5480333566665649\n",
            "518: 0.5207183957099915\n",
            "519: 0.5084743499755859\n",
            "520: 0.5417132377624512\n",
            "521: 0.5087286829948425\n",
            "522: 0.5394316911697388\n",
            "523: 0.5272549390792847\n",
            "524: 0.5085451006889343\n",
            "525: 0.543545663356781\n",
            "526: 0.5628722906112671\n",
            "527: 0.5415971875190735\n",
            "528: 0.5445042848587036\n",
            "529: 0.5769712328910828\n",
            "530: 0.5408175587654114\n",
            "531: 0.5629411339759827\n",
            "532: 0.6055011749267578\n",
            "533: 0.5527712106704712\n",
            "534: 0.71870356798172\n",
            "535: 0.5958608984947205\n",
            "536: 0.6871652603149414\n",
            "537: 0.5954453349113464\n",
            "538: 0.7160905599594116\n",
            "539: 0.62347412109375\n",
            "540: 0.6352006793022156\n",
            "541: 0.57212895154953\n",
            "542: 0.5770901441574097\n",
            "543: 0.6608842015266418\n",
            "544: 0.5864503383636475\n",
            "545: 0.5622190237045288\n",
            "546: 0.5804916620254517\n",
            "547: 0.5678391456604004\n",
            "548: 0.5854642391204834\n",
            "549: 0.5814035534858704\n",
            "550: 0.5611805319786072\n",
            "551: 0.5409197807312012\n",
            "552: 0.5407343506813049\n",
            "553: 0.580898106098175\n",
            "554: 0.5772082209587097\n",
            "555: 0.5391584634780884\n",
            "556: 0.5323644876480103\n",
            "557: 0.531389594078064\n",
            "558: 0.5570207834243774\n",
            "559: 0.5425325632095337\n",
            "560: 0.5653868317604065\n",
            "561: 0.5356337428092957\n",
            "562: 0.5475135445594788\n",
            "563: 0.5494414567947388\n",
            "564: 0.5504878163337708\n",
            "565: 0.5182365775108337\n",
            "566: 0.5212631225585938\n",
            "567: 0.5389915704727173\n",
            "568: 0.5325565934181213\n",
            "569: 0.5093156099319458\n",
            "570: 0.5250711441040039\n",
            "571: 0.5244099497795105\n",
            "572: 0.5286282896995544\n",
            "573: 0.5397071242332458\n",
            "574: 0.5437930226325989\n",
            "575: 0.5389864444732666\n",
            "576: 0.5060422420501709\n",
            "577: 0.5189216136932373\n",
            "578: 0.5353019833564758\n",
            "579: 0.5281116962432861\n",
            "580: 0.5344464778900146\n",
            "581: 0.48018041253089905\n",
            "582: 0.5076335668563843\n",
            "583: 0.5065914988517761\n",
            "584: 0.5123662948608398\n",
            "585: 0.48342201113700867\n",
            "586: 0.5244988203048706\n",
            "587: 0.5088667869567871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  59%|█████▉    | 590/1000 [00:30<00:20, 19.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "588: 0.5381784439086914\n",
            "589: 0.5187340378761292\n",
            "590: 0.5202193260192871\n",
            "591: 0.5495099425315857\n",
            "592: 0.4943535029888153\n",
            "593: 0.5062273740768433\n",
            "594: 0.4820919334888458\n",
            "595: 0.4829895794391632\n",
            "596: 0.505492091178894\n",
            "597: 0.5015062093734741\n",
            "598: 0.460236132144928\n",
            "599: 0.4799042344093323\n",
            "600: 0.535198450088501\n",
            "input:   tensor([[4, 3, 4, 5, 3, 5, 4, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 4, 3, 5, 4, 5, 3, 4]], device='cuda:0')\n",
            "incorrects: 4\n",
            "601: 0.49098193645477295\n",
            "602: 0.4929064214229584\n",
            "603: 0.47974374890327454\n",
            "604: 0.48951688408851624\n",
            "605: 0.48303279280662537\n",
            "606: 0.46862897276878357\n",
            "607: 0.48988157510757446\n",
            "608: 0.4703526496887207\n",
            "609: 0.4718295633792877\n",
            "610: 0.49217286705970764\n",
            "611: 0.4854438006877899\n",
            "612: 0.48611128330230713\n",
            "613: 0.4727107584476471\n",
            "614: 0.5149185657501221\n",
            "615: 0.5016424655914307\n",
            "616: 0.48974403738975525\n",
            "617: 0.5036092400550842\n",
            "618: 0.474759042263031\n",
            "619: 0.47964709997177124\n",
            "620: 0.520108163356781\n",
            "621: 0.47165003418922424\n",
            "622: 0.4669303297996521\n",
            "623: 0.4918382465839386\n",
            "624: 0.4970042407512665\n",
            "625: 0.4772453010082245\n",
            "626: 0.45907261967658997\n",
            "627: 0.45608144998550415\n",
            "628: 0.45947498083114624\n",
            "629: 0.4573037624359131\n",
            "630: 0.4682195782661438\n",
            "631: 0.4662400782108307\n",
            "632: 0.46634387969970703\n",
            "633: 0.4657406806945801\n",
            "634: 0.4813457429409027\n",
            "635: 0.48898065090179443\n",
            "636: 0.47466427087783813\n",
            "637: 0.4804263710975647\n",
            "638: 0.47049006819725037\n",
            "639: 0.4765971899032593\n",
            "640: 0.447920024394989\n",
            "641: 0.4685889780521393\n",
            "642: 0.4872862994670868\n",
            "643: 0.45609593391418457\n",
            "644: 0.4685244560241699\n",
            "645: 0.4861741065979004\n",
            "646: 0.44268837571144104\n",
            "647: 0.4737968146800995\n",
            "648: 0.4675082564353943\n",
            "649: 0.47144296765327454\n",
            "650: 0.46333321928977966\n",
            "651: 0.4533812999725342\n",
            "652: 0.45650428533554077\n",
            "653: 0.45944732427597046\n",
            "654: 0.46345075964927673\n",
            "655: 0.4524538516998291\n",
            "656: 0.45479217171669006\n",
            "657: 0.44898879528045654\n",
            "658: 0.45813941955566406\n",
            "659: 0.46204864978790283\n",
            "660: 0.466840922832489\n",
            "661: 0.43154993653297424\n",
            "662: 0.4509011507034302\n",
            "663: 0.44307151436805725\n",
            "664: 0.4550611674785614\n",
            "665: 0.45952457189559937\n",
            "666: 0.4381919205188751\n",
            "667: 0.44421708583831787\n",
            "668: 0.4498651325702667\n",
            "669: 0.4804050922393799\n",
            "670: 0.4261941909790039\n",
            "671: 0.4529010057449341\n",
            "672: 0.43077683448791504\n",
            "673: 0.4360531270503998\n",
            "674: 0.4525524079799652\n",
            "675: 0.4436039626598358\n",
            "676: 0.4437231123447418\n",
            "677: 0.4336736798286438\n",
            "678: 0.43259283900260925\n",
            "679: 0.4496697783470154\n",
            "680: 0.4336264729499817\n",
            "681: 0.4642464518547058\n",
            "682: 0.4704011082649231\n",
            "683: 0.4529488682746887\n",
            "684: 0.4593341648578644\n",
            "685: 0.4481992721557617\n",
            "686: 0.45132261514663696\n",
            "687: 0.4711249768733978\n",
            "688: 0.45528843998908997\n",
            "689: 0.48469841480255127\n",
            "690: 0.46614694595336914\n",
            "691: 0.4721245765686035\n",
            "692: 0.46478593349456787\n",
            "693: 0.43325114250183105\n",
            "694: 0.48794788122177124\n",
            "695: 0.4430385231971741\n",
            "696: 0.47977420687675476\n",
            "697: 0.4820033013820648\n",
            "698: 0.41078564524650574\n",
            "699: 0.4656834304332733\n",
            "700: 0.4962800145149231\n",
            "input:   tensor([[2, 4, 5, 2, 3, 4, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 3, 4, 5, 2, 4, 3, 2]], device='cuda:0')\n",
            "incorrects: 5\n",
            "701: 0.4687761664390564\n",
            "702: 0.4708417057991028\n",
            "703: 0.4726712107658386\n",
            "704: 0.44618991017341614\n",
            "705: 0.46178603172302246\n",
            "706: 0.4614403545856476\n",
            "707: 0.4862920045852661\n",
            "708: 0.47451791167259216\n",
            "709: 0.4775490462779999\n",
            "710: 0.48513609170913696\n",
            "711: 0.4157991409301758\n",
            "712: 0.5902952551841736\n",
            "713: 0.44732144474983215\n",
            "714: 0.5423203110694885\n",
            "715: 0.5368713140487671\n",
            "716: 0.501841127872467\n",
            "717: 0.5114774703979492\n",
            "718: 0.4775928854942322\n",
            "719: 0.544156551361084\n",
            "720: 0.4986715018749237\n",
            "721: 0.5000478029251099\n",
            "722: 0.4850068688392639\n",
            "723: 0.5099256634712219\n",
            "724: 0.47963207960128784\n",
            "725: 0.48602423071861267\n",
            "726: 0.4653169512748718\n",
            "727: 0.45661336183547974\n",
            "728: 0.45388132333755493\n",
            "729: 0.45094019174575806\n",
            "730: 0.4484044015407562\n",
            "731: 0.5275496244430542\n",
            "732: 0.43980082869529724\n",
            "733: 0.4390166997909546\n",
            "734: 0.5071862936019897\n",
            "735: 0.4683135747909546\n",
            "736: 0.44535505771636963\n",
            "737: 0.5303072333335876\n",
            "738: 0.43151313066482544\n",
            "739: 0.4526447355747223\n",
            "740: 0.5067660212516785\n",
            "741: 0.4650261402130127\n",
            "742: 0.43890583515167236\n",
            "743: 0.45813632011413574\n",
            "744: 0.509232223033905\n",
            "745: 0.40579721331596375\n",
            "746: 0.44303271174430847\n",
            "747: 0.4659700393676758\n",
            "748: 0.45053502917289734\n",
            "749: 0.4504742920398712\n",
            "750: 0.45089080929756165\n",
            "751: 0.4417913258075714\n",
            "752: 0.45303764939308167\n",
            "753: 0.4565567970275879\n",
            "754: 0.4622039198875427\n",
            "755: 0.4400629997253418\n",
            "756: 0.43387240171432495\n",
            "757: 0.464287132024765\n",
            "758: 0.4469451308250427\n",
            "759: 0.4439080059528351\n",
            "760: 0.4377797245979309\n",
            "761: 0.45279350876808167\n",
            "762: 0.4598144590854645\n",
            "763: 0.4363442659378052\n",
            "764: 0.43546921014785767\n",
            "765: 0.45589160919189453\n",
            "766: 0.4304143190383911\n",
            "767: 0.4271070063114166\n",
            "768: 0.42345696687698364\n",
            "769: 0.43902090191841125\n",
            "770: 0.42308157682418823\n",
            "771: 0.43587198853492737\n",
            "772: 0.4207753837108612\n",
            "773: 0.4408632218837738\n",
            "774: 0.41582491993904114\n",
            "775: 0.4369202256202698\n",
            "776: 0.417819082736969\n",
            "777: 0.43297743797302246\n",
            "778: 0.42061230540275574\n",
            "779: 0.4310888946056366\n",
            "780: 0.4362555742263794\n",
            "781: 0.41624653339385986\n",
            "782: 0.40529322624206543\n",
            "783: 0.4210543930530548\n",
            "784: 0.4039691388607025\n",
            "785: 0.4354795515537262\n",
            "786: 0.4151773452758789\n",
            "787: 0.4033339321613312\n",
            "788: 0.44180357456207275\n",
            "789: 0.4030832052230835\n",
            "790: 0.3992668390274048\n",
            "791: 0.40662556886672974\n",
            "792: 0.42039987444877625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|███████▉  | 796/1000 [00:40<00:10, 20.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "793: 0.41379356384277344\n",
            "794: 0.45035243034362793\n",
            "795: 0.4128963053226471\n",
            "796: 0.4848705530166626\n",
            "797: 0.4254271388053894\n",
            "798: 0.4633294343948364\n",
            "799: 0.5140081644058228\n",
            "800: 0.41193869709968567\n",
            "input:   tensor([[3, 5, 3, 2, 5, 4, 4, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 4, 5, 5, 3, 2, 4, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "801: 0.44204840064048767\n",
            "802: 0.43299371004104614\n",
            "803: 0.42469269037246704\n",
            "804: 0.42203593254089355\n",
            "805: 0.41315382719039917\n",
            "806: 0.41748276352882385\n",
            "807: 0.4136725068092346\n",
            "808: 0.4063330292701721\n",
            "809: 0.43636077642440796\n",
            "810: 0.3912659287452698\n",
            "811: 0.3918258845806122\n",
            "812: 0.40856438875198364\n",
            "813: 0.3970547914505005\n",
            "814: 0.40005868673324585\n",
            "815: 0.4193633198738098\n",
            "816: 0.39939355850219727\n",
            "817: 0.3844432532787323\n",
            "818: 0.42135173082351685\n",
            "819: 0.3968737721443176\n",
            "820: 0.4137842059135437\n",
            "821: 0.41121238470077515\n",
            "822: 0.3953211009502411\n",
            "823: 0.40992602705955505\n",
            "824: 0.38067492842674255\n",
            "825: 0.3965337872505188\n",
            "826: 0.44049733877182007\n",
            "827: 0.4151240289211273\n",
            "828: 0.42755326628685\n",
            "829: 0.4163810610771179\n",
            "830: 0.4205276072025299\n",
            "831: 0.39462971687316895\n",
            "832: 0.4405456483364105\n",
            "833: 0.4103050231933594\n",
            "834: 0.3985013961791992\n",
            "835: 0.39506661891937256\n",
            "836: 0.40023273229599\n",
            "837: 0.38723284006118774\n",
            "838: 0.380475252866745\n",
            "839: 0.40158966183662415\n",
            "840: 0.37959784269332886\n",
            "841: 0.3730632960796356\n",
            "842: 0.406646728515625\n",
            "843: 0.383441299200058\n",
            "844: 0.4108952283859253\n",
            "845: 0.39148250222206116\n",
            "846: 0.421886682510376\n",
            "847: 0.3921991288661957\n",
            "848: 0.3760859966278076\n",
            "849: 0.4116838872432709\n",
            "850: 0.3945026397705078\n",
            "851: 0.3758406639099121\n",
            "852: 0.415145605802536\n",
            "853: 0.39478349685668945\n",
            "854: 0.3964760899543762\n",
            "855: 0.3980511724948883\n",
            "856: 0.3929203450679779\n",
            "857: 0.38282766938209534\n",
            "858: 0.42062196135520935\n",
            "859: 0.3927565813064575\n",
            "860: 0.36661261320114136\n",
            "861: 0.3851999044418335\n",
            "862: 0.3965829908847809\n",
            "863: 0.4218127429485321\n",
            "864: 0.38043013215065\n",
            "865: 0.40957722067832947\n",
            "866: 0.4288386106491089\n",
            "867: 0.407511830329895\n",
            "868: 0.42380425333976746\n",
            "869: 0.38578179478645325\n",
            "870: 0.4173733592033386\n",
            "871: 0.41602692008018494\n",
            "872: 0.4392941892147064\n",
            "873: 0.40508678555488586\n",
            "874: 0.41507452726364136\n",
            "875: 0.41954347491264343\n",
            "876: 0.38376638293266296\n",
            "877: 0.41095155477523804\n",
            "878: 0.39086368680000305\n",
            "879: 0.36757147312164307\n",
            "880: 0.43868646025657654\n",
            "881: 0.3985539972782135\n",
            "882: 0.399524986743927\n",
            "883: 0.424324095249176\n",
            "884: 0.44256943464279175\n",
            "885: 0.3886164128780365\n",
            "886: 0.5148915648460388\n",
            "887: 0.400246262550354\n",
            "888: 0.43857285380363464\n",
            "889: 0.48520714044570923\n",
            "890: 0.39260637760162354\n",
            "891: 0.5024456977844238\n",
            "892: 0.4500562250614166\n",
            "893: 0.5646246671676636\n",
            "894: 0.40174248814582825\n",
            "895: 0.4485463798046112\n",
            "896: 0.41350507736206055\n",
            "897: 0.4297029674053192\n",
            "898: 0.4682653844356537\n",
            "899: 0.4554416239261627\n",
            "900: 0.42593178153038025\n",
            "input:   tensor([[4, 5, 2, 5, 3, 2, 2, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 2, 4, 3, 2, 2, 5, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "901: 0.41683515906333923\n",
            "902: 0.42673367261886597\n",
            "903: 0.42606934905052185\n",
            "904: 0.426658034324646\n",
            "905: 0.43242159485816956\n",
            "906: 0.4349803328514099\n",
            "907: 0.4286890923976898\n",
            "908: 0.4058651924133301\n",
            "909: 0.4084625840187073\n",
            "910: 0.3887067437171936\n",
            "911: 0.3887544274330139\n",
            "912: 0.44900304079055786\n",
            "913: 0.3842761516571045\n",
            "914: 0.4066668748855591\n",
            "915: 0.4061192572116852\n",
            "916: 0.3848356604576111\n",
            "917: 0.3949180543422699\n",
            "918: 0.39952296018600464\n",
            "919: 0.3590133786201477\n",
            "920: 0.394136905670166\n",
            "921: 0.390999972820282\n",
            "922: 0.40814971923828125\n",
            "923: 0.37492090463638306\n",
            "924: 0.41145724058151245\n",
            "925: 0.4088241755962372\n",
            "926: 0.40465065836906433\n",
            "927: 0.3908948302268982\n",
            "928: 0.4017907679080963\n",
            "929: 0.3567982614040375\n",
            "930: 0.37607064843177795\n",
            "931: 0.3944660425186157\n",
            "932: 0.4138692617416382\n",
            "933: 0.39246660470962524\n",
            "934: 0.3797474205493927\n",
            "935: 0.388521671295166\n",
            "936: 0.3750641644001007\n",
            "937: 0.37900882959365845\n",
            "938: 0.39311352372169495\n",
            "939: 0.3836984932422638\n",
            "940: 0.38452842831611633\n",
            "941: 0.3856056332588196\n",
            "942: 0.4019794762134552\n",
            "943: 0.37516504526138306\n",
            "944: 0.37481847405433655\n",
            "945: 0.3844752013683319\n",
            "946: 0.37652507424354553\n",
            "947: 0.39447513222694397\n",
            "948: 0.39266061782836914\n",
            "949: 0.38053277134895325\n",
            "950: 0.3885556161403656\n",
            "951: 0.39491915702819824\n",
            "952: 0.3843218982219696\n",
            "953: 0.35862043499946594\n",
            "954: 0.3612920939922333\n",
            "955: 0.3530789613723755\n",
            "956: 0.39576297998428345\n",
            "957: 0.3468876779079437\n",
            "958: 0.3862069845199585\n",
            "959: 0.39287784695625305\n",
            "960: 0.36821335554122925\n",
            "961: 0.3584136664867401\n",
            "962: 0.39081886410713196\n",
            "963: 0.3712448179721832\n",
            "964: 0.36994999647140503\n",
            "965: 0.363241046667099\n",
            "966: 0.3561893701553345\n",
            "967: 0.3538806438446045\n",
            "968: 0.3521461486816406\n",
            "969: 0.35292649269104004\n",
            "970: 0.36390870809555054\n",
            "971: 0.35319530963897705\n",
            "972: 0.3366568386554718\n",
            "973: 0.37677058577537537\n",
            "974: 0.36819425225257874\n",
            "975: 0.3484996259212494\n",
            "976: 0.3583644926548004\n",
            "977: 0.3638707399368286\n",
            "978: 0.3815702497959137\n",
            "979: 0.35383445024490356\n",
            "980: 0.3664509654045105\n",
            "981: 0.35643696784973145\n",
            "982: 0.35805782675743103\n",
            "983: 0.35951003432273865\n",
            "984: 0.384966641664505\n",
            "985: 0.3350525200366974\n",
            "986: 0.34767428040504456\n",
            "987: 0.3747061491012573\n",
            "988: 0.3631492555141449\n",
            "989: 0.38664937019348145\n",
            "990: 0.3515782058238983\n",
            "991: 0.3344966471195221\n",
            "992: 0.34087398648262024\n",
            "993: 0.3517143428325653\n",
            "994: 0.3905111849308014\n",
            "995: 0.34606456756591797\n",
            "996: 0.3726317286491394\n",
            "997: 0.36683130264282227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:50<00:00, 19.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998: 0.3704656660556793\n",
            "999: 0.38309988379478455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "fa6dfba0-8b9f-49e8-c327-7741919f4f85"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 81.25%\n"
          ]
        }
      ]
    }
  ]
}