{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "dfc08bfc-c71d-44b2-eb39-1660f0cff6b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "e37d56f9-5d61-4703-fdeb-08bf370ecc73"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2.797635078430176\n",
            "1: 2.4878015518188477\n",
            "2: 2.3340139389038086\n",
            "3: 2.2608416080474854\n",
            "4: 2.2459466457366943\n",
            "5: 2.199850559234619\n",
            "6: 2.2026562690734863\n",
            "7: 2.163006067276001\n",
            "8: 2.1598961353302\n",
            "9: 2.1393463611602783\n",
            "10: 2.1239266395568848\n",
            "11: 2.127950668334961\n",
            "12: 2.0992133617401123\n",
            "13: 2.135681629180908\n",
            "14: 2.0985476970672607\n",
            "15: 2.0787017345428467\n",
            "16: 2.058150291442871\n",
            "17: 2.069566249847412\n",
            "18: 2.0514683723449707\n",
            "19: 2.017598867416382\n",
            "20: 2.025083065032959\n",
            "21: 2.048281669616699\n",
            "22: 1.9812371730804443\n",
            "23: 2.0286498069763184\n",
            "24: 1.9859546422958374\n",
            "25: 2.005308151245117\n",
            "26: 2.0049960613250732\n",
            "27: 1.9866104125976562\n",
            "28: 2.0047099590301514\n",
            "29: 2.005924940109253\n",
            "30: 1.9846440553665161\n",
            "31: 1.960372805595398\n",
            "32: 1.972169280052185\n",
            "33: 1.952781319618225\n",
            "34: 1.9394750595092773\n",
            "35: 1.980185866355896\n",
            "36: 1.9445708990097046\n",
            "37: 1.9491454362869263\n",
            "38: 1.9554587602615356\n",
            "39: 1.9372355937957764\n",
            "40: 1.9379241466522217\n",
            "41: 1.8985792398452759\n",
            "42: 1.9272955656051636\n",
            "43: 1.9330424070358276\n",
            "44: 1.9191081523895264\n",
            "45: 1.9178719520568848\n",
            "46: 1.9267947673797607\n",
            "47: 1.9013383388519287\n",
            "48: 1.9077706336975098\n",
            "49: 1.9098433256149292\n",
            "50: 1.9298936128616333\n",
            "51: 1.9177495241165161\n",
            "52: 1.8947848081588745\n",
            "53: 1.924507975578308\n",
            "54: 1.8550249338150024\n",
            "55: 1.873559832572937\n",
            "56: 1.8332531452178955\n",
            "57: 1.8473140001296997\n",
            "58: 1.8761444091796875\n",
            "59: 1.8563951253890991\n",
            "60: 1.8180170059204102\n",
            "61: 1.8129597902297974\n",
            "62: 1.846484899520874\n",
            "63: 1.8253422975540161\n",
            "64: 1.8189738988876343\n",
            "65: 1.8179949522018433\n",
            "66: 1.8116248846054077\n",
            "67: 1.8009874820709229\n",
            "68: 1.8164429664611816\n",
            "69: 1.7784769535064697\n",
            "70: 1.7730929851531982\n",
            "71: 1.7795171737670898\n",
            "72: 1.77450430393219\n",
            "73: 1.7935364246368408\n",
            "74: 1.7620664834976196\n",
            "75: 1.7683651447296143\n",
            "76: 1.765247106552124\n",
            "77: 1.7594667673110962\n",
            "78: 1.7516050338745117\n",
            "79: 1.7739605903625488\n",
            "80: 1.7433782815933228\n",
            "81: 1.7569454908370972\n",
            "82: 1.7606964111328125\n",
            "83: 1.7428762912750244\n",
            "84: 1.7019658088684082\n",
            "85: 1.7670094966888428\n",
            "86: 1.7390891313552856\n",
            "87: 1.7087947130203247\n",
            "88: 1.7626335620880127\n",
            "89: 1.6927032470703125\n",
            "90: 1.720607042312622\n",
            "91: 1.7085309028625488\n",
            "92: 1.6733148097991943\n",
            "93: 1.7077064514160156\n",
            "94: 1.6907557249069214\n",
            "95: 1.707505702972412\n",
            "96: 1.67363703250885\n",
            "97: 1.6305334568023682\n",
            "98: 1.688252568244934\n",
            "99: 1.6833478212356567\n",
            "100: 1.6679182052612305\n",
            "input:   tensor([[5, 4, 3, 4, 5, 2, 2, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 2, 5, 4, 5, 4, 5, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "101: 1.663196086883545\n",
            "102: 1.6593122482299805\n",
            "103: 1.654196858406067\n",
            "104: 1.636191487312317\n",
            "105: 1.6607078313827515\n",
            "106: 1.6176151037216187\n",
            "107: 1.6630226373672485\n",
            "108: 1.6074272394180298\n",
            "109: 1.6477400064468384\n",
            "110: 1.6136445999145508\n",
            "111: 1.6084508895874023\n",
            "112: 1.6115285158157349\n",
            "113: 1.6203501224517822\n",
            "114: 1.5834286212921143\n",
            "115: 1.6313694715499878\n",
            "116: 1.6085566282272339\n",
            "117: 1.5878665447235107\n",
            "118: 1.6266098022460938\n",
            "119: 1.5710580348968506\n",
            "120: 1.596746563911438\n",
            "121: 1.5665299892425537\n",
            "122: 1.592459797859192\n",
            "123: 1.5678741931915283\n",
            "124: 1.6147215366363525\n",
            "125: 1.5336573123931885\n",
            "126: 1.5630104541778564\n",
            "127: 1.5608742237091064\n",
            "128: 1.5302071571350098\n",
            "129: 1.5595667362213135\n",
            "130: 1.5409446954727173\n",
            "131: 1.5187090635299683\n",
            "132: 1.5348113775253296\n",
            "133: 1.5340323448181152\n",
            "134: 1.5186097621917725\n",
            "135: 1.5254342555999756\n",
            "136: 1.5279510021209717\n",
            "137: 1.5212889909744263\n",
            "138: 1.5626574754714966\n",
            "139: 1.52653169631958\n",
            "140: 1.5222523212432861\n",
            "141: 1.5221226215362549\n",
            "142: 1.5170761346817017\n",
            "143: 1.4938372373580933\n",
            "144: 1.4615658521652222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  15%|█▍        | 148/1000 [00:10<00:57, 14.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "145: 1.4933606386184692\n",
            "146: 1.5532925128936768\n",
            "147: 1.5040174722671509\n",
            "148: 1.4859027862548828\n",
            "149: 1.5282752513885498\n",
            "150: 1.4666990041732788\n",
            "151: 1.4721544981002808\n",
            "152: 1.4638686180114746\n",
            "153: 1.4911365509033203\n",
            "154: 1.4735946655273438\n",
            "155: 1.4414175748825073\n",
            "156: 1.491284728050232\n",
            "157: 1.4260482788085938\n",
            "158: 1.4637525081634521\n",
            "159: 1.430141568183899\n",
            "160: 1.4627032279968262\n",
            "161: 1.4170596599578857\n",
            "162: 1.4647945165634155\n",
            "163: 1.4270256757736206\n",
            "164: 1.4089199304580688\n",
            "165: 1.4185672998428345\n",
            "166: 1.4489885568618774\n",
            "167: 1.3971130847930908\n",
            "168: 1.4531923532485962\n",
            "169: 1.443192481994629\n",
            "170: 1.4223392009735107\n",
            "171: 1.3937302827835083\n",
            "172: 1.4409198760986328\n",
            "173: 1.402637004852295\n",
            "174: 1.4010883569717407\n",
            "175: 1.4363696575164795\n",
            "176: 1.4160774946212769\n",
            "177: 1.404794692993164\n",
            "178: 1.3781437873840332\n",
            "179: 1.3960669040679932\n",
            "180: 1.3937376737594604\n",
            "181: 1.3869215250015259\n",
            "182: 1.398311972618103\n",
            "183: 1.358536720275879\n",
            "184: 1.3720898628234863\n",
            "185: 1.3311406373977661\n",
            "186: 1.3692959547042847\n",
            "187: 1.3467564582824707\n",
            "188: 1.3475948572158813\n",
            "189: 1.3669222593307495\n",
            "190: 1.3468714952468872\n",
            "191: 1.3305127620697021\n",
            "192: 1.31141996383667\n",
            "193: 1.34004807472229\n",
            "194: 1.3144097328186035\n",
            "195: 1.3228620290756226\n",
            "196: 1.3474382162094116\n",
            "197: 1.390129804611206\n",
            "198: 1.332140326499939\n",
            "199: 1.3981115818023682\n",
            "200: 1.3625593185424805\n",
            "input:   tensor([[4, 2, 5, 2, 4, 2, 3, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 2, 5, 4, 4, 3, 4, 4]], device='cuda:0')\n",
            "incorrects: 4\n",
            "201: 1.3364500999450684\n",
            "202: 1.3628089427947998\n",
            "203: 1.376476526260376\n",
            "204: 1.3219391107559204\n",
            "205: 1.356262445449829\n",
            "206: 1.3359423875808716\n",
            "207: 1.3221849203109741\n",
            "208: 1.292653203010559\n",
            "209: 1.3003389835357666\n",
            "210: 1.3193460702896118\n",
            "211: 1.2661815881729126\n",
            "212: 1.276281714439392\n",
            "213: 1.2937618494033813\n",
            "214: 1.255445957183838\n",
            "215: 1.2924401760101318\n",
            "216: 1.2464770078659058\n",
            "217: 1.204960823059082\n",
            "218: 1.2625104188919067\n",
            "219: 1.2333524227142334\n",
            "220: 1.234504222869873\n",
            "221: 1.252683401107788\n",
            "222: 1.307582139968872\n",
            "223: 1.2377421855926514\n",
            "224: 1.2337591648101807\n",
            "225: 1.2684260606765747\n",
            "226: 1.221558690071106\n",
            "227: 1.2431020736694336\n",
            "228: 1.2029063701629639\n",
            "229: 1.1745668649673462\n",
            "230: 1.2074124813079834\n",
            "231: 1.2231937646865845\n",
            "232: 1.204068899154663\n",
            "233: 1.2004928588867188\n",
            "234: 1.2460752725601196\n",
            "235: 1.1851845979690552\n",
            "236: 1.2108180522918701\n",
            "237: 1.2017347812652588\n",
            "238: 1.2178285121917725\n",
            "239: 1.2064716815948486\n",
            "240: 1.181749939918518\n",
            "241: 1.185721516609192\n",
            "242: 1.1621978282928467\n",
            "243: 1.212110161781311\n",
            "244: 1.1682847738265991\n",
            "245: 1.171392560005188\n",
            "246: 1.1925791501998901\n",
            "247: 1.1955019235610962\n",
            "248: 1.2158335447311401\n",
            "249: 1.1702561378479004\n",
            "250: 1.1422003507614136\n",
            "251: 1.139854907989502\n",
            "252: 1.188249111175537\n",
            "253: 1.188576340675354\n",
            "254: 1.2070589065551758\n",
            "255: 1.1338740587234497\n",
            "256: 1.1995971202850342\n",
            "257: 1.147876501083374\n",
            "258: 1.2081921100616455\n",
            "259: 1.0844666957855225\n",
            "260: 1.167368769645691\n",
            "261: 1.15801203250885\n",
            "262: 1.1603754758834839\n",
            "263: 1.1463494300842285\n",
            "264: 1.1266112327575684\n",
            "265: 1.1339161396026611\n",
            "266: 1.1191685199737549\n",
            "267: 1.1578361988067627\n",
            "268: 1.1216132640838623\n",
            "269: 1.165952444076538\n",
            "270: 1.09607994556427\n",
            "271: 1.0958055257797241\n",
            "272: 1.0810238122940063\n",
            "273: 1.130976915359497\n",
            "274: 1.1109848022460938\n",
            "275: 1.1106115579605103\n",
            "276: 1.1555216312408447\n",
            "277: 1.1084754467010498\n",
            "278: 1.1373308897018433\n",
            "279: 1.1851506233215332\n",
            "280: 1.0876816511154175\n",
            "281: 1.1515299081802368\n",
            "282: 1.0620527267456055\n",
            "283: 1.1185505390167236\n",
            "284: 1.0854418277740479\n",
            "285: 1.0903655290603638\n",
            "286: 1.0760153532028198\n",
            "287: 1.0778270959854126\n",
            "288: 1.0736594200134277\n",
            "289: 1.0645883083343506\n",
            "290: 1.0741586685180664\n",
            "291: 1.0479241609573364\n",
            "292: 1.0878729820251465\n",
            "293: 1.0400465726852417\n",
            "294: 1.0439852476119995\n",
            "295: 1.0480732917785645\n",
            "296: 1.047397255897522\n",
            "297: 1.0260865688323975\n",
            "298: 1.0250682830810547\n",
            "299: 1.0154534578323364\n",
            "300: 0.9844632148742676\n",
            "input:   tensor([[2, 3, 4, 3, 3, 3, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 3, 2, 3, 3, 4, 4, 3]], device='cuda:0')\n",
            "incorrects: 4\n",
            "301: 1.0566705465316772\n",
            "302: 1.0888278484344482\n",
            "303: 1.030333399772644\n",
            "304: 1.0412518978118896\n",
            "305: 1.0329134464263916\n",
            "306: 1.0278764963150024\n",
            "307: 1.0255825519561768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  31%|███       | 310/1000 [00:20<00:44, 15.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "308: 1.0146417617797852\n",
            "309: 1.0331388711929321\n",
            "310: 0.9841303825378418\n",
            "311: 1.039339303970337\n",
            "312: 0.9902533292770386\n",
            "313: 1.0149030685424805\n",
            "314: 0.964514970779419\n",
            "315: 1.055003046989441\n",
            "316: 0.9950140118598938\n",
            "317: 1.0058685541152954\n",
            "318: 0.9912046194076538\n",
            "319: 1.0110431909561157\n",
            "320: 0.9901937246322632\n",
            "321: 1.0050981044769287\n",
            "322: 0.9980780482292175\n",
            "323: 0.9876976013183594\n",
            "324: 0.9584865570068359\n",
            "325: 0.9742130637168884\n",
            "326: 1.0943330526351929\n",
            "327: 0.9888275861740112\n",
            "328: 1.0039036273956299\n",
            "329: 0.9838696718215942\n",
            "330: 0.9816551208496094\n",
            "331: 0.957250714302063\n",
            "332: 0.9352869391441345\n",
            "333: 0.9796928763389587\n",
            "334: 0.9751938581466675\n",
            "335: 0.9247007966041565\n",
            "336: 0.9066839814186096\n",
            "337: 0.9321062564849854\n",
            "338: 0.9432708621025085\n",
            "339: 0.9290735721588135\n",
            "340: 0.9565730094909668\n",
            "341: 0.9168662428855896\n",
            "342: 0.9496229290962219\n",
            "343: 0.9128372669219971\n",
            "344: 0.9782382249832153\n",
            "345: 0.908180296421051\n",
            "346: 0.8959537744522095\n",
            "347: 0.9523228406906128\n",
            "348: 0.8837871551513672\n",
            "349: 0.9672787189483643\n",
            "350: 0.9391204118728638\n",
            "351: 0.9587754011154175\n",
            "352: 0.8851302266120911\n",
            "353: 0.9082992076873779\n",
            "354: 0.8976605534553528\n",
            "355: 0.9413416981697083\n",
            "356: 0.8836062550544739\n",
            "357: 0.8806893825531006\n",
            "358: 0.8990795612335205\n",
            "359: 0.8682234287261963\n",
            "360: 0.981716513633728\n",
            "361: 0.8705079555511475\n",
            "362: 1.032754898071289\n",
            "363: 0.8761542439460754\n",
            "364: 0.9814159870147705\n",
            "365: 0.9490529298782349\n",
            "366: 0.9354763031005859\n",
            "367: 0.9044858813285828\n",
            "368: 0.9314208030700684\n",
            "369: 0.8951241970062256\n",
            "370: 0.8558328747749329\n",
            "371: 0.9217374324798584\n",
            "372: 0.8696271181106567\n",
            "373: 0.8842793703079224\n",
            "374: 0.8706090450286865\n",
            "375: 0.8713698387145996\n",
            "376: 0.8849563598632812\n",
            "377: 0.8487036824226379\n",
            "378: 0.8559205532073975\n",
            "379: 0.8414886593818665\n",
            "380: 0.8382432460784912\n",
            "381: 0.8448536992073059\n",
            "382: 0.8391334414482117\n",
            "383: 0.8399636745452881\n",
            "384: 0.7930042743682861\n",
            "385: 0.8262150883674622\n",
            "386: 0.851276695728302\n",
            "387: 0.7975152134895325\n",
            "388: 0.8227914571762085\n",
            "389: 0.83417147397995\n",
            "390: 0.7946857213973999\n",
            "391: 0.8445553183555603\n",
            "392: 0.837693452835083\n",
            "393: 0.8279561996459961\n",
            "394: 0.8858394026756287\n",
            "395: 0.7777264714241028\n",
            "396: 0.8856481909751892\n",
            "397: 0.7760343551635742\n",
            "398: 0.8062894344329834\n",
            "399: 0.8375685214996338\n",
            "400: 0.7992810010910034\n",
            "input:   tensor([[2, 5, 4, 5, 2, 2, 5, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 2, 5, 4, 5, 2, 5, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "401: 0.8108441829681396\n",
            "402: 0.8011809587478638\n",
            "403: 0.8408541083335876\n",
            "404: 0.8221089839935303\n",
            "405: 0.8138821721076965\n",
            "406: 0.7891392707824707\n",
            "407: 0.7975152730941772\n",
            "408: 0.8216404914855957\n",
            "409: 0.8196873068809509\n",
            "410: 0.8521516919136047\n",
            "411: 0.8002180457115173\n",
            "412: 0.8023790121078491\n",
            "413: 0.8004186749458313\n",
            "414: 0.8093249797821045\n",
            "415: 0.8026425242424011\n",
            "416: 0.7525002956390381\n",
            "417: 0.7603240013122559\n",
            "418: 0.761674702167511\n",
            "419: 0.7926388382911682\n",
            "420: 0.7905300855636597\n",
            "421: 0.7601256966590881\n",
            "422: 0.7752758860588074\n",
            "423: 0.766302764415741\n",
            "424: 0.7591476440429688\n",
            "425: 0.7469563484191895\n",
            "426: 0.760278582572937\n",
            "427: 0.75955730676651\n",
            "428: 0.7758949995040894\n",
            "429: 0.7294129729270935\n",
            "430: 0.7908602952957153\n",
            "431: 0.7558547258377075\n",
            "432: 0.7477571964263916\n",
            "433: 0.7976853251457214\n",
            "434: 0.8137206435203552\n",
            "435: 0.7663701176643372\n",
            "436: 0.8013924956321716\n",
            "437: 0.7699906229972839\n",
            "438: 0.7772396206855774\n",
            "439: 0.79156494140625\n",
            "440: 0.7713289260864258\n",
            "441: 0.7673203945159912\n",
            "442: 0.7838438153266907\n",
            "443: 0.7580869197845459\n",
            "444: 0.7222694158554077\n",
            "445: 0.7206953167915344\n",
            "446: 0.7147440314292908\n",
            "447: 0.6887509226799011\n",
            "448: 0.7536524534225464\n",
            "449: 0.7128728032112122\n",
            "450: 0.6842544078826904\n",
            "451: 0.7124806046485901\n",
            "452: 0.7001714110374451\n",
            "453: 0.7014858722686768\n",
            "454: 0.685556948184967\n",
            "455: 0.6771838068962097\n",
            "456: 0.6754061579704285\n",
            "457: 0.704693078994751\n",
            "458: 0.6691259741783142\n",
            "459: 0.6560063362121582\n",
            "460: 0.6622378826141357\n",
            "461: 0.6848040819168091\n",
            "462: 0.667730987071991\n",
            "463: 0.7050322890281677\n",
            "464: 0.7101591229438782\n",
            "465: 0.6648653745651245\n",
            "466: 0.676897406578064\n",
            "467: 0.6803485155105591\n",
            "468: 0.66401606798172\n",
            "469: 0.6865329742431641\n",
            "470: 0.6582409143447876\n",
            "471: 0.6921828389167786\n",
            "472: 0.6961802840232849\n",
            "473: 0.657874584197998\n",
            "474: 0.6819490790367126\n",
            "475: 0.6575588583946228\n",
            "476: 0.6417330503463745\n",
            "477: 0.6540743112564087\n",
            "478: 0.6588290333747864\n",
            "479: 0.6687098145484924\n",
            "480: 0.6555150151252747\n",
            "481: 0.6373960375785828\n",
            "482: 0.6312443017959595\n",
            "483: 0.6576088666915894\n",
            "484: 0.6455923914909363\n",
            "485: 0.6527761220932007\n",
            "486: 0.6646795868873596\n",
            "487: 0.6692361831665039\n",
            "488: 0.661933422088623\n",
            "489: 0.7847206592559814\n",
            "490: 0.7127994894981384\n",
            "491: 0.7395561337471008\n",
            "492: 0.6789924502372742\n",
            "493: 0.6857686638832092\n",
            "494: 0.6648359298706055\n",
            "495: 0.7015108466148376\n",
            "496: 0.7141772508621216\n",
            "497: 0.7064067721366882\n",
            "498: 0.695593535900116\n",
            "499: 0.6731045246124268\n",
            "500: 0.6946812868118286\n",
            "input:   tensor([[3, 4, 4, 3, 3, 4, 5, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 4, 3, 2, 4, 5, 4]], device='cuda:0')\n",
            "incorrects: 4\n",
            "501: 0.7154415845870972\n",
            "502: 0.6492617130279541\n",
            "503: 0.6751571297645569\n",
            "504: 0.7112303972244263\n",
            "505: 0.685269296169281\n",
            "506: 0.6769168376922607\n",
            "507: 0.7560910582542419\n",
            "508: 0.6558642983436584\n",
            "509: 0.6994351744651794\n",
            "510: 0.6337648034095764\n",
            "511: 0.7101802825927734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  52%|█████▏    | 516/1000 [00:30<00:27, 17.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512: 0.6090440154075623\n",
            "513: 0.6446576714515686\n",
            "514: 0.6527178883552551\n",
            "515: 0.6378310322761536\n",
            "516: 0.6468561291694641\n",
            "517: 0.6464178562164307\n",
            "518: 0.6493579149246216\n",
            "519: 0.6193405985832214\n",
            "520: 0.6219031810760498\n",
            "521: 0.61358642578125\n",
            "522: 0.6259344816207886\n",
            "523: 0.6075366139411926\n",
            "524: 0.621893048286438\n",
            "525: 0.6185920238494873\n",
            "526: 0.6025910973548889\n",
            "527: 0.58881676197052\n",
            "528: 0.5832171440124512\n",
            "529: 0.622134804725647\n",
            "530: 0.5740756988525391\n",
            "531: 0.5804957747459412\n",
            "532: 0.5853502750396729\n",
            "533: 0.5903634428977966\n",
            "534: 0.5802825689315796\n",
            "535: 0.5740465521812439\n",
            "536: 0.5740303993225098\n",
            "537: 0.6013234853744507\n",
            "538: 0.5929142832756042\n",
            "539: 0.5830521583557129\n",
            "540: 0.5711731314659119\n",
            "541: 0.5780900716781616\n",
            "542: 0.6113883852958679\n",
            "543: 0.5938930511474609\n",
            "544: 0.5975487232208252\n",
            "545: 0.5905042886734009\n",
            "546: 0.611792802810669\n",
            "547: 0.6165891289710999\n",
            "548: 0.6411629319190979\n",
            "549: 0.5778566598892212\n",
            "550: 0.6222193241119385\n",
            "551: 0.6198763847351074\n",
            "552: 0.5874467492103577\n",
            "553: 0.6095393300056458\n",
            "554: 0.6206524968147278\n",
            "555: 0.61708003282547\n",
            "556: 0.6084144115447998\n",
            "557: 0.6298028230667114\n",
            "558: 0.5989362597465515\n",
            "559: 0.6896843910217285\n",
            "560: 0.5737440586090088\n",
            "561: 0.6452937722206116\n",
            "562: 0.6180190443992615\n",
            "563: 0.6251235604286194\n",
            "564: 0.6498634815216064\n",
            "565: 0.5943548679351807\n",
            "566: 0.609170138835907\n",
            "567: 0.6275725960731506\n",
            "568: 0.5910755395889282\n",
            "569: 0.6307656168937683\n",
            "570: 0.6117502450942993\n",
            "571: 0.5858851671218872\n",
            "572: 0.6153357028961182\n",
            "573: 0.5914129018783569\n",
            "574: 0.5921134352684021\n",
            "575: 0.5608828067779541\n",
            "576: 0.5535405874252319\n",
            "577: 0.5639706254005432\n",
            "578: 0.543708860874176\n",
            "579: 0.5454796552658081\n",
            "580: 0.5342545509338379\n",
            "581: 0.5597663521766663\n",
            "582: 0.5636569261550903\n",
            "583: 0.578728437423706\n",
            "584: 0.5380889773368835\n",
            "585: 0.5457538962364197\n",
            "586: 0.5602256655693054\n",
            "587: 0.5377665758132935\n",
            "588: 0.5167044401168823\n",
            "589: 0.5636285543441772\n",
            "590: 0.543001115322113\n",
            "591: 0.5318214297294617\n",
            "592: 0.5416223406791687\n",
            "593: 0.540022611618042\n",
            "594: 0.5295068621635437\n",
            "595: 0.5137181282043457\n",
            "596: 0.523421049118042\n",
            "597: 0.5178397297859192\n",
            "598: 0.5398638844490051\n",
            "599: 0.5574871897697449\n",
            "600: 0.5798140168190002\n",
            "input:   tensor([[2, 4, 5, 5, 4, 3, 3, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 5, 2, 3, 2, 4, 3, 4]], device='cuda:0')\n",
            "incorrects: 7\n",
            "601: 0.543608546257019\n",
            "602: 0.5225872993469238\n",
            "603: 0.5909162759780884\n",
            "604: 0.5597086548805237\n",
            "605: 0.5582335591316223\n",
            "606: 0.5623687505722046\n",
            "607: 0.6120442748069763\n",
            "608: 0.5471780300140381\n",
            "609: 0.6126905679702759\n",
            "610: 0.553999125957489\n",
            "611: 0.5197519659996033\n",
            "612: 0.5709237456321716\n",
            "613: 0.553668200969696\n",
            "614: 0.5708866119384766\n",
            "615: 0.5233024954795837\n",
            "616: 0.5726003050804138\n",
            "617: 0.5548124313354492\n",
            "618: 0.5525900721549988\n",
            "619: 0.5304934978485107\n",
            "620: 0.47528931498527527\n",
            "621: 0.5422282218933105\n",
            "622: 0.5137406587600708\n",
            "623: 0.5269997119903564\n",
            "624: 0.5529270768165588\n",
            "625: 0.5344326496124268\n",
            "626: 0.5509965419769287\n",
            "627: 0.5120543241500854\n",
            "628: 0.5395817160606384\n",
            "629: 0.5049116015434265\n",
            "630: 0.5415895581245422\n",
            "631: 0.5116162300109863\n",
            "632: 0.5060415863990784\n",
            "633: 0.5141892433166504\n",
            "634: 0.5190577507019043\n",
            "635: 0.5027397871017456\n",
            "636: 0.5164952278137207\n",
            "637: 0.5247235894203186\n",
            "638: 0.5053734183311462\n",
            "639: 0.5276373624801636\n",
            "640: 0.518839418888092\n",
            "641: 0.5293554067611694\n",
            "642: 0.490272581577301\n",
            "643: 0.5012535452842712\n",
            "644: 0.4747188687324524\n",
            "645: 0.48315197229385376\n",
            "646: 0.501559853553772\n",
            "647: 0.49144837260246277\n",
            "648: 0.503379225730896\n",
            "649: 0.5312166213989258\n",
            "650: 0.49607086181640625\n",
            "651: 0.5179843902587891\n",
            "652: 0.4992983937263489\n",
            "653: 0.5190387964248657\n",
            "654: 0.46462613344192505\n",
            "655: 0.4952305853366852\n",
            "656: 0.5013787746429443\n",
            "657: 0.4819292724132538\n",
            "658: 0.4931827187538147\n",
            "659: 0.5017748475074768\n",
            "660: 0.496263325214386\n",
            "661: 0.48285186290740967\n",
            "662: 0.457396000623703\n",
            "663: 0.4864041209220886\n",
            "664: 0.4959757924079895\n",
            "665: 0.4784269630908966\n",
            "666: 0.48223912715911865\n",
            "667: 0.503190815448761\n",
            "668: 0.46561872959136963\n",
            "669: 0.4974469840526581\n",
            "670: 0.4869053363800049\n",
            "671: 0.4773084223270416\n",
            "672: 0.46274334192276\n",
            "673: 0.4927324950695038\n",
            "674: 0.4848994016647339\n",
            "675: 0.4796973466873169\n",
            "676: 0.4644046425819397\n",
            "677: 0.47773298621177673\n",
            "678: 0.4762688875198364\n",
            "679: 0.4633702039718628\n",
            "680: 0.4620547890663147\n",
            "681: 0.4635472297668457\n",
            "682: 0.4731009602546692\n",
            "683: 0.4711127281188965\n",
            "684: 0.44920921325683594\n",
            "685: 0.48549482226371765\n",
            "686: 0.46036943793296814\n",
            "687: 0.4618586599826813\n",
            "688: 0.4845528304576874\n",
            "689: 0.45249122381210327\n",
            "690: 0.4790204167366028\n",
            "691: 0.4681050777435303\n",
            "692: 0.4538944661617279\n",
            "693: 0.44407787919044495\n",
            "694: 0.46633172035217285\n",
            "695: 0.4433276653289795\n",
            "696: 0.45207223296165466\n",
            "697: 0.47471803426742554\n",
            "698: 0.4344724416732788\n",
            "699: 0.4454963505268097\n",
            "700: 0.4740985333919525\n",
            "input:   tensor([[4, 4, 2, 2, 3, 2, 2, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 2, 4, 4, 2, 3, 2, 4]], device='cuda:0')\n",
            "incorrects: 7\n",
            "701: 0.44770216941833496\n",
            "702: 0.47515788674354553\n",
            "703: 0.4503951370716095\n",
            "704: 0.45059123635292053\n",
            "705: 0.4464765191078186\n",
            "706: 0.45251935720443726\n",
            "707: 0.47698700428009033\n",
            "708: 0.46773016452789307\n",
            "709: 0.4661087989807129\n",
            "710: 0.4503791332244873\n",
            "711: 0.5038021802902222\n",
            "712: 0.4535454511642456\n",
            "713: 0.47825199365615845\n",
            "714: 0.48791494965553284\n",
            "715: 0.4602060616016388\n",
            "716: 0.489329993724823\n",
            "717: 0.5036181211471558\n",
            "718: 0.4968155026435852\n",
            "719: 0.42667239904403687\n",
            "720: 0.46872785687446594\n",
            "721: 0.4763295352458954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  73%|███████▎  | 726/1000 [00:40<00:14, 19.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "722: 0.4757784605026245\n",
            "723: 0.4587622582912445\n",
            "724: 0.4903657138347626\n",
            "725: 0.46297216415405273\n",
            "726: 0.4727136194705963\n",
            "727: 0.46477824449539185\n",
            "728: 0.46662795543670654\n",
            "729: 0.461911678314209\n",
            "730: 0.4800814688205719\n",
            "731: 0.5317946672439575\n",
            "732: 0.4379477798938751\n",
            "733: 0.5531448125839233\n",
            "734: 0.45533549785614014\n",
            "735: 0.4615228772163391\n",
            "736: 0.49226969480514526\n",
            "737: 0.4844951927661896\n",
            "738: 0.4831395149230957\n",
            "739: 0.47786587476730347\n",
            "740: 0.46215614676475525\n",
            "741: 0.4732614755630493\n",
            "742: 0.4989212453365326\n",
            "743: 0.4634529948234558\n",
            "744: 0.4943608343601227\n",
            "745: 0.4753184914588928\n",
            "746: 0.4943804144859314\n",
            "747: 0.4674665927886963\n",
            "748: 0.4204547703266144\n",
            "749: 0.45043930411338806\n",
            "750: 0.4941175580024719\n",
            "751: 0.46208351850509644\n",
            "752: 0.5044943690299988\n",
            "753: 0.4826430082321167\n",
            "754: 0.5478001236915588\n",
            "755: 0.47259631752967834\n",
            "756: 0.4651457369327545\n",
            "757: 0.5146099328994751\n",
            "758: 0.4639907777309418\n",
            "759: 0.5642129778862\n",
            "760: 0.46897342801094055\n",
            "761: 0.47310397028923035\n",
            "762: 0.4854135811328888\n",
            "763: 0.49245354533195496\n",
            "764: 0.47843658924102783\n",
            "765: 0.46501410007476807\n",
            "766: 0.4587855339050293\n",
            "767: 0.4782746732234955\n",
            "768: 0.46525102853775024\n",
            "769: 0.4626055955886841\n",
            "770: 0.4506617486476898\n",
            "771: 0.46335265040397644\n",
            "772: 0.4153924286365509\n",
            "773: 0.42847931385040283\n",
            "774: 0.43235039710998535\n",
            "775: 0.45614415407180786\n",
            "776: 0.442655473947525\n",
            "777: 0.4430980980396271\n",
            "778: 0.4311140477657318\n",
            "779: 0.4540199339389801\n",
            "780: 0.4238714575767517\n",
            "781: 0.4010554552078247\n",
            "782: 0.478044331073761\n",
            "783: 0.4267231523990631\n",
            "784: 0.4309282898902893\n",
            "785: 0.42663857340812683\n",
            "786: 0.4232582151889801\n",
            "787: 0.42322009801864624\n",
            "788: 0.46355095505714417\n",
            "789: 0.39909979701042175\n",
            "790: 0.44189453125\n",
            "791: 0.46011248230934143\n",
            "792: 0.41549113392829895\n",
            "793: 0.4246315658092499\n",
            "794: 0.42276543378829956\n",
            "795: 0.43622830510139465\n",
            "796: 0.4263160824775696\n",
            "797: 0.45945268869400024\n",
            "798: 0.4255223572254181\n",
            "799: 0.41794294118881226\n",
            "800: 0.4525419771671295\n",
            "input:   tensor([[3, 2, 2, 4, 2, 5, 5, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 5, 2, 3, 4, 2, 3, 5]], device='cuda:0')\n",
            "incorrects: 7\n",
            "801: 0.4395068883895874\n",
            "802: 0.4507657587528229\n",
            "803: 0.4401777982711792\n",
            "804: 0.4380999505519867\n",
            "805: 0.41821780800819397\n",
            "806: 0.43873271346092224\n",
            "807: 0.43106138706207275\n",
            "808: 0.40229320526123047\n",
            "809: 0.4487135708332062\n",
            "810: 0.411335289478302\n",
            "811: 0.3981676399707794\n",
            "812: 0.39791014790534973\n",
            "813: 0.40166839957237244\n",
            "814: 0.4410460591316223\n",
            "815: 0.41230762004852295\n",
            "816: 0.40970471501350403\n",
            "817: 0.419912189245224\n",
            "818: 0.40766361355781555\n",
            "819: 0.41349247097969055\n",
            "820: 0.412468820810318\n",
            "821: 0.4103195071220398\n",
            "822: 0.41916871070861816\n",
            "823: 0.40358003973960876\n",
            "824: 0.38725006580352783\n",
            "825: 0.45227110385894775\n",
            "826: 0.43572673201560974\n",
            "827: 0.4334924817085266\n",
            "828: 0.40325242280960083\n",
            "829: 0.41467106342315674\n",
            "830: 0.4438772201538086\n",
            "831: 0.4655437469482422\n",
            "832: 0.3980115056037903\n",
            "833: 0.5395351052284241\n",
            "834: 0.7152246832847595\n",
            "835: 0.6932856440544128\n",
            "836: 0.6178553700447083\n",
            "837: 0.6401211023330688\n",
            "838: 0.6977935433387756\n",
            "839: 0.5885095000267029\n",
            "840: 0.5766118764877319\n",
            "841: 0.5282143354415894\n",
            "842: 0.5452089309692383\n",
            "843: 0.5318378210067749\n",
            "844: 0.5776578187942505\n",
            "845: 0.5327360033988953\n",
            "846: 0.5318608283996582\n",
            "847: 0.49731895327568054\n",
            "848: 0.4992287755012512\n",
            "849: 0.4874088764190674\n",
            "850: 0.4510664641857147\n",
            "851: 0.4348573684692383\n",
            "852: 0.4584191143512726\n",
            "853: 0.4609793722629547\n",
            "854: 0.46507593989372253\n",
            "855: 0.494494765996933\n",
            "856: 0.4388498365879059\n",
            "857: 0.43464040756225586\n",
            "858: 0.45052093267440796\n",
            "859: 0.4286579191684723\n",
            "860: 0.4198204278945923\n",
            "861: 0.43814408779144287\n",
            "862: 0.4660317003726959\n",
            "863: 0.45032742619514465\n",
            "864: 0.429428368806839\n",
            "865: 0.44774165749549866\n",
            "866: 0.43110018968582153\n",
            "867: 0.40711909532546997\n",
            "868: 0.40283942222595215\n",
            "869: 0.4309016168117523\n",
            "870: 0.44028958678245544\n",
            "871: 0.43206921219825745\n",
            "872: 0.4084678590297699\n",
            "873: 0.41957056522369385\n",
            "874: 0.4170290231704712\n",
            "875: 0.402500718832016\n",
            "876: 0.4179273247718811\n",
            "877: 0.40836673974990845\n",
            "878: 0.42553311586380005\n",
            "879: 0.45940110087394714\n",
            "880: 0.40589094161987305\n",
            "881: 0.39769309759140015\n",
            "882: 0.4443454146385193\n",
            "883: 0.41414040327072144\n",
            "884: 0.4324757158756256\n",
            "885: 0.4108193516731262\n",
            "886: 0.39774614572525024\n",
            "887: 0.4063689708709717\n",
            "888: 0.4078677296638489\n",
            "889: 0.39770081639289856\n",
            "890: 0.47255709767341614\n",
            "891: 0.3819322884082794\n",
            "892: 0.4191339910030365\n",
            "893: 0.4651985764503479\n",
            "894: 0.4491260051727295\n",
            "895: 0.4017331600189209\n",
            "896: 0.40112796425819397\n",
            "897: 0.43930599093437195\n",
            "898: 0.4140075147151947\n",
            "899: 0.4142884910106659\n",
            "900: 0.40230610966682434\n",
            "input:   tensor([[2, 5, 5, 5, 5, 2, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 2, 5, 5, 2, 3, 3, 5]], device='cuda:0')\n",
            "incorrects: 5\n",
            "901: 0.4331699013710022\n",
            "902: 0.43565627932548523\n",
            "903: 0.40241608023643494\n",
            "904: 0.4207291901111603\n",
            "905: 0.3848799765110016\n",
            "906: 0.4035695195198059\n",
            "907: 0.4281240701675415\n",
            "908: 0.37296172976493835\n",
            "909: 0.3865851163864136\n",
            "910: 0.39886054396629333\n",
            "911: 0.44746845960617065\n",
            "912: 0.36771634221076965\n",
            "913: 0.4241477847099304\n",
            "914: 0.3950035870075226\n",
            "915: 0.40163716673851013\n",
            "916: 0.41775861382484436\n",
            "917: 0.37152865529060364\n",
            "918: 0.36279577016830444\n",
            "919: 0.39462971687316895\n",
            "920: 0.38332176208496094\n",
            "921: 0.3967829942703247\n",
            "922: 0.4391597807407379\n",
            "923: 0.3617810010910034\n",
            "924: 0.3783724308013916\n",
            "925: 0.39728468656539917\n",
            "926: 0.3997832238674164\n",
            "927: 0.3707481622695923\n",
            "928: 0.35616591572761536\n",
            "929: 0.39345091581344604\n",
            "930: 0.3782549798488617\n",
            "931: 0.3548751473426819\n",
            "932: 0.3857620060443878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  94%|█████████▎| 936/1000 [00:50<00:03, 19.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "933: 0.38110414147377014\n",
            "934: 0.3869953453540802\n",
            "935: 0.36288371682167053\n",
            "936: 0.3652299642562866\n",
            "937: 0.3955049514770508\n",
            "938: 0.4198540151119232\n",
            "939: 0.416943222284317\n",
            "940: 0.4016740918159485\n",
            "941: 0.3932243287563324\n",
            "942: 0.36744314432144165\n",
            "943: 0.42825859785079956\n",
            "944: 0.378195583820343\n",
            "945: 0.3975553810596466\n",
            "946: 0.39388197660446167\n",
            "947: 0.3940126895904541\n",
            "948: 0.4037431478500366\n",
            "949: 0.389197438955307\n",
            "950: 0.38490474224090576\n",
            "951: 0.3487967252731323\n",
            "952: 0.36680731177330017\n",
            "953: 0.38446107506752014\n",
            "954: 0.3785320222377777\n",
            "955: 0.3767951726913452\n",
            "956: 0.3721362352371216\n",
            "957: 0.36923813819885254\n",
            "958: 0.38836953043937683\n",
            "959: 0.373357892036438\n",
            "960: 0.39260411262512207\n",
            "961: 0.3516077399253845\n",
            "962: 0.37776148319244385\n",
            "963: 0.37694621086120605\n",
            "964: 0.36616280674934387\n",
            "965: 0.3600388467311859\n",
            "966: 0.3671846389770508\n",
            "967: 0.40030115842819214\n",
            "968: 0.39550328254699707\n",
            "969: 0.41785430908203125\n",
            "970: 0.37128469347953796\n",
            "971: 0.44521546363830566\n",
            "972: 0.36867645382881165\n",
            "973: 0.4339306354522705\n",
            "974: 0.3841826021671295\n",
            "975: 0.37750351428985596\n",
            "976: 0.36715036630630493\n",
            "977: 0.39041703939437866\n",
            "978: 0.39864879846572876\n",
            "979: 0.4593023359775543\n",
            "980: 0.40014487504959106\n",
            "981: 0.43762046098709106\n",
            "982: 0.37773072719573975\n",
            "983: 0.4332429766654968\n",
            "984: 0.46988534927368164\n",
            "985: 0.4132923185825348\n",
            "986: 0.4055737853050232\n",
            "987: 0.387282133102417\n",
            "988: 0.40624743700027466\n",
            "989: 0.3813459575176239\n",
            "990: 0.38906189799308777\n",
            "991: 0.37105631828308105\n",
            "992: 0.37371525168418884\n",
            "993: 0.378240168094635\n",
            "994: 0.3765147626399994\n",
            "995: 0.37997645139694214\n",
            "996: 0.38364240527153015\n",
            "997: 0.3918781876564026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:53<00:00, 18.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "998: 0.41865459084510803\n",
            "999: 0.382826030254364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "85c3fb09-2166-4b24-ea18-786ab9e4dcaa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 84.375%\n"
          ]
        }
      ]
    }
  ]
}