{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "8373cfd1-6346-4a15-aee2-b289e5d0313b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "d34ba9e6-0700-4b3e-9dbf-0f5d2fd59010"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 3.401230573654175\n",
            "1: 2.501105785369873\n",
            "2: 2.297044277191162\n",
            "3: 2.1846704483032227\n",
            "4: 2.129467248916626\n",
            "5: 2.1679232120513916\n",
            "6: 2.087216854095459\n",
            "7: 2.1017708778381348\n",
            "8: 2.1031064987182617\n",
            "9: 2.050971031188965\n",
            "10: 2.0831520557403564\n",
            "11: 2.0753841400146484\n",
            "12: 2.022801399230957\n",
            "13: 2.0084080696105957\n",
            "14: 2.0599286556243896\n",
            "15: 2.0332210063934326\n",
            "16: 2.0613362789154053\n",
            "17: 2.041513681411743\n",
            "18: 2.0077953338623047\n",
            "19: 2.021064519882202\n",
            "20: 1.9977418184280396\n",
            "21: 1.9609863758087158\n",
            "22: 1.9783103466033936\n",
            "23: 1.9388624429702759\n",
            "24: 1.9403854608535767\n",
            "25: 2.0045292377471924\n",
            "26: 1.9563367366790771\n",
            "27: 1.9620602130889893\n",
            "28: 1.9475752115249634\n",
            "29: 1.9410171508789062\n",
            "30: 1.9085379838943481\n",
            "31: 1.909257411956787\n",
            "32: 1.8879634141921997\n",
            "33: 1.8992094993591309\n",
            "34: 1.8715054988861084\n",
            "35: 1.9083049297332764\n",
            "36: 1.882127046585083\n",
            "37: 1.8411362171173096\n",
            "38: 1.8801289796829224\n",
            "39: 1.8911769390106201\n",
            "40: 1.8719515800476074\n",
            "41: 1.8532606363296509\n",
            "42: 1.8339948654174805\n",
            "43: 1.8774776458740234\n",
            "44: 1.779306411743164\n",
            "45: 1.8869844675064087\n",
            "46: 1.8394546508789062\n",
            "47: 1.8628419637680054\n",
            "48: 1.8327058553695679\n",
            "49: 1.8267768621444702\n",
            "50: 1.8221136331558228\n",
            "51: 1.820665955543518\n",
            "52: 1.8161084651947021\n",
            "53: 1.8259156942367554\n",
            "54: 1.827425241470337\n",
            "55: 1.7598055601119995\n",
            "56: 1.7815558910369873\n",
            "57: 1.7815229892730713\n",
            "58: 1.7606096267700195\n",
            "59: 1.799823522567749\n",
            "60: 1.7571115493774414\n",
            "61: 1.7856677770614624\n",
            "62: 1.792188048362732\n",
            "63: 1.8132894039154053\n",
            "64: 1.7471184730529785\n",
            "65: 1.75337815284729\n",
            "66: 1.765199065208435\n",
            "67: 1.7220454216003418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   7%|▋         | 70/1000 [00:10<02:13,  6.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68: 1.773900032043457\n",
            "69: 1.7292231321334839\n",
            "70: 1.7478266954421997\n",
            "71: 1.7454346418380737\n",
            "72: 1.7269299030303955\n",
            "73: 1.6844974756240845\n",
            "74: 1.7509827613830566\n",
            "75: 1.7369378805160522\n",
            "76: 1.7060917615890503\n",
            "77: 1.7143645286560059\n",
            "78: 1.7413281202316284\n",
            "79: 1.6951066255569458\n",
            "80: 1.70162832736969\n",
            "81: 1.7380344867706299\n",
            "82: 1.7289066314697266\n",
            "83: 1.687938928604126\n",
            "84: 1.6519581079483032\n",
            "85: 1.6598811149597168\n",
            "86: 1.6467138528823853\n",
            "87: 1.67922043800354\n",
            "88: 1.6297913789749146\n",
            "89: 1.6798005104064941\n",
            "90: 1.6523131132125854\n",
            "91: 1.6861127614974976\n",
            "92: 1.6443918943405151\n",
            "93: 1.6947553157806396\n",
            "94: 1.6525758504867554\n",
            "95: 1.6823093891143799\n",
            "96: 1.6445993185043335\n",
            "97: 1.6499935388565063\n",
            "98: 1.6348520517349243\n",
            "99: 1.6436207294464111\n",
            "100: 1.6597812175750732\n",
            "input:   tensor([[2, 5, 4, 2, 2, 3, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 2, 2, 3, 2, 2, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "101: 1.6430368423461914\n",
            "102: 1.6093084812164307\n",
            "103: 1.6468071937561035\n",
            "104: 1.6263577938079834\n",
            "105: 1.6216521263122559\n",
            "106: 1.612839937210083\n",
            "107: 1.6236035823822021\n",
            "108: 1.609344482421875\n",
            "109: 1.5848990678787231\n",
            "110: 1.588586449623108\n",
            "111: 1.5980186462402344\n",
            "112: 1.5717781782150269\n",
            "113: 1.6374064683914185\n",
            "114: 1.6028650999069214\n",
            "115: 1.5348472595214844\n",
            "116: 1.5651689767837524\n",
            "117: 1.5665432214736938\n",
            "118: 1.572213888168335\n",
            "119: 1.5330252647399902\n",
            "120: 1.5755854845046997\n",
            "121: 1.5405747890472412\n",
            "122: 1.5637023448944092\n",
            "123: 1.536534309387207\n",
            "124: 1.5703092813491821\n",
            "125: 1.5048980712890625\n",
            "126: 1.561663269996643\n",
            "127: 1.5268275737762451\n",
            "128: 1.4991447925567627\n",
            "129: 1.5438287258148193\n",
            "130: 1.523136854171753\n",
            "131: 1.5346651077270508\n",
            "132: 1.4960319995880127\n",
            "133: 1.537734031677246\n",
            "134: 1.5107673406600952\n",
            "135: 1.5040864944458008\n",
            "136: 1.5113811492919922\n",
            "137: 1.4415110349655151\n",
            "138: 1.5184195041656494\n",
            "139: 1.4836219549179077\n",
            "140: 1.5193591117858887\n",
            "141: 1.451005458831787\n",
            "142: 1.4458060264587402\n",
            "143: 1.4611666202545166\n",
            "144: 1.4496243000030518\n",
            "145: 1.4674657583236694\n",
            "146: 1.4661699533462524\n",
            "147: 1.4441190958023071\n",
            "148: 1.4548474550247192\n",
            "149: 1.4497894048690796\n",
            "150: 1.4603450298309326\n",
            "151: 1.4299266338348389\n",
            "152: 1.4648598432540894\n",
            "153: 1.459356427192688\n",
            "154: 1.4563897848129272\n",
            "155: 1.4257595539093018\n",
            "156: 1.4732186794281006\n",
            "157: 1.4394934177398682\n",
            "158: 1.4559500217437744\n",
            "159: 1.4503405094146729\n",
            "160: 1.4110796451568604\n",
            "161: 1.4068882465362549\n",
            "162: 1.4117920398712158\n",
            "163: 1.3892868757247925\n",
            "164: 1.4374343156814575\n",
            "165: 1.439660906791687\n",
            "166: 1.412376880645752\n",
            "167: 1.411167025566101\n",
            "168: 1.3855698108673096\n",
            "169: 1.4012621641159058\n",
            "170: 1.373538851737976\n",
            "171: 1.402014970779419\n",
            "172: 1.4266126155853271\n",
            "173: 1.4034878015518188\n",
            "174: 1.3593494892120361\n",
            "175: 1.3406345844268799\n",
            "176: 1.3622105121612549\n",
            "177: 1.3786543607711792\n",
            "178: 1.3646987676620483\n",
            "179: 1.372795820236206\n",
            "180: 1.3754093647003174\n",
            "181: 1.3263541460037231\n",
            "182: 1.3722323179244995\n",
            "183: 1.365760326385498\n",
            "184: 1.3192723989486694\n",
            "185: 1.3230277299880981\n",
            "186: 1.2720152139663696\n",
            "187: 1.310965895652771\n",
            "188: 1.2943798303604126\n",
            "189: 1.315218448638916\n",
            "190: 1.357302188873291\n",
            "191: 1.4186789989471436\n",
            "192: 1.3775237798690796\n",
            "193: 1.3717503547668457\n",
            "194: 1.3483015298843384\n",
            "195: 1.376661777496338\n",
            "196: 1.3372126817703247\n",
            "197: 1.353366732597351\n",
            "198: 1.2876954078674316\n",
            "199: 1.3234962224960327\n",
            "200: 1.346349835395813\n",
            "input:   tensor([[3, 5, 4, 2, 2, 4, 5, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 4, 2, 2, 3, 5, 4]], device='cuda:0')\n",
            "incorrects: 2\n",
            "201: 1.3406422138214111\n",
            "202: 1.2789043188095093\n",
            "203: 1.3209530115127563\n",
            "204: 1.2685329914093018\n",
            "205: 1.252256989479065\n",
            "206: 1.3089745044708252\n",
            "207: 1.296912431716919\n",
            "208: 1.260789155960083\n",
            "209: 1.3078258037567139\n",
            "210: 1.2643064260482788\n",
            "211: 1.3080334663391113\n",
            "212: 1.2321317195892334\n",
            "213: 1.3333067893981934\n",
            "214: 1.2598438262939453\n",
            "215: 1.20346200466156\n",
            "216: 1.28227961063385\n",
            "217: 1.2827024459838867\n",
            "218: 1.2659093141555786\n",
            "219: 1.2715203762054443\n",
            "220: 1.2243198156356812\n",
            "221: 1.2353092432022095\n",
            "222: 1.2276084423065186\n",
            "223: 1.170575737953186\n",
            "224: 1.234344482421875\n",
            "225: 1.198609471321106\n",
            "226: 1.182094693183899\n",
            "227: 1.158616304397583\n",
            "228: 1.2857753038406372\n",
            "229: 1.230352520942688\n",
            "230: 1.223617434501648\n",
            "231: 1.1598392724990845\n",
            "232: 1.2012696266174316\n",
            "233: 1.1598830223083496\n",
            "234: 1.185749888420105\n",
            "235: 1.1351103782653809\n",
            "236: 1.1557427644729614\n",
            "237: 1.1194522380828857\n",
            "238: 1.1318317651748657\n",
            "239: 1.1306593418121338\n",
            "240: 1.191848874092102\n",
            "241: 1.1629688739776611\n",
            "242: 1.156381607055664\n",
            "243: 1.1016688346862793\n",
            "244: 1.1060409545898438\n",
            "245: 1.1369634866714478\n",
            "246: 1.097595453262329\n",
            "247: 1.1200872659683228\n",
            "248: 1.1018701791763306\n",
            "249: 1.1613118648529053\n",
            "250: 1.1262933015823364\n",
            "251: 1.1005760431289673\n",
            "252: 1.0860662460327148\n",
            "253: 1.0790115594863892\n",
            "254: 1.137725591659546\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  26%|██▌       | 256/1000 [00:20<00:54, 13.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255: 1.073627233505249\n",
            "256: 1.0953989028930664\n",
            "257: 1.05478036403656\n",
            "258: 1.0248057842254639\n",
            "259: 1.0761349201202393\n",
            "260: 1.105521559715271\n",
            "261: 1.1185745000839233\n",
            "262: 1.049312710762024\n",
            "263: 1.1157252788543701\n",
            "264: 1.0609345436096191\n",
            "265: 1.0596975088119507\n",
            "266: 1.057810664176941\n",
            "267: 1.0844955444335938\n",
            "268: 1.0535106658935547\n",
            "269: 1.0609862804412842\n",
            "270: 1.0604703426361084\n",
            "271: 1.0180641412734985\n",
            "272: 1.0786901712417603\n",
            "273: 1.031104326248169\n",
            "274: 1.0650688409805298\n",
            "275: 1.0364155769348145\n",
            "276: 1.003841757774353\n",
            "277: 1.07004976272583\n",
            "278: 1.0187362432479858\n",
            "279: 1.0586304664611816\n",
            "280: 1.0625107288360596\n",
            "281: 1.0498508214950562\n",
            "282: 1.006453275680542\n",
            "283: 1.0594245195388794\n",
            "284: 1.0526318550109863\n",
            "285: 1.0124506950378418\n",
            "286: 1.0291630029678345\n",
            "287: 1.0335675477981567\n",
            "288: 1.0132248401641846\n",
            "289: 1.0444321632385254\n",
            "290: 0.9814149141311646\n",
            "291: 0.9597742557525635\n",
            "292: 1.0303080081939697\n",
            "293: 0.9731603860855103\n",
            "294: 1.0139151811599731\n",
            "295: 1.0369181632995605\n",
            "296: 1.0042468309402466\n",
            "297: 0.9924148917198181\n",
            "298: 0.998909056186676\n",
            "299: 0.9754152297973633\n",
            "300: 0.9610622525215149\n",
            "input:   tensor([[3, 3, 5, 2, 3, 4, 4, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 2, 4, 5, 3, 3, 3]], device='cuda:0')\n",
            "incorrects: 7\n",
            "301: 0.924872100353241\n",
            "302: 0.9496740102767944\n",
            "303: 0.9177226424217224\n",
            "304: 0.9406644701957703\n",
            "305: 0.9317037463188171\n",
            "306: 0.9064292311668396\n",
            "307: 0.944009006023407\n",
            "308: 0.965475857257843\n",
            "309: 0.9563344717025757\n",
            "310: 0.9460307359695435\n",
            "311: 0.9105210304260254\n",
            "312: 0.9785699844360352\n",
            "313: 0.9002246856689453\n",
            "314: 0.879555344581604\n",
            "315: 0.9099361896514893\n",
            "316: 0.906552255153656\n",
            "317: 0.928541898727417\n",
            "318: 0.9119735956192017\n",
            "319: 0.9304415583610535\n",
            "320: 0.9046165943145752\n",
            "321: 0.9568852186203003\n",
            "322: 0.9081856608390808\n",
            "323: 0.9620550870895386\n",
            "324: 0.8808863162994385\n",
            "325: 0.8976068496704102\n",
            "326: 0.8755182027816772\n",
            "327: 0.8768789768218994\n",
            "328: 0.8961904644966125\n",
            "329: 0.9025495648384094\n",
            "330: 0.8395304083824158\n",
            "331: 0.8635475635528564\n",
            "332: 0.8333392143249512\n",
            "333: 0.8710780143737793\n",
            "334: 0.8480966687202454\n",
            "335: 0.8407554030418396\n",
            "336: 0.8721115589141846\n",
            "337: 0.8485469222068787\n",
            "338: 0.8411387801170349\n",
            "339: 0.8263204097747803\n",
            "340: 0.8445210456848145\n",
            "341: 0.823593258857727\n",
            "342: 0.8197031021118164\n",
            "343: 0.8346452116966248\n",
            "344: 0.8197975754737854\n",
            "345: 0.8166790008544922\n",
            "346: 0.847133219242096\n",
            "347: 0.8222509622573853\n",
            "348: 0.8434855341911316\n",
            "349: 0.7633118629455566\n",
            "350: 0.8117172718048096\n",
            "351: 0.7714542150497437\n",
            "352: 0.8567072153091431\n",
            "353: 0.8157654404640198\n",
            "354: 0.8239299654960632\n",
            "355: 0.7963351011276245\n",
            "356: 0.7947908639907837\n",
            "357: 0.7766339182853699\n",
            "358: 0.8193386793136597\n",
            "359: 0.809337854385376\n",
            "360: 0.7982805967330933\n",
            "361: 0.7970249652862549\n",
            "362: 0.8001135587692261\n",
            "363: 0.7935935258865356\n",
            "364: 0.8070064187049866\n",
            "365: 0.8731924891471863\n",
            "366: 0.8354626297950745\n",
            "367: 0.8471555709838867\n",
            "368: 0.851277768611908\n",
            "369: 0.7700876593589783\n",
            "370: 0.8300706744194031\n",
            "371: 0.748598039150238\n",
            "372: 0.822458803653717\n",
            "373: 0.7832980155944824\n",
            "374: 0.7770887017250061\n",
            "375: 0.7689826488494873\n",
            "376: 0.7554378509521484\n",
            "377: 0.7607587575912476\n",
            "378: 0.8386636972427368\n",
            "379: 0.7322524189949036\n",
            "380: 0.7566205859184265\n",
            "381: 0.7705361843109131\n",
            "382: 0.7495502233505249\n",
            "383: 0.7738282084465027\n",
            "384: 0.7596234083175659\n",
            "385: 0.7604938745498657\n",
            "386: 0.7829930782318115\n",
            "387: 0.7730184197425842\n",
            "388: 0.7628511786460876\n",
            "389: 0.7433561086654663\n",
            "390: 0.7622830271720886\n",
            "391: 0.7640567421913147\n",
            "392: 0.6994403004646301\n",
            "393: 0.7221776247024536\n",
            "394: 0.7507570385932922\n",
            "395: 0.7305218577384949\n",
            "396: 0.7318046689033508\n",
            "397: 0.6860538721084595\n",
            "398: 0.7010729908943176\n",
            "399: 0.6967256665229797\n",
            "400: 0.7443158030509949\n",
            "input:   tensor([[2, 5, 2, 3, 4, 5, 2, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 2, 5, 3, 4, 2, 5, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "401: 0.7405977249145508\n",
            "402: 0.6777902245521545\n",
            "403: 0.7071245908737183\n",
            "404: 0.6936393976211548\n",
            "405: 0.7181904315948486\n",
            "406: 0.7225036025047302\n",
            "407: 0.7294556498527527\n",
            "408: 0.6938565969467163\n",
            "409: 0.7464611530303955\n",
            "410: 0.7566613554954529\n",
            "411: 0.7480515241622925\n",
            "412: 0.7302942276000977\n",
            "413: 0.8133362531661987\n",
            "414: 0.6824917197227478\n",
            "415: 0.752511739730835\n",
            "416: 0.7265724539756775\n",
            "417: 0.6984829902648926\n",
            "418: 0.7549765706062317\n",
            "419: 0.7361408472061157\n",
            "420: 0.6640109419822693\n",
            "421: 0.7281951904296875\n",
            "422: 0.7147817611694336\n",
            "423: 0.7121633291244507\n",
            "424: 0.7199737429618835\n",
            "425: 0.7053889632225037\n",
            "426: 0.6551018953323364\n",
            "427: 0.7020571231842041\n",
            "428: 0.6900842785835266\n",
            "429: 0.6573938131332397\n",
            "430: 0.6822495460510254\n",
            "431: 0.6894816160202026\n",
            "432: 0.6982558369636536\n",
            "433: 0.6841532588005066\n",
            "434: 0.6956058740615845\n",
            "435: 0.6538287997245789\n",
            "436: 0.6358428001403809\n",
            "437: 0.6483004093170166\n",
            "438: 0.672186017036438\n",
            "439: 0.6640051603317261\n",
            "440: 0.6462385058403015\n",
            "441: 0.6375194787979126\n",
            "442: 0.6372511982917786\n",
            "443: 0.6302441954612732\n",
            "444: 0.6979513168334961\n",
            "445: 0.6137464642524719\n",
            "446: 0.6466752886772156\n",
            "447: 0.6330797076225281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  45%|████▌     | 451/1000 [00:30<00:33, 16.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448: 0.645434558391571\n",
            "449: 0.6029922962188721\n",
            "450: 0.6284847855567932\n",
            "451: 0.6422280669212341\n",
            "452: 0.7015345692634583\n",
            "453: 0.5959850549697876\n",
            "454: 0.6938579678535461\n",
            "455: 0.629040002822876\n",
            "456: 0.6348475813865662\n",
            "457: 0.6208232045173645\n",
            "458: 0.6821888089179993\n",
            "459: 0.6241246461868286\n",
            "460: 0.7374354600906372\n",
            "461: 0.6307433247566223\n",
            "462: 0.6618214249610901\n",
            "463: 0.6515529751777649\n",
            "464: 0.6544589996337891\n",
            "465: 0.6120071411132812\n",
            "466: 0.6452041864395142\n",
            "467: 0.6638752222061157\n",
            "468: 0.5989445447921753\n",
            "469: 0.6230584383010864\n",
            "470: 0.6899414658546448\n",
            "471: 0.6993363499641418\n",
            "472: 0.668201208114624\n",
            "473: 0.6699269413948059\n",
            "474: 0.6385456919670105\n",
            "475: 0.6635546088218689\n",
            "476: 0.6356886625289917\n",
            "477: 0.6287006735801697\n",
            "478: 0.6716015934944153\n",
            "479: 0.6714935302734375\n",
            "480: 0.6050931811332703\n",
            "481: 0.6324937343597412\n",
            "482: 0.6313937306404114\n",
            "483: 0.6149828433990479\n",
            "484: 0.614185094833374\n",
            "485: 0.6166908740997314\n",
            "486: 0.6269984245300293\n",
            "487: 0.6151638031005859\n",
            "488: 0.6150819659233093\n",
            "489: 0.5626185536384583\n",
            "490: 0.585060715675354\n",
            "491: 0.6273271441459656\n",
            "492: 0.6133890151977539\n",
            "493: 0.595209002494812\n",
            "494: 0.5839119553565979\n",
            "495: 0.5908796191215515\n",
            "496: 0.5806483030319214\n",
            "497: 0.5675147771835327\n",
            "498: 0.5756819844245911\n",
            "499: 0.5881044864654541\n",
            "500: 0.5739870667457581\n",
            "input:   tensor([[5, 3, 4, 3, 3, 2, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 3, 4, 3, 3, 2, 5, 5]], device='cuda:0')\n",
            "incorrects: 3\n",
            "501: 0.5777969360351562\n",
            "502: 0.5934821963310242\n",
            "503: 0.5504770874977112\n",
            "504: 0.6026606559753418\n",
            "505: 0.5744959712028503\n",
            "506: 0.6108866930007935\n",
            "507: 0.587693452835083\n",
            "508: 0.6181831955909729\n",
            "509: 0.5584007501602173\n",
            "510: 0.5670477747917175\n",
            "511: 0.5738660097122192\n",
            "512: 0.5469391942024231\n",
            "513: 0.5534744262695312\n",
            "514: 0.5668864250183105\n",
            "515: 0.5631433725357056\n",
            "516: 0.5580090880393982\n",
            "517: 0.5542870163917542\n",
            "518: 0.5624047517776489\n",
            "519: 0.5294138789176941\n",
            "520: 0.5326216816902161\n",
            "521: 0.5431113839149475\n",
            "522: 0.5492425560951233\n",
            "523: 0.5584039092063904\n",
            "524: 0.5285713076591492\n",
            "525: 0.5380439162254333\n",
            "526: 0.5308743119239807\n",
            "527: 0.5383254289627075\n",
            "528: 0.5411462187767029\n",
            "529: 0.5489240288734436\n",
            "530: 0.5895751118659973\n",
            "531: 0.5172195434570312\n",
            "532: 0.5319377183914185\n",
            "533: 0.5631516575813293\n",
            "534: 0.5489996671676636\n",
            "535: 0.527837872505188\n",
            "536: 0.5797269940376282\n",
            "537: 0.5600499510765076\n",
            "538: 0.5440272688865662\n",
            "539: 0.5131245851516724\n",
            "540: 0.5452602505683899\n",
            "541: 0.5470283031463623\n",
            "542: 0.5385705828666687\n",
            "543: 0.5400182008743286\n",
            "544: 0.5390081405639648\n",
            "545: 0.5353080034255981\n",
            "546: 0.6233472228050232\n",
            "547: 0.5390158295631409\n",
            "548: 0.5201114416122437\n",
            "549: 0.5357726812362671\n",
            "550: 0.5887671709060669\n",
            "551: 0.5535558462142944\n",
            "552: 0.5170876383781433\n",
            "553: 0.5837581157684326\n",
            "554: 0.526439905166626\n",
            "555: 0.5410568714141846\n",
            "556: 0.5802216529846191\n",
            "557: 0.5219141840934753\n",
            "558: 0.5522434115409851\n",
            "559: 0.49316608905792236\n",
            "560: 0.5274553298950195\n",
            "561: 0.5469474792480469\n",
            "562: 0.510903537273407\n",
            "563: 0.5177837014198303\n",
            "564: 0.5281187891960144\n",
            "565: 0.5228312015533447\n",
            "566: 0.5276049971580505\n",
            "567: 0.5567055344581604\n",
            "568: 0.5262786149978638\n",
            "569: 0.6108829975128174\n",
            "570: 0.5366477966308594\n",
            "571: 0.6076217293739319\n",
            "572: 0.5597304701805115\n",
            "573: 0.5825524926185608\n",
            "574: 0.568185031414032\n",
            "575: 0.5641498565673828\n",
            "576: 0.5563275218009949\n",
            "577: 0.5598058700561523\n",
            "578: 0.5769505500793457\n",
            "579: 0.6029580235481262\n",
            "580: 0.5492700934410095\n",
            "581: 0.5345475077629089\n",
            "582: 0.5612018704414368\n",
            "583: 0.5203355550765991\n",
            "584: 0.5422989130020142\n",
            "585: 0.5472992658615112\n",
            "586: 0.5254222750663757\n",
            "587: 0.5334897041320801\n",
            "588: 0.549898087978363\n",
            "589: 0.5296048521995544\n",
            "590: 0.5124980807304382\n",
            "591: 0.526909351348877\n",
            "592: 0.5351573824882507\n",
            "593: 0.5274999737739563\n",
            "594: 0.4976958632469177\n",
            "595: 0.5312753915786743\n",
            "596: 0.49520841240882874\n",
            "597: 0.46375319361686707\n",
            "598: 0.5085080862045288\n",
            "599: 0.5306091904640198\n",
            "600: 0.5120368599891663\n",
            "input:   tensor([[3, 5, 3, 3, 4, 2, 2, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 3, 3, 3, 5, 4, 3, 5]], device='cuda:0')\n",
            "incorrects: 6\n",
            "601: 0.5200145244598389\n",
            "602: 0.5120381116867065\n",
            "603: 0.5108945965766907\n",
            "604: 0.48182255029678345\n",
            "605: 0.4918783903121948\n",
            "606: 0.4694133698940277\n",
            "607: 0.4691074788570404\n",
            "608: 0.47665563225746155\n",
            "609: 0.47063034772872925\n",
            "610: 0.4803844392299652\n",
            "611: 0.513130247592926\n",
            "612: 0.48842087388038635\n",
            "613: 0.46924829483032227\n",
            "614: 0.49097752571105957\n",
            "615: 0.5112441778182983\n",
            "616: 0.4816643297672272\n",
            "617: 0.4882844388484955\n",
            "618: 0.5002747178077698\n",
            "619: 0.4665442407131195\n",
            "620: 0.475143164396286\n",
            "621: 0.5053811073303223\n",
            "622: 0.4721803367137909\n",
            "623: 0.4776298403739929\n",
            "624: 0.5038537383079529\n",
            "625: 0.4805745482444763\n",
            "626: 0.455207884311676\n",
            "627: 0.48629307746887207\n",
            "628: 0.4526747167110443\n",
            "629: 0.46406474709510803\n",
            "630: 0.4648648202419281\n",
            "631: 0.47058114409446716\n",
            "632: 0.4460326135158539\n",
            "633: 0.46016860008239746\n",
            "634: 0.47985565662384033\n",
            "635: 0.46892666816711426\n",
            "636: 0.46413007378578186\n",
            "637: 0.4624682664871216\n",
            "638: 0.45788443088531494\n",
            "639: 0.4319654107093811\n",
            "640: 0.44813525676727295\n",
            "641: 0.47016045451164246\n",
            "642: 0.4498743712902069\n",
            "643: 0.4636244475841522\n",
            "644: 0.4942607581615448\n",
            "645: 0.4832583963871002\n",
            "646: 0.4578896164894104\n",
            "647: 0.4729211926460266\n",
            "648: 0.46042904257774353\n",
            "649: 0.46581512689590454\n",
            "650: 0.4896251857280731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  66%|██████▌   | 655/1000 [00:40<00:19, 17.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "651: 0.467553973197937\n",
            "652: 0.4648176431655884\n",
            "653: 0.4911976456642151\n",
            "654: 0.45389798283576965\n",
            "655: 0.45835691690444946\n",
            "656: 0.505477249622345\n",
            "657: 0.48642146587371826\n",
            "658: 0.45615077018737793\n",
            "659: 0.5351996421813965\n",
            "660: 0.4683299958705902\n",
            "661: 0.43910929560661316\n",
            "662: 0.49235665798187256\n",
            "663: 0.46226003766059875\n",
            "664: 0.4842638671398163\n",
            "665: 0.4743165969848633\n",
            "666: 0.4839310944080353\n",
            "667: 0.5112587809562683\n",
            "668: 0.4503178298473358\n",
            "669: 0.47240570187568665\n",
            "670: 0.48710986971855164\n",
            "671: 0.48020631074905396\n",
            "672: 0.456676721572876\n",
            "673: 0.47096365690231323\n",
            "674: 0.44144803285598755\n",
            "675: 0.4869357645511627\n",
            "676: 0.4372209310531616\n",
            "677: 0.45522797107696533\n",
            "678: 0.46531882882118225\n",
            "679: 0.44899508357048035\n",
            "680: 0.44952890276908875\n",
            "681: 0.4392344057559967\n",
            "682: 0.4539485573768616\n",
            "683: 0.46850478649139404\n",
            "684: 0.44622400403022766\n",
            "685: 0.4736514687538147\n",
            "686: 0.44495731592178345\n",
            "687: 0.43023309111595154\n",
            "688: 0.46190372109413147\n",
            "689: 0.4273545742034912\n",
            "690: 0.4472697079181671\n",
            "691: 0.4344792068004608\n",
            "692: 0.47054657340049744\n",
            "693: 0.4724302589893341\n",
            "694: 0.43941715359687805\n",
            "695: 0.4352444112300873\n",
            "696: 0.44468793272972107\n",
            "697: 0.4399232566356659\n",
            "698: 0.46844303607940674\n",
            "699: 0.42461711168289185\n",
            "700: 0.4449860155582428\n",
            "input:   tensor([[3, 4, 3, 2, 4, 2, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 2, 4, 3, 3, 3, 2]], device='cuda:0')\n",
            "incorrects: 7\n",
            "701: 0.43849071860313416\n",
            "702: 0.4786180853843689\n",
            "703: 0.44495394825935364\n",
            "704: 0.4196849465370178\n",
            "705: 0.42054483294487\n",
            "706: 0.4211685061454773\n",
            "707: 0.4382927119731903\n",
            "708: 0.4620320200920105\n",
            "709: 0.45181703567504883\n",
            "710: 0.43812108039855957\n",
            "711: 0.42354193329811096\n",
            "712: 0.40245503187179565\n",
            "713: 0.441529780626297\n",
            "714: 0.4502335786819458\n",
            "715: 0.42750924825668335\n",
            "716: 0.4091176390647888\n",
            "717: 0.45577773451805115\n",
            "718: 0.4186868667602539\n",
            "719: 0.4073881506919861\n",
            "720: 0.4465632140636444\n",
            "721: 0.43316125869750977\n",
            "722: 0.4251875579357147\n",
            "723: 0.4577694833278656\n",
            "724: 0.47067201137542725\n",
            "725: 0.4737943112850189\n",
            "726: 0.4297022819519043\n",
            "727: 0.4198952615261078\n",
            "728: 0.4149360656738281\n",
            "729: 0.42655524611473083\n",
            "730: 0.41801881790161133\n",
            "731: 0.44151362776756287\n",
            "732: 0.4797482490539551\n",
            "733: 0.434844046831131\n",
            "734: 0.431059330701828\n",
            "735: 0.4434622526168823\n",
            "736: 0.44969356060028076\n",
            "737: 0.4467461109161377\n",
            "738: 0.41775766015052795\n",
            "739: 0.5111623406410217\n",
            "740: 0.41268038749694824\n",
            "741: 0.44618284702301025\n",
            "742: 0.44251662492752075\n",
            "743: 0.454238623380661\n",
            "744: 0.48783648014068604\n",
            "745: 0.44770148396492004\n",
            "746: 0.4308166801929474\n",
            "747: 0.4342194199562073\n",
            "748: 0.40315666794776917\n",
            "749: 0.4613158702850342\n",
            "750: 0.4298241138458252\n",
            "751: 0.432696670293808\n",
            "752: 0.46516862511634827\n",
            "753: 0.4506680369377136\n",
            "754: 0.4466746151447296\n",
            "755: 0.43697595596313477\n",
            "756: 0.4329169988632202\n",
            "757: 0.42464274168014526\n",
            "758: 0.4166572690010071\n",
            "759: 0.439654141664505\n",
            "760: 0.4658976197242737\n",
            "761: 0.4605379104614258\n",
            "762: 0.4192456305027008\n",
            "763: 0.4508470296859741\n",
            "764: 0.4452659487724304\n",
            "765: 0.4377232491970062\n",
            "766: 0.41818273067474365\n",
            "767: 0.4546424150466919\n",
            "768: 0.4360668957233429\n",
            "769: 0.43811801075935364\n",
            "770: 0.4361051321029663\n",
            "771: 0.41056543588638306\n",
            "772: 0.41420090198516846\n",
            "773: 0.4245932996273041\n",
            "774: 0.40989184379577637\n",
            "775: 0.4151667058467865\n",
            "776: 0.4181848466396332\n",
            "777: 0.4285537600517273\n",
            "778: 0.42836514115333557\n",
            "779: 0.43572524189949036\n",
            "780: 0.42758166790008545\n",
            "781: 0.3938831388950348\n",
            "782: 0.40024688839912415\n",
            "783: 0.40115034580230713\n",
            "784: 0.4011078178882599\n",
            "785: 0.42372334003448486\n",
            "786: 0.3969244658946991\n",
            "787: 0.4123876094818115\n",
            "788: 0.4306385815143585\n",
            "789: 0.3976604640483856\n",
            "790: 0.37528935074806213\n",
            "791: 0.4030129909515381\n",
            "792: 0.3840462565422058\n",
            "793: 0.3936673402786255\n",
            "794: 0.4014764428138733\n",
            "795: 0.42605239152908325\n",
            "796: 0.39989206194877625\n",
            "797: 0.3934083878993988\n",
            "798: 0.41990548372268677\n",
            "799: 0.3893493413925171\n",
            "800: 0.41084688901901245\n",
            "input:   tensor([[5, 2, 5, 3, 4, 2, 5, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 5, 5, 3, 2, 4, 5, 2]], device='cuda:0')\n",
            "incorrects: 4\n",
            "801: 0.38801109790802\n",
            "802: 0.3977256119251251\n",
            "803: 0.38537684082984924\n",
            "804: 0.3982851505279541\n",
            "805: 0.3884781002998352\n",
            "806: 0.3878474235534668\n",
            "807: 0.391437828540802\n",
            "808: 0.39167556166648865\n",
            "809: 0.3814617693424225\n",
            "810: 0.37841659784317017\n",
            "811: 0.3939562439918518\n",
            "812: 0.3891395330429077\n",
            "813: 0.38784992694854736\n",
            "814: 0.4191395044326782\n",
            "815: 0.4064761698246002\n",
            "816: 0.37577328085899353\n",
            "817: 0.4059859812259674\n",
            "818: 0.38269466161727905\n",
            "819: 0.3880634009838104\n",
            "820: 0.37710580229759216\n",
            "821: 0.4036638140678406\n",
            "822: 0.38449567556381226\n",
            "823: 0.3655318319797516\n",
            "824: 0.3847405016422272\n",
            "825: 0.4028888940811157\n",
            "826: 0.39309626817703247\n",
            "827: 0.3839642107486725\n",
            "828: 0.3630022704601288\n",
            "829: 0.382984459400177\n",
            "830: 0.38987740874290466\n",
            "831: 0.4326341152191162\n",
            "832: 0.4193955957889557\n",
            "833: 0.4327153265476227\n",
            "834: 0.3912346363067627\n",
            "835: 0.3894248604774475\n",
            "836: 0.4113589823246002\n",
            "837: 0.3858705461025238\n",
            "838: 0.41185063123703003\n",
            "839: 0.425326943397522\n",
            "840: 0.4071267247200012\n",
            "841: 0.4020029902458191\n",
            "842: 0.4028064012527466\n",
            "843: 0.38204225897789\n",
            "844: 0.4149315655231476\n",
            "845: 0.3887672424316406\n",
            "846: 0.3870381712913513\n",
            "847: 0.3871930241584778\n",
            "848: 0.3853137791156769\n",
            "849: 0.4090099632740021\n",
            "850: 0.3892327547073364\n",
            "851: 0.4448072910308838\n",
            "852: 0.3874782621860504\n",
            "853: 0.42323920130729675\n",
            "854: 0.3937709331512451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  86%|████████▌ | 859/1000 [00:50<00:07, 18.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "855: 0.494182825088501\n",
            "856: 0.37621432542800903\n",
            "857: 0.3832762539386749\n",
            "858: 0.40720728039741516\n",
            "859: 0.4293483793735504\n",
            "860: 0.39243414998054504\n",
            "861: 0.441006064414978\n",
            "862: 0.4348162114620209\n",
            "863: 0.4178259074687958\n",
            "864: 0.3843914866447449\n",
            "865: 0.42851853370666504\n",
            "866: 0.408882737159729\n",
            "867: 0.3982895016670227\n",
            "868: 0.4129410684108734\n",
            "869: 0.4607236087322235\n",
            "870: 0.3751091957092285\n",
            "871: 0.43847423791885376\n",
            "872: 0.4013316035270691\n",
            "873: 0.44240352511405945\n",
            "874: 0.43345707654953003\n",
            "875: 0.4477173388004303\n",
            "876: 0.5483145117759705\n",
            "877: 0.41919612884521484\n",
            "878: 0.5067286491394043\n",
            "879: 0.41725337505340576\n",
            "880: 0.4101925492286682\n",
            "881: 0.4702812433242798\n",
            "882: 0.5094444155693054\n",
            "883: 0.4366513192653656\n",
            "884: 0.4128284156322479\n",
            "885: 0.4488702118396759\n",
            "886: 0.47367534041404724\n",
            "887: 0.46816638112068176\n",
            "888: 0.3922692835330963\n",
            "889: 0.45860862731933594\n",
            "890: 0.4955599009990692\n",
            "891: 0.4354282319545746\n",
            "892: 0.4954681396484375\n",
            "893: 0.4183166027069092\n",
            "894: 0.4706358313560486\n",
            "895: 0.44970810413360596\n",
            "896: 0.4315336048603058\n",
            "897: 0.47730371356010437\n",
            "898: 0.4377790689468384\n",
            "899: 0.39292022585868835\n",
            "900: 0.40486493706703186\n",
            "input:   tensor([[4, 4, 5, 3, 5, 2, 5, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 5, 5, 4, 3, 4, 2, 5]], device='cuda:0')\n",
            "incorrects: 6\n",
            "901: 0.40724995732307434\n",
            "902: 0.4003884494304657\n",
            "903: 0.39898812770843506\n",
            "904: 0.43962275981903076\n",
            "905: 0.42687466740608215\n",
            "906: 0.41274985671043396\n",
            "907: 0.369950532913208\n",
            "908: 0.40547963976860046\n",
            "909: 0.4030664563179016\n",
            "910: 0.40129008889198303\n",
            "911: 0.3690916895866394\n",
            "912: 0.39598003029823303\n",
            "913: 0.3966163694858551\n",
            "914: 0.40889739990234375\n",
            "915: 0.3826310932636261\n",
            "916: 0.3664860129356384\n",
            "917: 0.4008937180042267\n",
            "918: 0.381317138671875\n",
            "919: 0.38920852541923523\n",
            "920: 0.37203070521354675\n",
            "921: 0.3904411196708679\n",
            "922: 0.37605640292167664\n",
            "923: 0.3824695646762848\n",
            "924: 0.37050527334213257\n",
            "925: 0.39210057258605957\n",
            "926: 0.3749297857284546\n",
            "927: 0.3534770607948303\n",
            "928: 0.354050874710083\n",
            "929: 0.3666473925113678\n",
            "930: 0.36500561237335205\n",
            "931: 0.3681425452232361\n",
            "932: 0.3822791874408722\n",
            "933: 0.36910760402679443\n",
            "934: 0.3916822671890259\n",
            "935: 0.39065831899642944\n",
            "936: 0.37733182311058044\n",
            "937: 0.36563774943351746\n",
            "938: 0.38390111923217773\n",
            "939: 0.4171919822692871\n",
            "940: 0.3748781383037567\n",
            "941: 0.385276734828949\n",
            "942: 0.39273762702941895\n",
            "943: 0.37163108587265015\n",
            "944: 0.3478511571884155\n",
            "945: 0.34739577770233154\n",
            "946: 0.35287460684776306\n",
            "947: 0.36435437202453613\n",
            "948: 0.34383463859558105\n",
            "949: 0.3634144067764282\n",
            "950: 0.38773903250694275\n",
            "951: 0.35342928767204285\n",
            "952: 0.3859572112560272\n",
            "953: 0.35650375485420227\n",
            "954: 0.4000273644924164\n",
            "955: 0.3896556794643402\n",
            "956: 0.4074605405330658\n",
            "957: 0.41458261013031006\n",
            "958: 0.37413179874420166\n",
            "959: 0.42025265097618103\n",
            "960: 0.36264461278915405\n",
            "961: 0.36364656686782837\n",
            "962: 0.44321539998054504\n",
            "963: 0.3851196765899658\n",
            "964: 0.35988253355026245\n",
            "965: 0.4262703061103821\n",
            "966: 0.4060851037502289\n",
            "967: 0.4087395966053009\n",
            "968: 0.4060508906841278\n",
            "969: 0.39061278104782104\n",
            "970: 0.369896799325943\n",
            "971: 0.38174402713775635\n",
            "972: 0.39720216393470764\n",
            "973: 0.38686704635620117\n",
            "974: 0.35191282629966736\n",
            "975: 0.3749000132083893\n",
            "976: 0.3796471953392029\n",
            "977: 0.3466183543205261\n",
            "978: 0.38174983859062195\n",
            "979: 0.37320029735565186\n",
            "980: 0.35067644715309143\n",
            "981: 0.35721322894096375\n",
            "982: 0.34535083174705505\n",
            "983: 0.347000390291214\n",
            "984: 0.35546356439590454\n",
            "985: 0.36383935809135437\n",
            "986: 0.37080904841423035\n",
            "987: 0.3701813817024231\n",
            "988: 0.3409188985824585\n",
            "989: 0.359518826007843\n",
            "990: 0.35539889335632324\n",
            "991: 0.3353648781776428\n",
            "992: 0.3479798138141632\n",
            "993: 0.3571164906024933\n",
            "994: 0.36778485774993896\n",
            "995: 0.34377172589302063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:57<00:00, 17.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "996: 0.3308544158935547\n",
            "997: 0.34540706872940063\n",
            "998: 0.31389281153678894\n",
            "999: 0.3339492082595825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "5b78bab6-4a8d-4e83-d873-fb3d9e9549d9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 81.25%\n"
          ]
        }
      ]
    }
  ]
}