{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "55245d51-3d0a-4270-9e3c-c3184888a9bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "0ad64b61-b546-44c2-856e-5788f8a038c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2.7159199714660645\n",
            "1: 2.340632200241089\n",
            "2: 2.211869716644287\n",
            "3: 2.1506853103637695\n",
            "4: 2.077253580093384\n",
            "5: 2.1267380714416504\n",
            "6: 2.054264783859253\n",
            "7: 2.074209690093994\n",
            "8: 2.081350564956665\n",
            "9: 2.0057532787323\n",
            "10: 2.018472909927368\n",
            "11: 2.0012898445129395\n",
            "12: 1.9789748191833496\n",
            "13: 1.9547322988510132\n",
            "14: 1.9762852191925049\n",
            "15: 1.9849650859832764\n",
            "16: 1.9714045524597168\n",
            "17: 1.9267220497131348\n",
            "18: 1.951064944267273\n",
            "19: 1.982918381690979\n",
            "20: 1.9797437191009521\n",
            "21: 1.952080249786377\n",
            "22: 1.9145829677581787\n",
            "23: 1.9215447902679443\n",
            "24: 1.8749977350234985\n",
            "25: 1.8898621797561646\n",
            "26: 1.9347507953643799\n",
            "27: 1.9007478952407837\n",
            "28: 1.8965784311294556\n",
            "29: 1.8471498489379883\n",
            "30: 1.8468708992004395\n",
            "31: 1.9052762985229492\n",
            "32: 1.816293478012085\n",
            "33: 1.882497787475586\n",
            "34: 1.8536301851272583\n",
            "35: 1.8320268392562866\n",
            "36: 1.8486570119857788\n",
            "37: 1.8808456659317017\n",
            "38: 1.8483726978302002\n",
            "39: 1.857274055480957\n",
            "40: 1.8012079000473022\n",
            "41: 1.8206894397735596\n",
            "42: 1.8089230060577393\n",
            "43: 1.8185392618179321\n",
            "44: 1.8206745386123657\n",
            "45: 1.7904345989227295\n",
            "46: 1.851409673690796\n",
            "47: 1.816481351852417\n",
            "48: 1.8017771244049072\n",
            "49: 1.8075007200241089\n",
            "50: 1.8022892475128174\n",
            "51: 1.815476894378662\n",
            "52: 1.77125883102417\n",
            "53: 1.7841598987579346\n",
            "54: 1.8148012161254883\n",
            "55: 1.7675175666809082\n",
            "56: 1.7576065063476562\n",
            "57: 1.7336772680282593\n",
            "58: 1.7582645416259766\n",
            "59: 1.7235771417617798\n",
            "60: 1.73176109790802\n",
            "61: 1.7733203172683716\n",
            "62: 1.766688585281372\n",
            "63: 1.7356574535369873\n",
            "64: 1.7127269506454468\n",
            "65: 1.697195291519165\n",
            "66: 1.7425141334533691\n",
            "67: 1.7038679122924805\n",
            "68: 1.7463284730911255\n",
            "69: 1.7308335304260254\n",
            "70: 1.7131160497665405\n",
            "71: 1.7499823570251465\n",
            "72: 1.6538732051849365\n",
            "73: 1.710418462753296\n",
            "74: 1.6882609128952026\n",
            "75: 1.7021708488464355\n",
            "76: 1.6951428651809692\n",
            "77: 1.6740386486053467\n",
            "78: 1.6894197463989258\n",
            "79: 1.6820340156555176\n",
            "80: 1.6409671306610107\n",
            "81: 1.6783453226089478\n",
            "82: 1.7021063566207886\n",
            "83: 1.6414246559143066\n",
            "84: 1.6045727729797363\n",
            "85: 1.6577188968658447\n",
            "86: 1.6302698850631714\n",
            "87: 1.6610914468765259\n",
            "88: 1.6484143733978271\n",
            "89: 1.6238620281219482\n",
            "90: 1.6355456113815308\n",
            "91: 1.652058482170105\n",
            "92: 1.5960878133773804\n",
            "93: 1.651713490486145\n",
            "94: 1.570116400718689\n",
            "95: 1.649415373802185\n",
            "96: 1.5713602304458618\n",
            "97: 1.6072094440460205\n",
            "98: 1.569584608078003\n",
            "99: 1.5900969505310059\n",
            "100: 1.6132524013519287\n",
            "input:   tensor([[5, 5, 5, 2, 3, 2, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 5, 5, 5, 3, 3, 2, 5]], device='cuda:0')\n",
            "incorrects: 5\n",
            "101: 1.6036617755889893\n",
            "102: 1.5692681074142456\n",
            "103: 1.5714595317840576\n",
            "104: 1.5914373397827148\n",
            "105: 1.554364562034607\n",
            "106: 1.5515713691711426\n",
            "107: 1.540436863899231\n",
            "108: 1.5531140565872192\n",
            "109: 1.5370839834213257\n",
            "110: 1.5539929866790771\n",
            "111: 1.5707401037216187\n",
            "112: 1.5148416757583618\n",
            "113: 1.5167605876922607\n",
            "114: 1.5378693342208862\n",
            "115: 1.5445656776428223\n",
            "116: 1.5071228742599487\n",
            "117: 1.5138218402862549\n",
            "118: 1.5106701850891113\n",
            "119: 1.4952716827392578\n",
            "120: 1.4984325170516968\n",
            "121: 1.5211697816848755\n",
            "122: 1.5117017030715942\n",
            "123: 1.4943305253982544\n",
            "124: 1.5257642269134521\n",
            "125: 1.5201175212860107\n",
            "126: 1.5349020957946777\n",
            "127: 1.5139026641845703\n",
            "128: 1.4392266273498535\n",
            "129: 1.5274817943572998\n",
            "130: 1.4476590156555176\n",
            "131: 1.4800242185592651\n",
            "132: 1.4461071491241455\n",
            "133: 1.437313199043274\n",
            "134: 1.4526162147521973\n",
            "135: 1.4338806867599487\n",
            "136: 1.4259514808654785\n",
            "137: 1.4121073484420776\n",
            "138: 1.4265087842941284\n",
            "139: 1.4559760093688965\n",
            "140: 1.450703501701355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  14%|█▍        | 144/1000 [00:10<00:59, 14.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141: 1.429375171661377\n",
            "142: 1.4708038568496704\n",
            "143: 1.4130728244781494\n",
            "144: 1.426938772201538\n",
            "145: 1.4158269166946411\n",
            "146: 1.4316428899765015\n",
            "147: 1.4025956392288208\n",
            "148: 1.4313727617263794\n",
            "149: 1.3923890590667725\n",
            "150: 1.4011284112930298\n",
            "151: 1.3822747468948364\n",
            "152: 1.3944215774536133\n",
            "153: 1.4168020486831665\n",
            "154: 1.3475834131240845\n",
            "155: 1.3935788869857788\n",
            "156: 1.3425382375717163\n",
            "157: 1.3844558000564575\n",
            "158: 1.3378889560699463\n",
            "159: 1.3482110500335693\n",
            "160: 1.4005327224731445\n",
            "161: 1.4245086908340454\n",
            "162: 1.351359486579895\n",
            "163: 1.485213279724121\n",
            "164: 1.3365448713302612\n",
            "165: 1.3408681154251099\n",
            "166: 1.3633060455322266\n",
            "167: 1.3562052249908447\n",
            "168: 1.3528529405593872\n",
            "169: 1.3829494714736938\n",
            "170: 1.3404639959335327\n",
            "171: 1.3405674695968628\n",
            "172: 1.3186167478561401\n",
            "173: 1.318481206893921\n",
            "174: 1.295263648033142\n",
            "175: 1.3060723543167114\n",
            "176: 1.3011683225631714\n",
            "177: 1.3565260171890259\n",
            "178: 1.3387513160705566\n",
            "179: 1.3186016082763672\n",
            "180: 1.371983528137207\n",
            "181: 1.2977324724197388\n",
            "182: 1.2495943307876587\n",
            "183: 1.2604387998580933\n",
            "184: 1.2635440826416016\n",
            "185: 1.3102190494537354\n",
            "186: 1.263338565826416\n",
            "187: 1.2619777917861938\n",
            "188: 1.2375667095184326\n",
            "189: 1.2263447046279907\n",
            "190: 1.2287101745605469\n",
            "191: 1.2379968166351318\n",
            "192: 1.2671701908111572\n",
            "193: 1.2562592029571533\n",
            "194: 1.2187105417251587\n",
            "195: 1.2733943462371826\n",
            "196: 1.1969529390335083\n",
            "197: 1.2201802730560303\n",
            "198: 1.2262918949127197\n",
            "199: 1.2132644653320312\n",
            "200: 1.2389730215072632\n",
            "input:   tensor([[2, 3, 2, 3, 5, 5, 3, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 3, 2, 3, 5, 2, 3, 2]], device='cuda:0')\n",
            "incorrects: 1\n",
            "201: 1.2452446222305298\n",
            "202: 1.237577199935913\n",
            "203: 1.2633737325668335\n",
            "204: 1.2404695749282837\n",
            "205: 1.220490574836731\n",
            "206: 1.1698518991470337\n",
            "207: 1.1841942071914673\n",
            "208: 1.1580100059509277\n",
            "209: 1.1658539772033691\n",
            "210: 1.1475226879119873\n",
            "211: 1.1381980180740356\n",
            "212: 1.1642340421676636\n",
            "213: 1.1739550828933716\n",
            "214: 1.1271324157714844\n",
            "215: 1.1960320472717285\n",
            "216: 1.1268987655639648\n",
            "217: 1.1926825046539307\n",
            "218: 1.1433719396591187\n",
            "219: 1.1454687118530273\n",
            "220: 1.1829919815063477\n",
            "221: 1.1117281913757324\n",
            "222: 1.1481860876083374\n",
            "223: 1.1400492191314697\n",
            "224: 1.147104024887085\n",
            "225: 1.1704633235931396\n",
            "226: 1.1039401292800903\n",
            "227: 1.1076077222824097\n",
            "228: 1.156982183456421\n",
            "229: 1.1048240661621094\n",
            "230: 1.129746675491333\n",
            "231: 1.0867562294006348\n",
            "232: 1.139939785003662\n",
            "233: 1.1709685325622559\n",
            "234: 1.1871259212493896\n",
            "235: 1.1781409978866577\n",
            "236: 1.0896941423416138\n",
            "237: 1.143505573272705\n",
            "238: 1.1012754440307617\n",
            "239: 1.1197227239608765\n",
            "240: 1.1278475522994995\n",
            "241: 1.093039631843567\n",
            "242: 1.0945416688919067\n",
            "243: 1.0856457948684692\n",
            "244: 1.074425458908081\n",
            "245: 1.0503610372543335\n",
            "246: 1.0671294927597046\n",
            "247: 1.0438077449798584\n",
            "248: 1.0639159679412842\n",
            "249: 1.0164304971694946\n",
            "250: 1.046223759651184\n",
            "251: 1.077763319015503\n",
            "252: 1.0163161754608154\n",
            "253: 1.0735667943954468\n",
            "254: 1.066765308380127\n",
            "255: 1.0321763753890991\n",
            "256: 1.0670933723449707\n",
            "257: 1.0431132316589355\n",
            "258: 1.035774827003479\n",
            "259: 1.0252132415771484\n",
            "260: 1.0594099760055542\n",
            "261: 1.0170695781707764\n",
            "262: 1.0080586671829224\n",
            "263: 0.9928251504898071\n",
            "264: 0.9738388061523438\n",
            "265: 0.9651315808296204\n",
            "266: 0.9872922897338867\n",
            "267: 0.9414473176002502\n",
            "268: 0.961999773979187\n",
            "269: 0.9771410226821899\n",
            "270: 0.9241079688072205\n",
            "271: 0.9308236241340637\n",
            "272: 0.9634473919868469\n",
            "273: 0.9308353662490845\n",
            "274: 0.950498640537262\n",
            "275: 0.9284975528717041\n",
            "276: 0.9544033408164978\n",
            "277: 0.9651123285293579\n",
            "278: 0.9771533608436584\n",
            "279: 0.9482100009918213\n",
            "280: 0.9704532623291016\n",
            "281: 0.9113025069236755\n",
            "282: 0.9727010726928711\n",
            "283: 0.9582194089889526\n",
            "284: 0.9814042448997498\n",
            "285: 0.8883827924728394\n",
            "286: 0.9359288215637207\n",
            "287: 0.9569727182388306\n",
            "288: 0.8955692052841187\n",
            "289: 0.8978665471076965\n",
            "290: 0.8982465267181396\n",
            "291: 0.9219456315040588\n",
            "292: 0.9362703561782837\n",
            "293: 0.9145072102546692\n",
            "294: 0.9082937836647034\n",
            "295: 0.908567488193512\n",
            "296: 0.9261945486068726\n",
            "297: 0.8886702060699463\n",
            "298: 0.9219878315925598\n",
            "299: 0.8802084922790527\n",
            "300: 0.855800211429596\n",
            "input:   tensor([[4, 4, 2, 3, 2, 3, 2, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 3, 4, 4, 2, 3, 4, 4]], device='cuda:0')\n",
            "incorrects: 5\n",
            "301: 0.8594071865081787\n",
            "302: 0.8456084728240967\n",
            "303: 0.8706223964691162\n",
            "304: 0.8399179577827454\n",
            "305: 0.8600409626960754\n",
            "306: 0.8900406360626221\n",
            "307: 0.8473488092422485\n",
            "308: 0.8537567853927612\n",
            "309: 0.8519347906112671\n",
            "310: 0.844239354133606\n",
            "311: 0.8296176195144653\n",
            "312: 0.8580052852630615\n",
            "313: 0.8483020067214966\n",
            "314: 0.8822535276412964\n",
            "315: 0.8092426061630249\n",
            "316: 0.7867684364318848\n",
            "317: 0.8193305134773254\n",
            "318: 0.839758038520813\n",
            "319: 0.8390451669692993\n",
            "320: 0.8040980696678162\n",
            "321: 0.8042597770690918\n",
            "322: 0.8090752363204956\n",
            "323: 0.7995044589042664\n",
            "324: 0.805475652217865\n",
            "325: 0.8373464941978455\n",
            "326: 0.8429628610610962\n",
            "327: 0.804055392742157\n",
            "328: 0.8839982748031616\n",
            "329: 0.787324070930481\n",
            "330: 0.7973031997680664\n",
            "331: 0.8145282864570618\n",
            "332: 0.8059278130531311\n",
            "333: 0.8318870663642883\n",
            "334: 0.7838402986526489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  34%|███▍      | 339/1000 [00:20<00:38, 17.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "335: 0.8408811688423157\n",
            "336: 0.821189820766449\n",
            "337: 0.816382110118866\n",
            "338: 0.7702741026878357\n",
            "339: 0.7913607358932495\n",
            "340: 0.8461558222770691\n",
            "341: 0.8474199771881104\n",
            "342: 0.8759096264839172\n",
            "343: 0.8180527091026306\n",
            "344: 0.8636281490325928\n",
            "345: 0.8126228451728821\n",
            "346: 0.8495261073112488\n",
            "347: 0.7622610330581665\n",
            "348: 0.7712553143501282\n",
            "349: 0.7534445524215698\n",
            "350: 0.764530599117279\n",
            "351: 0.7501214146614075\n",
            "352: 0.7529242634773254\n",
            "353: 0.7702922821044922\n",
            "354: 0.7553625106811523\n",
            "355: 0.7291116714477539\n",
            "356: 0.730505108833313\n",
            "357: 0.7647315263748169\n",
            "358: 0.8019096255302429\n",
            "359: 0.7678351402282715\n",
            "360: 0.7439815402030945\n",
            "361: 0.7344028353691101\n",
            "362: 0.7114460468292236\n",
            "363: 0.7380483746528625\n",
            "364: 0.7473811507225037\n",
            "365: 0.7175288200378418\n",
            "366: 0.7285388112068176\n",
            "367: 0.7153905630111694\n",
            "368: 0.6770309209823608\n",
            "369: 0.7094429731369019\n",
            "370: 0.6856462955474854\n",
            "371: 0.7331066131591797\n",
            "372: 0.7316758632659912\n",
            "373: 0.7104676961898804\n",
            "374: 0.7346172332763672\n",
            "375: 0.686581552028656\n",
            "376: 0.7588407397270203\n",
            "377: 0.7500640749931335\n",
            "378: 0.7370606660842896\n",
            "379: 0.7162653803825378\n",
            "380: 0.7344314455986023\n",
            "381: 0.6949364542961121\n",
            "382: 0.6930496692657471\n",
            "383: 0.7113565802574158\n",
            "384: 0.6927549242973328\n",
            "385: 0.7084221243858337\n",
            "386: 0.7036215662956238\n",
            "387: 0.7111724019050598\n",
            "388: 0.6813406944274902\n",
            "389: 0.6434025168418884\n",
            "390: 0.6925475597381592\n",
            "391: 0.6853794455528259\n",
            "392: 0.6466384530067444\n",
            "393: 0.7045620679855347\n",
            "394: 0.6758728623390198\n",
            "395: 0.7156646847724915\n",
            "396: 0.669526219367981\n",
            "397: 0.7108314037322998\n",
            "398: 0.6459047794342041\n",
            "399: 0.6388461589813232\n",
            "400: 0.6722152233123779\n",
            "input:   tensor([[2, 3, 2, 3, 5, 4, 2, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 2, 3, 3, 2, 4, 5, 3]], device='cuda:0')\n",
            "incorrects: 4\n",
            "401: 0.6561569571495056\n",
            "402: 0.6369543075561523\n",
            "403: 0.6621993780136108\n",
            "404: 0.6851579546928406\n",
            "405: 0.669228732585907\n",
            "406: 0.6323602199554443\n",
            "407: 0.7474872469902039\n",
            "408: 0.6349887251853943\n",
            "409: 0.727186918258667\n",
            "410: 0.6778752207756042\n",
            "411: 0.676177442073822\n",
            "412: 0.6538960933685303\n",
            "413: 0.6523364782333374\n",
            "414: 0.6500541567802429\n",
            "415: 0.6377559900283813\n",
            "416: 0.6425233483314514\n",
            "417: 0.6391342878341675\n",
            "418: 0.6229096055030823\n",
            "419: 0.6329700946807861\n",
            "420: 0.646388828754425\n",
            "421: 0.6523873805999756\n",
            "422: 0.6498470902442932\n",
            "423: 0.6598050594329834\n",
            "424: 0.6461013555526733\n",
            "425: 0.6782374382019043\n",
            "426: 0.6673712730407715\n",
            "427: 0.6793476343154907\n",
            "428: 0.6545507907867432\n",
            "429: 0.6666104197502136\n",
            "430: 0.7036938667297363\n",
            "431: 0.6116938591003418\n",
            "432: 0.6341680884361267\n",
            "433: 0.6608205437660217\n",
            "434: 0.6846861839294434\n",
            "435: 0.6878658533096313\n",
            "436: 0.6640650033950806\n",
            "437: 0.6028669476509094\n",
            "438: 0.6490963101387024\n",
            "439: 0.6567158102989197\n",
            "440: 0.5987597703933716\n",
            "441: 0.6393545269966125\n",
            "442: 0.6146039366722107\n",
            "443: 0.6076068878173828\n",
            "444: 0.6443629860877991\n",
            "445: 0.5790780186653137\n",
            "446: 0.6162977814674377\n",
            "447: 0.5960639119148254\n",
            "448: 0.5996604561805725\n",
            "449: 0.5940237045288086\n",
            "450: 0.5878922343254089\n",
            "451: 0.5913770794868469\n",
            "452: 0.566006600856781\n",
            "453: 0.589530348777771\n",
            "454: 0.5937680602073669\n",
            "455: 0.5962303876876831\n",
            "456: 0.5692113041877747\n",
            "457: 0.5769691467285156\n",
            "458: 0.5744125247001648\n",
            "459: 0.5737134218215942\n",
            "460: 0.5707924962043762\n",
            "461: 0.5960696935653687\n",
            "462: 0.569614589214325\n",
            "463: 0.5911246538162231\n",
            "464: 0.6048242449760437\n",
            "465: 0.6000259518623352\n",
            "466: 0.5937952995300293\n",
            "467: 0.5744442939758301\n",
            "468: 0.5679712295532227\n",
            "469: 0.5545691251754761\n",
            "470: 0.5600011944770813\n",
            "471: 0.5776697993278503\n",
            "472: 0.5498957633972168\n",
            "473: 0.5710164308547974\n",
            "474: 0.5278187394142151\n",
            "475: 0.5566202998161316\n",
            "476: 0.5531190037727356\n",
            "477: 0.5748069882392883\n",
            "478: 0.562416672706604\n",
            "479: 0.5448635220527649\n",
            "480: 0.5762854814529419\n",
            "481: 0.536421000957489\n",
            "482: 0.5772315859794617\n",
            "483: 0.5294730067253113\n",
            "484: 0.5621404051780701\n",
            "485: 0.5590128302574158\n",
            "486: 0.5711804628372192\n",
            "487: 0.5628244280815125\n",
            "488: 0.5464717745780945\n",
            "489: 0.5471720099449158\n",
            "490: 0.5806531310081482\n",
            "491: 0.550173819065094\n",
            "492: 0.5360129475593567\n",
            "493: 0.5570110082626343\n",
            "494: 0.552619218826294\n",
            "495: 0.5354733467102051\n",
            "496: 0.5489311218261719\n",
            "497: 0.5634084939956665\n",
            "498: 0.5480045080184937\n",
            "499: 0.53407222032547\n",
            "500: 0.5346996784210205\n",
            "input:   tensor([[5, 5, 4, 5, 2, 3, 3, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 5, 3, 4, 5, 2, 3, 5]], device='cuda:0')\n",
            "incorrects: 4\n",
            "501: 0.5345814824104309\n",
            "502: 0.5248422622680664\n",
            "503: 0.5678369402885437\n",
            "504: 0.5399602651596069\n",
            "505: 0.5417328476905823\n",
            "506: 0.533687949180603\n",
            "507: 0.5274603366851807\n",
            "508: 0.5277751088142395\n",
            "509: 0.562190592288971\n",
            "510: 0.5722585320472717\n",
            "511: 0.5409963130950928\n",
            "512: 0.5349370241165161\n",
            "513: 0.5667153596878052\n",
            "514: 0.5199868083000183\n",
            "515: 0.5915783047676086\n",
            "516: 0.5303579568862915\n",
            "517: 0.5413891673088074\n",
            "518: 0.5445670485496521\n",
            "519: 0.5636582970619202\n",
            "520: 0.5323137640953064\n",
            "521: 0.5408293604850769\n",
            "522: 0.48706620931625366\n",
            "523: 0.5251636505126953\n",
            "524: 0.5779900550842285\n",
            "525: 0.5530418157577515\n",
            "526: 0.5192818641662598\n",
            "527: 0.5361089706420898\n",
            "528: 0.5361132621765137\n",
            "529: 0.5391265153884888\n",
            "530: 0.5219689607620239\n",
            "531: 0.5458735227584839\n",
            "532: 0.5197035074234009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  54%|█████▎    | 537/1000 [00:30<00:25, 18.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "533: 0.5293940305709839\n",
            "534: 0.5078270435333252\n",
            "535: 0.5428709387779236\n",
            "536: 0.5293728709220886\n",
            "537: 0.5161980390548706\n",
            "538: 0.5341401696205139\n",
            "539: 0.4827260971069336\n",
            "540: 0.548072338104248\n",
            "541: 0.5018462538719177\n",
            "542: 0.5319571495056152\n",
            "543: 0.5855957865715027\n",
            "544: 0.5012254118919373\n",
            "545: 0.6155388355255127\n",
            "546: 0.5164189338684082\n",
            "547: 0.6397287845611572\n",
            "548: 0.5647966265678406\n",
            "549: 0.5122579336166382\n",
            "550: 0.5855109691619873\n",
            "551: 0.5715779066085815\n",
            "552: 0.5547770857810974\n",
            "553: 0.5396165251731873\n",
            "554: 0.5784672498703003\n",
            "555: 0.5002285838127136\n",
            "556: 0.5432012677192688\n",
            "557: 0.5184900164604187\n",
            "558: 0.5061147809028625\n",
            "559: 0.5234165787696838\n",
            "560: 0.5382082462310791\n",
            "561: 0.5063276290893555\n",
            "562: 0.511388897895813\n",
            "563: 0.5108919143676758\n",
            "564: 0.5215871334075928\n",
            "565: 0.5247786641120911\n",
            "566: 0.4781842529773712\n",
            "567: 0.508637011051178\n",
            "568: 0.5266063213348389\n",
            "569: 0.5086038112640381\n",
            "570: 0.49855995178222656\n",
            "571: 0.5161296129226685\n",
            "572: 0.5332735776901245\n",
            "573: 0.4915812313556671\n",
            "574: 0.49148863554000854\n",
            "575: 0.5096360445022583\n",
            "576: 0.49455806612968445\n",
            "577: 0.5194324851036072\n",
            "578: 0.4728546440601349\n",
            "579: 0.5685528516769409\n",
            "580: 0.498800128698349\n",
            "581: 0.5868744850158691\n",
            "582: 0.5341588258743286\n",
            "583: 0.5352626442909241\n",
            "584: 0.5627952814102173\n",
            "585: 0.502458393573761\n",
            "586: 0.5302041172981262\n",
            "587: 0.5437357425689697\n",
            "588: 0.5249929428100586\n",
            "589: 0.5474667549133301\n",
            "590: 0.563088595867157\n",
            "591: 0.5159225463867188\n",
            "592: 0.5244688987731934\n",
            "593: 0.545012891292572\n",
            "594: 0.5196378827095032\n",
            "595: 0.4954527020454407\n",
            "596: 0.523658812046051\n",
            "597: 0.5011171698570251\n",
            "598: 0.4974614381790161\n",
            "599: 0.4831680655479431\n",
            "600: 0.5356149673461914\n",
            "input:   tensor([[5, 5, 4, 3, 4, 2, 4, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 2, 5, 3, 4, 2, 5, 4]], device='cuda:0')\n",
            "incorrects: 5\n",
            "601: 0.511276364326477\n",
            "602: 0.47043731808662415\n",
            "603: 0.5557253360748291\n",
            "604: 0.4689865708351135\n",
            "605: 0.47972723841667175\n",
            "606: 0.5120972394943237\n",
            "607: 0.48130595684051514\n",
            "608: 0.4996423125267029\n",
            "609: 0.48403576016426086\n",
            "610: 0.49024713039398193\n",
            "611: 0.49539849162101746\n",
            "612: 0.4557320177555084\n",
            "613: 0.4695361256599426\n",
            "614: 0.47929778695106506\n",
            "615: 0.49807071685791016\n",
            "616: 0.44875842332839966\n",
            "617: 0.4776592552661896\n",
            "618: 0.47728314995765686\n",
            "619: 0.47428983449935913\n",
            "620: 0.4878954291343689\n",
            "621: 0.48938095569610596\n",
            "622: 0.49923548102378845\n",
            "623: 0.463428795337677\n",
            "624: 0.48315107822418213\n",
            "625: 0.4654807448387146\n",
            "626: 0.4349338114261627\n",
            "627: 0.49306875467300415\n",
            "628: 0.4815187156200409\n",
            "629: 0.4964665174484253\n",
            "630: 0.4897628128528595\n",
            "631: 0.4565444886684418\n",
            "632: 0.45528680086135864\n",
            "633: 0.45398247241973877\n",
            "634: 0.4783840477466583\n",
            "635: 0.4329301118850708\n",
            "636: 0.49664634466171265\n",
            "637: 0.4426499009132385\n",
            "638: 0.4796414077281952\n",
            "639: 0.4586051106452942\n",
            "640: 0.44925370812416077\n",
            "641: 0.464376300573349\n",
            "642: 0.4425295293331146\n",
            "643: 0.4499407112598419\n",
            "644: 0.47544148564338684\n",
            "645: 0.4825325608253479\n",
            "646: 0.47206729650497437\n",
            "647: 0.4669092297554016\n",
            "648: 0.45916807651519775\n",
            "649: 0.4479024410247803\n",
            "650: 0.44074147939682007\n",
            "651: 0.43814781308174133\n",
            "652: 0.47352540493011475\n",
            "653: 0.43694964051246643\n",
            "654: 0.4372331202030182\n",
            "655: 0.44805023074150085\n",
            "656: 0.4433238208293915\n",
            "657: 0.47788918018341064\n",
            "658: 0.4332996606826782\n",
            "659: 0.42344704270362854\n",
            "660: 0.4523201286792755\n",
            "661: 0.4381767809391022\n",
            "662: 0.4564828872680664\n",
            "663: 0.4770577847957611\n",
            "664: 0.44175592064857483\n",
            "665: 0.40381065011024475\n",
            "666: 0.4625202417373657\n",
            "667: 0.44070932269096375\n",
            "668: 0.4662425220012665\n",
            "669: 0.42140382528305054\n",
            "670: 0.4597904682159424\n",
            "671: 0.44095557928085327\n",
            "672: 0.4620307683944702\n",
            "673: 0.4488702714443207\n",
            "674: 0.40992945432662964\n",
            "675: 0.4220944344997406\n",
            "676: 0.47594955563545227\n",
            "677: 0.43061748147010803\n",
            "678: 0.4143344461917877\n",
            "679: 0.44675037264823914\n",
            "680: 0.44123655557632446\n",
            "681: 0.4298035204410553\n",
            "682: 0.4253883957862854\n",
            "683: 0.44288402795791626\n",
            "684: 0.41553398966789246\n",
            "685: 0.4238007962703705\n",
            "686: 0.4162537753582001\n",
            "687: 0.4381903111934662\n",
            "688: 0.43175947666168213\n",
            "689: 0.4033445119857788\n",
            "690: 0.42916619777679443\n",
            "691: 0.42847904562950134\n",
            "692: 0.43220585584640503\n",
            "693: 0.4619942307472229\n",
            "694: 0.40950170159339905\n",
            "695: 0.5209552049636841\n",
            "696: 0.44694414734840393\n",
            "697: 0.5086020231246948\n",
            "698: 0.44244256615638733\n",
            "699: 0.478139728307724\n",
            "700: 0.4667406380176544\n",
            "input:   tensor([[4, 5, 3, 5, 3, 4, 5, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 4, 3, 3, 4, 5, 4, 5]], device='cuda:0')\n",
            "incorrects: 7\n",
            "701: 0.49335673451423645\n",
            "702: 0.45298242568969727\n",
            "703: 0.5272513628005981\n",
            "704: 0.47257333993911743\n",
            "705: 0.45798274874687195\n",
            "706: 0.5688758492469788\n",
            "707: 0.4827045798301697\n",
            "708: 0.5267916917800903\n",
            "709: 0.5652974247932434\n",
            "710: 0.4416009783744812\n",
            "711: 0.49800166487693787\n",
            "712: 0.49130693078041077\n",
            "713: 0.46139347553253174\n",
            "714: 0.509303629398346\n",
            "715: 0.4683624505996704\n",
            "716: 0.48107099533081055\n",
            "717: 0.44972556829452515\n",
            "718: 0.462253212928772\n",
            "719: 0.5091464519500732\n",
            "720: 0.4798845648765564\n",
            "721: 0.5127542018890381\n",
            "722: 0.4344371259212494\n",
            "723: 0.44272086024284363\n",
            "724: 0.4388801157474518\n",
            "725: 0.431449830532074\n",
            "726: 0.45738375186920166\n",
            "727: 0.4567559063434601\n",
            "728: 0.4318634867668152\n",
            "729: 0.41477343440055847\n",
            "730: 0.41081705689430237\n",
            "731: 0.42498013377189636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  74%|███████▎  | 735/1000 [00:40<00:13, 18.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "732: 0.4416087865829468\n",
            "733: 0.4338935613632202\n",
            "734: 0.4253292381763458\n",
            "735: 0.4640275835990906\n",
            "736: 0.4437926113605499\n",
            "737: 0.41335397958755493\n",
            "738: 0.3995330333709717\n",
            "739: 0.40192991495132446\n",
            "740: 0.41009485721588135\n",
            "741: 0.4052377939224243\n",
            "742: 0.44076988101005554\n",
            "743: 0.3896525800228119\n",
            "744: 0.42218634486198425\n",
            "745: 0.4161558151245117\n",
            "746: 0.41818809509277344\n",
            "747: 0.42023590207099915\n",
            "748: 0.44871002435684204\n",
            "749: 0.40684977173805237\n",
            "750: 0.4349977374076843\n",
            "751: 0.40076032280921936\n",
            "752: 0.4215726852416992\n",
            "753: 0.44108110666275024\n",
            "754: 0.38700243830680847\n",
            "755: 0.43387800455093384\n",
            "756: 0.4028025269508362\n",
            "757: 0.38800883293151855\n",
            "758: 0.4180164635181427\n",
            "759: 0.44364455342292786\n",
            "760: 0.4305459260940552\n",
            "761: 0.4052961766719818\n",
            "762: 0.45078518986701965\n",
            "763: 0.391659140586853\n",
            "764: 0.38873982429504395\n",
            "765: 0.4360658526420593\n",
            "766: 0.415536493062973\n",
            "767: 0.3929416239261627\n",
            "768: 0.3980906307697296\n",
            "769: 0.39193195104599\n",
            "770: 0.3869918882846832\n",
            "771: 0.41097426414489746\n",
            "772: 0.3830980062484741\n",
            "773: 0.40823861956596375\n",
            "774: 0.3830513060092926\n",
            "775: 0.37262964248657227\n",
            "776: 0.39243221282958984\n",
            "777: 0.3868933320045471\n",
            "778: 0.3867366909980774\n",
            "779: 0.39368146657943726\n",
            "780: 0.3703862130641937\n",
            "781: 0.37178388237953186\n",
            "782: 0.3832423985004425\n",
            "783: 0.38409680128097534\n",
            "784: 0.41224268078804016\n",
            "785: 0.3601478338241577\n",
            "786: 0.38129234313964844\n",
            "787: 0.36368629336357117\n",
            "788: 0.37977951765060425\n",
            "789: 0.39845016598701477\n",
            "790: 0.3901383876800537\n",
            "791: 0.4197401702404022\n",
            "792: 0.40790972113609314\n",
            "793: 0.39800146222114563\n",
            "794: 0.38786718249320984\n",
            "795: 0.38324880599975586\n",
            "796: 0.41066408157348633\n",
            "797: 0.4235597848892212\n",
            "798: 0.3656025230884552\n",
            "799: 0.38962522149086\n",
            "800: 0.4128744602203369\n",
            "input:   tensor([[3, 3, 2, 3, 4, 4, 5, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 3, 2, 4, 3, 5, 2, 4]], device='cuda:0')\n",
            "incorrects: 5\n",
            "801: 0.3862404227256775\n",
            "802: 0.3774125576019287\n",
            "803: 0.39824438095092773\n",
            "804: 0.3662068247795105\n",
            "805: 0.38813111186027527\n",
            "806: 0.3884168863296509\n",
            "807: 0.38812875747680664\n",
            "808: 0.3611390292644501\n",
            "809: 0.4869091510772705\n",
            "810: 0.40906229615211487\n",
            "811: 0.5079153776168823\n",
            "812: 0.480048805475235\n",
            "813: 0.38521507382392883\n",
            "814: 0.39531418681144714\n",
            "815: 0.45677441358566284\n",
            "816: 0.40114539861679077\n",
            "817: 0.46046480536460876\n",
            "818: 0.4723549783229828\n",
            "819: 0.43112650513648987\n",
            "820: 0.3959856629371643\n",
            "821: 0.40639132261276245\n",
            "822: 0.4268551170825958\n",
            "823: 0.4241028428077698\n",
            "824: 0.400422602891922\n",
            "825: 0.4056606888771057\n",
            "826: 0.4266126751899719\n",
            "827: 0.4903155267238617\n",
            "828: 0.4108644723892212\n",
            "829: 0.44399604201316833\n",
            "830: 0.4066271185874939\n",
            "831: 0.39965981245040894\n",
            "832: 0.409371018409729\n",
            "833: 0.3896228075027466\n",
            "834: 0.3909676969051361\n",
            "835: 0.40636733174324036\n",
            "836: 0.4141104817390442\n",
            "837: 0.3857356011867523\n",
            "838: 0.3706711232662201\n",
            "839: 0.419528067111969\n",
            "840: 0.36884042620658875\n",
            "841: 0.40587031841278076\n",
            "842: 0.3635983467102051\n",
            "843: 0.36233335733413696\n",
            "844: 0.3415968120098114\n",
            "845: 0.4080207943916321\n",
            "846: 0.37468695640563965\n",
            "847: 0.39743393659591675\n",
            "848: 0.4150446653366089\n",
            "849: 0.397442102432251\n",
            "850: 0.36423853039741516\n",
            "851: 0.38428348302841187\n",
            "852: 0.36333638429641724\n",
            "853: 0.3349061906337738\n",
            "854: 0.3785820007324219\n",
            "855: 0.37321919202804565\n",
            "856: 0.3766196370124817\n",
            "857: 0.34288647770881653\n",
            "858: 0.4511641263961792\n",
            "859: 0.364591121673584\n",
            "860: 0.36777210235595703\n",
            "861: 0.40445539355278015\n",
            "862: 0.40276557207107544\n",
            "863: 0.3544517159461975\n",
            "864: 0.3471178710460663\n",
            "865: 0.3579436242580414\n",
            "866: 0.388659805059433\n",
            "867: 0.3437776267528534\n",
            "868: 0.4185883402824402\n",
            "869: 0.3808704912662506\n",
            "870: 0.361507385969162\n",
            "871: 0.3457431495189667\n",
            "872: 0.3841802179813385\n",
            "873: 0.3357769846916199\n",
            "874: 0.32030579447746277\n",
            "875: 0.340542733669281\n",
            "876: 0.3536694347858429\n",
            "877: 0.332771360874176\n",
            "878: 0.3096241056919098\n",
            "879: 0.3245287537574768\n",
            "880: 0.33489784598350525\n",
            "881: 0.31668826937675476\n",
            "882: 0.34763437509536743\n",
            "883: 0.33362025022506714\n",
            "884: 0.37898844480514526\n",
            "885: 0.3140442967414856\n",
            "886: 0.360159307718277\n",
            "887: 0.31445246934890747\n",
            "888: 0.3027862310409546\n",
            "889: 0.3075483441352844\n",
            "890: 0.3517208695411682\n",
            "891: 0.3498462736606598\n",
            "892: 0.30745935440063477\n",
            "893: 0.356355756521225\n",
            "894: 0.32475537061691284\n",
            "895: 0.32402846217155457\n",
            "896: 0.3208134174346924\n",
            "897: 0.3016233742237091\n",
            "898: 0.3731965720653534\n",
            "899: 0.3364834785461426\n",
            "900: 0.3453845977783203\n",
            "input:   tensor([[4, 5, 3, 5, 2, 2, 2, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 4, 5, 2, 3, 2, 5, 2]], device='cuda:0')\n",
            "incorrects: 6\n",
            "901: 0.31188613176345825\n",
            "902: 0.3961719572544098\n",
            "903: 0.3106233477592468\n",
            "904: 0.268298476934433\n",
            "905: 0.3362058997154236\n",
            "906: 0.3519241213798523\n",
            "907: 0.31605610251426697\n",
            "908: 0.34362509846687317\n",
            "909: 0.34867921471595764\n",
            "910: 0.31271275877952576\n",
            "911: 0.30690473318099976\n",
            "912: 0.3529756963253021\n",
            "913: 0.3372623920440674\n",
            "914: 0.3009870946407318\n",
            "915: 0.28922274708747864\n",
            "916: 0.29337891936302185\n",
            "917: 0.30199992656707764\n",
            "918: 0.28164446353912354\n",
            "919: 0.2945571541786194\n",
            "920: 0.2914370596408844\n",
            "921: 0.27935880422592163\n",
            "922: 0.3181438148021698\n",
            "923: 0.3160443902015686\n",
            "924: 0.2811610996723175\n",
            "925: 0.26651567220687866\n",
            "926: 0.2881145775318146\n",
            "927: 0.27756261825561523\n",
            "928: 0.2969949543476105\n",
            "929: 0.24980086088180542\n",
            "930: 0.26246213912963867\n",
            "931: 0.2822190225124359\n",
            "932: 0.25611597299575806\n",
            "933: 0.2821381688117981\n",
            "934: 0.2891165614128113\n",
            "935: 0.36404046416282654\n",
            "936: 0.2777530550956726\n",
            "937: 0.32104992866516113\n",
            "938: 0.33519136905670166\n",
            "939: 0.3433185815811157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  94%|█████████▍| 942/1000 [00:50<00:02, 19.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "940: 0.2780251204967499\n",
            "941: 0.3489471673965454\n",
            "942: 0.3219373822212219\n",
            "943: 0.32006511092185974\n",
            "944: 0.287994384765625\n",
            "945: 0.3195747435092926\n",
            "946: 0.24891731142997742\n",
            "947: 0.2845100164413452\n",
            "948: 0.30493804812431335\n",
            "949: 0.34677281975746155\n",
            "950: 0.3081819415092468\n",
            "951: 0.26820099353790283\n",
            "952: 0.25609081983566284\n",
            "953: 0.26454564929008484\n",
            "954: 0.24327512085437775\n",
            "955: 0.24684742093086243\n",
            "956: 0.29283076524734497\n",
            "957: 0.26320382952690125\n",
            "958: 0.2556506097316742\n",
            "959: 0.24689587950706482\n",
            "960: 0.3048698902130127\n",
            "961: 0.22283144295215607\n",
            "962: 0.2604905366897583\n",
            "963: 0.2393389344215393\n",
            "964: 0.24247199296951294\n",
            "965: 0.22451430559158325\n",
            "966: 0.23703710734844208\n",
            "967: 0.22739265859127045\n",
            "968: 0.22064292430877686\n",
            "969: 0.21850770711898804\n",
            "970: 0.20160435140132904\n",
            "971: 0.21377970278263092\n",
            "972: 0.22758297622203827\n",
            "973: 0.16810797154903412\n",
            "974: 0.2182527333498001\n",
            "975: 0.2112853229045868\n",
            "976: 0.21269434690475464\n",
            "977: 0.23143872618675232\n",
            "978: 0.21455417573451996\n",
            "979: 0.24093268811702728\n",
            "980: 0.20328621566295624\n",
            "981: 0.20353031158447266\n",
            "982: 0.2270665317773819\n",
            "983: 0.25055721402168274\n",
            "984: 0.20728270709514618\n",
            "985: 0.22717270255088806\n",
            "986: 0.21055720746517181\n",
            "987: 0.18924041092395782\n",
            "988: 0.20359981060028076\n",
            "989: 0.2343878149986267\n",
            "990: 0.21037369966506958\n",
            "991: 0.20301751792430878\n",
            "992: 0.1720777451992035\n",
            "993: 0.19442011415958405\n",
            "994: 0.21548530459403992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:53<00:00, 18.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "995: 0.1511784940958023\n",
            "996: 0.1793159395456314\n",
            "997: 0.21370358765125275\n",
            "998: 0.18582852184772491\n",
            "999: 0.1681508868932724\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "b573c080-77d4-4b8d-b70c-8014a9d70e3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 81.25%\n"
          ]
        }
      ]
    }
  ]
}