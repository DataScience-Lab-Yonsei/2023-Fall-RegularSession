{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers architecture를 받아와 구축해보자!\n",
        "\n",
        "Transformers 강의 + 실습까지 수강하시느라 너무 수고 많으셨습니다! 저도 저번 기수 당시 transformers를 처음 접했는데, 모델의 구조가 난해하고 쓰인 개념들도 어려워서 이해하는데 많은 시간이 걸렸었네요.. 그래도 transformers 모델이 현재 contemporary AI technology에 쓰이지 않는 곳이 없다보니, 어려운 내용들이 다수 있지만 힘주어서 중요한 내용들로 채워넣으려고 노력했습니다 수고하셨습니다 XD\n",
        "\n",
        "Transformers은 개념도 개념이지만, 매번 새롭게 attention 코드를 짜고, encoder와 decoder 구조를 구축하는 것도 막막하실 겁니다! 다행히도 transformers architecture는 워낙 유명해서 이제 코드 몇줄만 `딸깍`해도 최신 논문기반 transformer 구조를 `huggingface` 혹은 `github`에서 받아서 사용할 수 있습니다 :D 이번 실습에는 초심자가 사용하기는 어렵지만 `x-transformers`에서 저희가 구축한 transformers 구조를 받아와, 예시 문장을 출력하는 것까지 마무리할 예정입니다!\n",
        "\n",
        "transformers architecture가 2017년 나온 이후로, 이 architecture를 기반으로 한 여러 모델들이 나왔고, 또한 base model에 대해서도 여러 개선점들이 추가되었습니다. `x-transformers`은 이 개선된 model들을 코드 몇줄을 추가해서 적용 가능하게 하는 라이브러리로, 최신 논문 동향을 파악하고 있어야 한다는 점에서 어렵지만 그만큼 성능이 뒷받침해주는 코드들을 모아둔 라이브러리입니다.\n",
        "\n",
        "TMI가 생각보다 길어졌는데, 아무튼 이번 과제는 따로 작성해 넣어야할 부분은 없고, 제가 드리는 코드를 그대로 실행하기만 하면 되는 과정으로 추가했습니다. 이제 개강이 얼마 남지 않았는데, 다들 화이팅입니다 XD"
      ],
      "metadata": {
        "id": "A5fMGVbqRuGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Colab GPU 환경에서 구동하세요!"
      ],
      "metadata": {
        "id": "DPL6mUynVaU9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXjqwGEyQMve",
        "outputId": "fc2a56f1-94ab-4fbd-819e-f2ca3dde67d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting x-transformers\n",
            "  Downloading x_transformers-1.19.1-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from x-transformers) (2.0.1+cu118)\n",
            "Collecting einops>=0.6.1 (from x-transformers)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->x-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6->x-transformers) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->x-transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->x-transformers) (1.3.0)\n",
            "Installing collected packages: einops, x-transformers\n",
            "Successfully installed einops-0.6.1 x-transformers-1.19.1\n"
          ]
        }
      ],
      "source": [
        "!pip install x-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from x_transformers import XTransformer\n",
        "\n",
        "## Transformers Architectures 받아오\n",
        "model = XTransformer(\n",
        "    ## 모델의 차원 (논문 = 512)\n",
        "    dim = 16,\n",
        "    ## encoder token의 개수 (논문 = 256)\n",
        "    enc_num_tokens = 16,\n",
        "    ## encoder 반복 횟수 (논문 = 6)\n",
        "    enc_depth = 6,\n",
        "    ## multihead attention n_heads 개수 (논문 = 8)\n",
        "    enc_heads = 8,\n",
        "    ## encoder token의 max sequence length (논문 = 1024)\n",
        "    enc_max_seq_len = 32,\n",
        "    ## (논문 = 256)\n",
        "    dec_num_tokens = 16,\n",
        "    dec_depth = 6,\n",
        "    dec_heads = 8,\n",
        "    ## (논문 = 1024)\n",
        "    dec_max_seq_len = 32,\n",
        "    tie_token_emb = True\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "bJ0qDgPOQSN-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## NUM_BATCHES = Epoches의 개수\n",
        "## BATCH_SIZE = 하나의 batch에 들어갈 sample의 개수\n",
        "## LEARNING_RATE = learning rate\n",
        "## GENERATE_EVERY = 100번마다 한번씩 generate해서 accuracy확인\n",
        "## NUM_TOKENS = 데이터 내 유니크한 토큰의 수\n",
        "## ENC_SEQ_LEN = encoder sequence length\n",
        "\n",
        "NUM_BATCHES = int(1e3)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 3e-4\n",
        "GENERATE_EVERY  = 100\n",
        "NUM_TOKENS = 4 + 2\n",
        "ENC_SEQ_LEN = 8\n",
        "DEC_SEQ_LEN = 16 + 1"
      ],
      "metadata": {
        "id": "KDsaOoz4UDF8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformer 모델에 넣을 임의의 src, tgt, src_mask 생성\n",
        "\n",
        "def cycle():\n",
        "    while True:\n",
        "        prefix = torch.ones((BATCH_SIZE, 1)).long().cuda()\n",
        "        src = torch.randint(2, NUM_TOKENS, (BATCH_SIZE, ENC_SEQ_LEN)).long().cuda()\n",
        "        tgt = torch.cat((prefix, src, src), 1)\n",
        "        src_mask = torch.ones(BATCH_SIZE, src.shape[1]).bool().cuda()\n",
        "        yield (src, tgt, src_mask)"
      ],
      "metadata": {
        "id": "NwlWGM0YUFxG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Train Model\n",
        "\n",
        "import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "## loss update 해가면서 학습\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    src, tgt, src_mask = next(cycle())\n",
        "\n",
        "    loss = model(src, tgt, mask=src_mask)\n",
        "    loss.backward()\n",
        "    print(f'{i}: {loss.item()}')\n",
        "\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    ## 매 N(100)번마다 accuracy 측정\n",
        "    if i != 0 and i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        src, _, src_mask = next(cycle())\n",
        "        src, src_mask = src[:1], src_mask[:1]\n",
        "        start_tokens = (torch.ones((1, 1)) * 1).long().cuda()\n",
        "\n",
        "        sample = model.generate(src, start_tokens, ENC_SEQ_LEN, mask = src_mask)\n",
        "        incorrects = (src != sample).abs().sum()\n",
        "\n",
        "        print(f\"input:  \", src)\n",
        "        print(f\"predicted output:  \", sample)\n",
        "        print(f\"incorrects: {incorrects}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1KUCYbiUGJk",
        "outputId": "c221c2c0-ccda-4669-bd0e-63a232096ca1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:   0%|          | 0/1000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 3.5363845825195312\n",
            "1: 2.5506021976470947\n",
            "2: 2.264939785003662\n",
            "3: 2.1915524005889893\n",
            "4: 2.1163032054901123\n",
            "5: 2.1038739681243896\n",
            "6: 2.0782885551452637\n",
            "7: 2.0580554008483887\n",
            "8: 2.0479843616485596\n",
            "9: 2.0629780292510986\n",
            "10: 2.0210423469543457\n",
            "11: 2.0202560424804688\n",
            "12: 2.0394973754882812\n",
            "13: 1.9996416568756104\n",
            "14: 2.001347780227661\n",
            "15: 1.9803589582443237\n",
            "16: 2.037302017211914\n",
            "17: 1.9408445358276367\n",
            "18: 1.9772305488586426\n",
            "19: 1.9449580907821655\n",
            "20: 1.9746168851852417\n",
            "21: 1.937604308128357\n",
            "22: 1.9570003747940063\n",
            "23: 1.9667229652404785\n",
            "24: 1.9157633781433105\n",
            "25: 1.9036816358566284\n",
            "26: 1.8998273611068726\n",
            "27: 1.865684151649475\n",
            "28: 1.903259515762329\n",
            "29: 1.8805909156799316\n",
            "30: 1.8854260444641113\n",
            "31: 1.88181734085083\n",
            "32: 1.8762459754943848\n",
            "33: 1.8737146854400635\n",
            "34: 1.8870985507965088\n",
            "35: 1.8390964269638062\n",
            "36: 1.8458092212677002\n",
            "37: 1.900241732597351\n",
            "38: 1.7807025909423828\n",
            "39: 1.8230148553848267\n",
            "40: 1.838757038116455\n",
            "41: 1.8340129852294922\n",
            "42: 1.8241393566131592\n",
            "43: 1.8297234773635864\n",
            "44: 1.7884249687194824\n",
            "45: 1.8296021223068237\n",
            "46: 1.7559125423431396\n",
            "47: 1.7664483785629272\n",
            "48: 1.7621479034423828\n",
            "49: 1.7734663486480713\n",
            "50: 1.7290118932724\n",
            "51: 1.7480522394180298\n",
            "52: 1.7632073163986206\n",
            "53: 1.7538113594055176\n",
            "54: 1.731448769569397\n",
            "55: 1.7338898181915283\n",
            "56: 1.70314621925354\n",
            "57: 1.7311148643493652\n",
            "58: 1.778733730316162\n",
            "59: 1.7030168771743774\n",
            "60: 1.7503725290298462\n",
            "61: 1.7260913848876953\n",
            "62: 1.6878528594970703\n",
            "63: 1.697084665298462\n",
            "64: 1.723344087600708\n",
            "65: 1.6806191205978394\n",
            "66: 1.6458420753479004\n",
            "67: 1.7328038215637207\n",
            "68: 1.6672227382659912\n",
            "69: 1.6877431869506836\n",
            "70: 1.7092527151107788\n",
            "71: 1.7003562450408936\n",
            "72: 1.6887283325195312\n",
            "73: 1.6612449884414673\n",
            "74: 1.637371301651001\n",
            "75: 1.6641900539398193\n",
            "76: 1.682928442955017\n",
            "77: 1.6757110357284546\n",
            "78: 1.628403663635254\n",
            "79: 1.669906497001648\n",
            "80: 1.663970708847046\n",
            "81: 1.6592340469360352\n",
            "82: 1.6322691440582275\n",
            "83: 1.6552878618240356\n",
            "84: 1.613666296005249\n",
            "85: 1.6290112733840942\n",
            "86: 1.6249247789382935\n",
            "87: 1.624130129814148\n",
            "88: 1.6609697341918945\n",
            "89: 1.6137216091156006\n",
            "90: 1.598213791847229\n",
            "91: 1.620344877243042\n",
            "92: 1.6196837425231934\n",
            "93: 1.5747028589248657\n",
            "94: 1.6164129972457886\n",
            "95: 1.592955231666565\n",
            "96: 1.5828856229782104\n",
            "97: 1.6222906112670898\n",
            "98: 1.59061598777771\n",
            "99: 1.5776469707489014\n",
            "100: 1.5832133293151855\n",
            "input:   tensor([[4, 4, 5, 3, 2, 2, 3, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[3, 4, 4, 3, 3, 4, 4, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "101: 1.576782464981079\n",
            "102: 1.6040034294128418\n",
            "103: 1.602531909942627\n",
            "104: 1.587986707687378\n",
            "105: 1.5470200777053833\n",
            "106: 1.5621252059936523\n",
            "107: 1.558007001876831\n",
            "108: 1.5461865663528442\n",
            "109: 1.5465742349624634\n",
            "110: 1.5565904378890991\n",
            "111: 1.5632927417755127\n",
            "112: 1.555653691291809\n",
            "113: 1.5772989988327026\n",
            "114: 1.5591331720352173\n",
            "115: 1.5478246212005615\n",
            "116: 1.5534921884536743\n",
            "117: 1.543699860572815\n",
            "118: 1.4903355836868286\n",
            "119: 1.5509874820709229\n",
            "120: 1.5251219272613525\n",
            "121: 1.483141303062439\n",
            "122: 1.509353518486023\n",
            "123: 1.4846280813217163\n",
            "124: 1.5249284505844116\n",
            "125: 1.4960728883743286\n",
            "126: 1.5018583536148071\n",
            "127: 1.5133930444717407\n",
            "128: 1.4490346908569336\n",
            "129: 1.4865763187408447\n",
            "130: 1.4989608526229858\n",
            "131: 1.4914144277572632\n",
            "132: 1.49631929397583\n",
            "133: 1.521028757095337\n",
            "134: 1.4598665237426758\n",
            "135: 1.4742950201034546\n",
            "136: 1.4602915048599243\n",
            "137: 1.4828368425369263\n",
            "138: 1.5045655965805054\n",
            "139: 1.48651921749115\n",
            "140: 1.476872444152832\n",
            "141: 1.4815220832824707\n",
            "142: 1.473964810371399\n",
            "143: 1.4479200839996338\n",
            "144: 1.4743586778640747\n",
            "145: 1.4496543407440186\n",
            "146: 1.4434832334518433\n",
            "147: 1.4009263515472412\n",
            "148: 1.4032485485076904\n",
            "149: 1.4056179523468018\n",
            "150: 1.3910654783248901\n",
            "151: 1.4193576574325562\n",
            "152: 1.4231750965118408\n",
            "153: 1.390728235244751\n",
            "154: 1.4108086824417114\n",
            "155: 1.4512265920639038\n",
            "156: 1.431571364402771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  16%|█▌        | 158/1000 [00:10<00:53, 15.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157: 1.4008640050888062\n",
            "158: 1.3414876461029053\n",
            "159: 1.3916746377944946\n",
            "160: 1.3706940412521362\n",
            "161: 1.3766337633132935\n",
            "162: 1.3539798259735107\n",
            "163: 1.3607406616210938\n",
            "164: 1.43787682056427\n",
            "165: 1.4227697849273682\n",
            "166: 1.3931187391281128\n",
            "167: 1.3944611549377441\n",
            "168: 1.4087345600128174\n",
            "169: 1.359459638595581\n",
            "170: 1.3567333221435547\n",
            "171: 1.427065134048462\n",
            "172: 1.3371367454528809\n",
            "173: 1.3463525772094727\n",
            "174: 1.383100986480713\n",
            "175: 1.3941693305969238\n",
            "176: 1.362324833869934\n",
            "177: 1.350888729095459\n",
            "178: 1.3419662714004517\n",
            "179: 1.3503172397613525\n",
            "180: 1.3416064977645874\n",
            "181: 1.3637659549713135\n",
            "182: 1.3054044246673584\n",
            "183: 1.3577377796173096\n",
            "184: 1.3595693111419678\n",
            "185: 1.369030475616455\n",
            "186: 1.3408730030059814\n",
            "187: 1.3396656513214111\n",
            "188: 1.3627790212631226\n",
            "189: 1.3135662078857422\n",
            "190: 1.3322205543518066\n",
            "191: 1.2711786031723022\n",
            "192: 1.351226806640625\n",
            "193: 1.324966549873352\n",
            "194: 1.272853136062622\n",
            "195: 1.2978448867797852\n",
            "196: 1.3033660650253296\n",
            "197: 1.2445307970046997\n",
            "198: 1.3250333070755005\n",
            "199: 1.3319741487503052\n",
            "200: 1.2713372707366943\n",
            "input:   tensor([[5, 4, 3, 4, 3, 3, 4, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 4, 3, 3, 3, 3, 4]], device='cuda:0')\n",
            "incorrects: 6\n",
            "201: 1.3187731504440308\n",
            "202: 1.2539926767349243\n",
            "203: 1.2816733121871948\n",
            "204: 1.2698355913162231\n",
            "205: 1.3084797859191895\n",
            "206: 1.311354160308838\n",
            "207: 1.2763170003890991\n",
            "208: 1.2673234939575195\n",
            "209: 1.278777003288269\n",
            "210: 1.271120309829712\n",
            "211: 1.2717206478118896\n",
            "212: 1.2359263896942139\n",
            "213: 1.226629376411438\n",
            "214: 1.2860840559005737\n",
            "215: 1.2640947103500366\n",
            "216: 1.2448410987854004\n",
            "217: 1.2432199716567993\n",
            "218: 1.1909159421920776\n",
            "219: 1.2355455160140991\n",
            "220: 1.1958942413330078\n",
            "221: 1.2237142324447632\n",
            "222: 1.1611404418945312\n",
            "223: 1.2333848476409912\n",
            "224: 1.191864252090454\n",
            "225: 1.171531319618225\n",
            "226: 1.221386194229126\n",
            "227: 1.2173908948898315\n",
            "228: 1.230424404144287\n",
            "229: 1.1994099617004395\n",
            "230: 1.1883835792541504\n",
            "231: 1.2294626235961914\n",
            "232: 1.180222749710083\n",
            "233: 1.1424704790115356\n",
            "234: 1.188258171081543\n",
            "235: 1.1526435613632202\n",
            "236: 1.1803207397460938\n",
            "237: 1.1873011589050293\n",
            "238: 1.2197262048721313\n",
            "239: 1.1448278427124023\n",
            "240: 1.1548957824707031\n",
            "241: 1.1868507862091064\n",
            "242: 1.1362518072128296\n",
            "243: 1.1616390943527222\n",
            "244: 1.103585124015808\n",
            "245: 1.1536206007003784\n",
            "246: 1.132643222808838\n",
            "247: 1.1148942708969116\n",
            "248: 1.1329433917999268\n",
            "249: 1.137818694114685\n",
            "250: 1.1541838645935059\n",
            "251: 1.1030206680297852\n",
            "252: 1.1377382278442383\n",
            "253: 1.122302532196045\n",
            "254: 1.1157103776931763\n",
            "255: 1.1242040395736694\n",
            "256: 1.14573335647583\n",
            "257: 1.1097440719604492\n",
            "258: 1.1099754571914673\n",
            "259: 1.1035184860229492\n",
            "260: 1.1393541097640991\n",
            "261: 1.0700141191482544\n",
            "262: 1.105348825454712\n",
            "263: 1.121315360069275\n",
            "264: 1.1100698709487915\n",
            "265: 1.0925815105438232\n",
            "266: 1.0663715600967407\n",
            "267: 1.0533784627914429\n",
            "268: 1.0664798021316528\n",
            "269: 1.0523838996887207\n",
            "270: 1.0665804147720337\n",
            "271: 1.0805219411849976\n",
            "272: 1.0758004188537598\n",
            "273: 1.0798630714416504\n",
            "274: 1.0709105730056763\n",
            "275: 1.0418784618377686\n",
            "276: 1.047935128211975\n",
            "277: 1.112359881401062\n",
            "278: 1.0281106233596802\n",
            "279: 1.1198009252548218\n",
            "280: 1.029299020767212\n",
            "281: 1.0430032014846802\n",
            "282: 1.0671242475509644\n",
            "283: 1.0292810201644897\n",
            "284: 1.0261131525039673\n",
            "285: 1.07794189453125\n",
            "286: 0.9895360469818115\n",
            "287: 1.0480619668960571\n",
            "288: 1.0237481594085693\n",
            "289: 1.029264211654663\n",
            "290: 0.9850479364395142\n",
            "291: 1.0540878772735596\n",
            "292: 1.0223503112792969\n",
            "293: 1.0138548612594604\n",
            "294: 1.0384345054626465\n",
            "295: 1.05173659324646\n",
            "296: 1.0017555952072144\n",
            "297: 1.0448734760284424\n",
            "298: 0.981330394744873\n",
            "299: 0.9952425956726074\n",
            "300: 0.9690033197402954\n",
            "input:   tensor([[5, 5, 4, 2, 3, 5, 2, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 5, 2, 5, 4, 3, 2, 5]], device='cuda:0')\n",
            "incorrects: 4\n",
            "301: 1.0042006969451904\n",
            "302: 1.0094411373138428\n",
            "303: 1.00901198387146\n",
            "304: 0.9959087371826172\n",
            "305: 1.0057048797607422\n",
            "306: 0.9938703179359436\n",
            "307: 1.0127882957458496\n",
            "308: 1.001159429550171\n",
            "309: 0.9315661191940308\n",
            "310: 0.9940494298934937\n",
            "311: 0.9510380029678345\n",
            "312: 1.0023841857910156\n",
            "313: 0.9941094517707825\n",
            "314: 0.9834848642349243\n",
            "315: 0.9985275864601135\n",
            "316: 0.9642301797866821\n",
            "317: 0.9699557423591614\n",
            "318: 0.9732683300971985\n",
            "319: 0.9405112266540527\n",
            "320: 0.9500146508216858\n",
            "321: 0.9895296096801758\n",
            "322: 0.9988451600074768\n",
            "323: 1.0133551359176636\n",
            "324: 0.9754897952079773\n",
            "325: 1.0010532140731812\n",
            "326: 0.9457386136054993\n",
            "327: 0.9916894435882568\n",
            "328: 0.98721843957901\n",
            "329: 0.9144648313522339\n",
            "330: 0.9766867756843567\n",
            "331: 0.9122647643089294\n",
            "332: 0.9606137871742249\n",
            "333: 0.9788269996643066\n",
            "334: 0.9203978180885315\n",
            "335: 0.9115029573440552\n",
            "336: 0.8624476194381714\n",
            "337: 0.8991641402244568\n",
            "338: 0.8986293077468872\n",
            "339: 0.8895201086997986\n",
            "340: 0.8763629794120789\n",
            "341: 0.905478298664093\n",
            "342: 0.8797618746757507\n",
            "343: 0.9097217917442322\n",
            "344: 0.8676158785820007\n",
            "345: 0.8522922992706299\n",
            "346: 0.8576701879501343\n",
            "347: 0.872454822063446\n",
            "348: 0.9024861454963684\n",
            "349: 0.8716589212417603\n",
            "350: 0.8853832483291626\n",
            "351: 0.822356104850769\n",
            "352: 0.9082817435264587\n",
            "353: 0.8691209554672241\n",
            "354: 0.9217216968536377\n",
            "355: 0.8696830868721008\n",
            "356: 0.8662492632865906\n",
            "357: 0.8533002734184265\n",
            "358: 0.9003306031227112\n",
            "359: 0.9026436805725098\n",
            "360: 0.8685460090637207\n",
            "361: 0.9225850105285645\n",
            "362: 0.8645853996276855\n",
            "363: 0.8688578605651855\n",
            "364: 0.8496672511100769\n",
            "365: 0.827991783618927\n",
            "366: 0.9132744073867798\n",
            "367: 0.8603501319885254\n",
            "368: 0.8361030220985413\n",
            "369: 0.8237189054489136\n",
            "370: 0.8754804134368896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  38%|███▊      | 376/1000 [00:20<00:32, 19.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "371: 0.8616665601730347\n",
            "372: 0.8568291664123535\n",
            "373: 0.9188927412033081\n",
            "374: 0.8223289251327515\n",
            "375: 0.8863011598587036\n",
            "376: 0.8385462164878845\n",
            "377: 0.8805311322212219\n",
            "378: 0.8517838716506958\n",
            "379: 0.8067492246627808\n",
            "380: 0.8327056169509888\n",
            "381: 0.8638747334480286\n",
            "382: 0.8098494410514832\n",
            "383: 0.8511287569999695\n",
            "384: 0.8763384819030762\n",
            "385: 0.7942199110984802\n",
            "386: 0.8361011147499084\n",
            "387: 0.7781546115875244\n",
            "388: 0.7972903847694397\n",
            "389: 0.809349775314331\n",
            "390: 0.794104278087616\n",
            "391: 0.7783336043357849\n",
            "392: 0.7779484391212463\n",
            "393: 0.7814876437187195\n",
            "394: 0.7589930295944214\n",
            "395: 0.7487598657608032\n",
            "396: 0.7551804780960083\n",
            "397: 0.7727528810501099\n",
            "398: 0.7732232213020325\n",
            "399: 0.7404147386550903\n",
            "400: 0.782452404499054\n",
            "input:   tensor([[5, 2, 2, 2, 3, 5, 3, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[2, 3, 5, 2, 4, 2, 3, 5]], device='cuda:0')\n",
            "incorrects: 6\n",
            "401: 0.7654131054878235\n",
            "402: 0.7920652627944946\n",
            "403: 0.7527590394020081\n",
            "404: 0.733409583568573\n",
            "405: 0.7691285610198975\n",
            "406: 0.7404714226722717\n",
            "407: 0.7419158816337585\n",
            "408: 0.772022008895874\n",
            "409: 0.7574200630187988\n",
            "410: 0.7645031213760376\n",
            "411: 0.7833818793296814\n",
            "412: 0.7386693358421326\n",
            "413: 0.7607291340827942\n",
            "414: 0.7550162076950073\n",
            "415: 0.7406513690948486\n",
            "416: 0.73623126745224\n",
            "417: 0.7364668846130371\n",
            "418: 0.7425686120986938\n",
            "419: 0.7628920078277588\n",
            "420: 0.7171347141265869\n",
            "421: 0.7114410996437073\n",
            "422: 0.7450991868972778\n",
            "423: 0.7253732085227966\n",
            "424: 0.7073594927787781\n",
            "425: 0.7312982082366943\n",
            "426: 0.725607693195343\n",
            "427: 0.6952501535415649\n",
            "428: 0.6876642107963562\n",
            "429: 0.6889278888702393\n",
            "430: 0.7381106615066528\n",
            "431: 0.6852689385414124\n",
            "432: 0.7675172090530396\n",
            "433: 0.6785504817962646\n",
            "434: 0.7436370253562927\n",
            "435: 0.7061820030212402\n",
            "436: 0.7323442101478577\n",
            "437: 0.7461718916893005\n",
            "438: 0.6878966689109802\n",
            "439: 0.7113766670227051\n",
            "440: 0.7288718223571777\n",
            "441: 0.7305001020431519\n",
            "442: 0.7324973344802856\n",
            "443: 0.676973819732666\n",
            "444: 0.7707033157348633\n",
            "445: 0.7076989412307739\n",
            "446: 0.718393087387085\n",
            "447: 0.7270972728729248\n",
            "448: 0.7040019631385803\n",
            "449: 0.7099748849868774\n",
            "450: 0.7252891063690186\n",
            "451: 0.7260724306106567\n",
            "452: 0.7527104616165161\n",
            "453: 0.7054911851882935\n",
            "454: 0.7610219717025757\n",
            "455: 0.7566608786582947\n",
            "456: 0.6986441016197205\n",
            "457: 0.7213574647903442\n",
            "458: 0.7347967028617859\n",
            "459: 0.6968632340431213\n",
            "460: 0.7454293370246887\n",
            "461: 0.6725236773490906\n",
            "462: 0.7125222086906433\n",
            "463: 0.6744483113288879\n",
            "464: 0.7183206677436829\n",
            "465: 0.6912886500358582\n",
            "466: 0.6826710104942322\n",
            "467: 0.6941459774971008\n",
            "468: 0.6770370006561279\n",
            "469: 0.6535081267356873\n",
            "470: 0.661030650138855\n",
            "471: 0.6796290874481201\n",
            "472: 0.6993167400360107\n",
            "473: 0.6539180278778076\n",
            "474: 0.6571378707885742\n",
            "475: 0.6598206758499146\n",
            "476: 0.6593731641769409\n",
            "477: 0.6432321071624756\n",
            "478: 0.6349194049835205\n",
            "479: 0.681136965751648\n",
            "480: 0.6448392868041992\n",
            "481: 0.6713508367538452\n",
            "482: 0.6823183298110962\n",
            "483: 0.6402902007102966\n",
            "484: 0.6158723831176758\n",
            "485: 0.6569071412086487\n",
            "486: 0.6315802931785583\n",
            "487: 0.6112537384033203\n",
            "488: 0.6146915555000305\n",
            "489: 0.6217537522315979\n",
            "490: 0.6206926107406616\n",
            "491: 0.6340455412864685\n",
            "492: 0.575462818145752\n",
            "493: 0.6232057809829712\n",
            "494: 0.6313754320144653\n",
            "495: 0.6059651970863342\n",
            "496: 0.6464290618896484\n",
            "497: 0.6109561920166016\n",
            "498: 0.6153821349143982\n",
            "499: 0.6058067083358765\n",
            "500: 0.6281241774559021\n",
            "input:   tensor([[4, 5, 5, 5, 5, 5, 4, 5]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 5, 4, 5, 4, 5, 2, 5]], device='cuda:0')\n",
            "incorrects: 4\n",
            "501: 0.6164957284927368\n",
            "502: 0.644518256187439\n",
            "503: 0.5975855588912964\n",
            "504: 0.6273971796035767\n",
            "505: 0.6150327324867249\n",
            "506: 0.599797785282135\n",
            "507: 0.5682812333106995\n",
            "508: 0.5906765460968018\n",
            "509: 0.579539954662323\n",
            "510: 0.5639781355857849\n",
            "511: 0.5722699761390686\n",
            "512: 0.5644827485084534\n",
            "513: 0.5781853199005127\n",
            "514: 0.5953863859176636\n",
            "515: 0.5830078125\n",
            "516: 0.6272863149642944\n",
            "517: 0.5999366044998169\n",
            "518: 0.5951192378997803\n",
            "519: 0.5670907497406006\n",
            "520: 0.5856006741523743\n",
            "521: 0.5885745286941528\n",
            "522: 0.5831446647644043\n",
            "523: 0.5769258141517639\n",
            "524: 0.5937098860740662\n",
            "525: 0.5860140919685364\n",
            "526: 0.5716028809547424\n",
            "527: 0.5919108390808105\n",
            "528: 0.529866635799408\n",
            "529: 0.584625780582428\n",
            "530: 0.6022162437438965\n",
            "531: 0.5756048560142517\n",
            "532: 0.5751008987426758\n",
            "533: 0.565281331539154\n",
            "534: 0.5726356506347656\n",
            "535: 0.6090942025184631\n",
            "536: 0.5811549425125122\n",
            "537: 0.5347940921783447\n",
            "538: 0.5702921152114868\n",
            "539: 0.5567546486854553\n",
            "540: 0.5640795230865479\n",
            "541: 0.5612857937812805\n",
            "542: 0.5512644052505493\n",
            "543: 0.532799243927002\n",
            "544: 0.578123927116394\n",
            "545: 0.5607591867446899\n",
            "546: 0.5707440376281738\n",
            "547: 0.6055272221565247\n",
            "548: 0.5494363307952881\n",
            "549: 0.6071897745132446\n",
            "550: 0.5587639808654785\n",
            "551: 0.566241443157196\n",
            "552: 0.6426537036895752\n",
            "553: 0.5699111223220825\n",
            "554: 0.6036428213119507\n",
            "555: 0.5910706520080566\n",
            "556: 0.607982337474823\n",
            "557: 0.5878297090530396\n",
            "558: 0.5613307952880859\n",
            "559: 0.5463913679122925\n",
            "560: 0.5829659700393677\n",
            "561: 0.564944863319397\n",
            "562: 0.5823150873184204\n",
            "563: 0.5626981854438782\n",
            "564: 0.5905382037162781\n",
            "565: 0.6157418489456177\n",
            "566: 0.5329615473747253\n",
            "567: 0.5455049276351929\n",
            "568: 0.5425766110420227\n",
            "569: 0.5639650225639343\n",
            "570: 0.5382497310638428\n",
            "571: 0.5735733509063721\n",
            "572: 0.5135431885719299\n",
            "573: 0.5357620120048523\n",
            "574: 0.5460796356201172\n",
            "575: 0.5420290231704712\n",
            "576: 0.5690414309501648\n",
            "577: 0.5445616245269775\n",
            "578: 0.5665307641029358\n",
            "579: 0.5587443709373474\n",
            "580: 0.5878197550773621\n",
            "581: 0.6068006157875061\n",
            "582: 0.5306901931762695\n",
            "583: 0.5621232986450195\n",
            "584: 0.5350638628005981\n",
            "585: 0.5533154010772705\n",
            "586: 0.5788262486457825\n",
            "587: 0.5728884339332581\n",
            "588: 0.572270393371582\n",
            "589: 0.5622442960739136\n",
            "590: 0.5393469929695129\n",
            "591: 0.6167905330657959\n",
            "592: 0.548197865486145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  59%|█████▉    | 594/1000 [00:30<00:20, 20.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "593: 0.6201993227005005\n",
            "594: 0.5860369801521301\n",
            "595: 0.5901767015457153\n",
            "596: 0.5635480880737305\n",
            "597: 0.541772186756134\n",
            "598: 0.6223844885826111\n",
            "599: 0.5482400059700012\n",
            "600: 0.5323712825775146\n",
            "input:   tensor([[2, 5, 5, 4, 5, 5, 5, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 5, 5, 4, 2, 5, 5, 2]], device='cuda:0')\n",
            "incorrects: 3\n",
            "601: 0.5699364542961121\n",
            "602: 0.5544357895851135\n",
            "603: 0.5613698363304138\n",
            "604: 0.591215193271637\n",
            "605: 0.537032425403595\n",
            "606: 0.5391689538955688\n",
            "607: 0.6059051156044006\n",
            "608: 0.5837838649749756\n",
            "609: 0.5927106142044067\n",
            "610: 0.6013795137405396\n",
            "611: 0.560204267501831\n",
            "612: 0.5672552585601807\n",
            "613: 0.5468578338623047\n",
            "614: 0.5476542711257935\n",
            "615: 0.544449508190155\n",
            "616: 0.594987154006958\n",
            "617: 0.6483073830604553\n",
            "618: 0.5531762838363647\n",
            "619: 0.6261215806007385\n",
            "620: 0.554713249206543\n",
            "621: 0.567674458026886\n",
            "622: 0.6371515989303589\n",
            "623: 0.5740925073623657\n",
            "624: 0.5938554406166077\n",
            "625: 0.6064944863319397\n",
            "626: 0.5413174033164978\n",
            "627: 0.5707780122756958\n",
            "628: 0.5749865770339966\n",
            "629: 0.5683720707893372\n",
            "630: 0.5347265005111694\n",
            "631: 0.5725212693214417\n",
            "632: 0.576416552066803\n",
            "633: 0.5441619157791138\n",
            "634: 0.5379878282546997\n",
            "635: 0.5457653999328613\n",
            "636: 0.5282196402549744\n",
            "637: 0.5458536148071289\n",
            "638: 0.5412988066673279\n",
            "639: 0.5322946310043335\n",
            "640: 0.530440092086792\n",
            "641: 0.5081605911254883\n",
            "642: 0.5527783632278442\n",
            "643: 0.512284517288208\n",
            "644: 0.5190088152885437\n",
            "645: 0.5030170679092407\n",
            "646: 0.4964802861213684\n",
            "647: 0.518334686756134\n",
            "648: 0.5133985280990601\n",
            "649: 0.5077844262123108\n",
            "650: 0.509968638420105\n",
            "651: 0.5220649838447571\n",
            "652: 0.5364443063735962\n",
            "653: 0.48564207553863525\n",
            "654: 0.48673316836357117\n",
            "655: 0.48799359798431396\n",
            "656: 0.4999195337295532\n",
            "657: 0.5096403956413269\n",
            "658: 0.5353740453720093\n",
            "659: 0.49952462315559387\n",
            "660: 0.4995557963848114\n",
            "661: 0.48782190680503845\n",
            "662: 0.4832061529159546\n",
            "663: 0.5007386207580566\n",
            "664: 0.48599973320961\n",
            "665: 0.4990890622138977\n",
            "666: 0.48786938190460205\n",
            "667: 0.4651024639606476\n",
            "668: 0.4969971477985382\n",
            "669: 0.47158119082450867\n",
            "670: 0.49586862325668335\n",
            "671: 0.48575517535209656\n",
            "672: 0.4855612814426422\n",
            "673: 0.4796695411205292\n",
            "674: 0.4834560453891754\n",
            "675: 0.46927765011787415\n",
            "676: 0.4963323175907135\n",
            "677: 0.44899722933769226\n",
            "678: 0.5070787072181702\n",
            "679: 0.47674721479415894\n",
            "680: 0.5524957180023193\n",
            "681: 0.5124333500862122\n",
            "682: 0.5012117028236389\n",
            "683: 0.4992920458316803\n",
            "684: 0.5076926350593567\n",
            "685: 0.4892498552799225\n",
            "686: 0.533523440361023\n",
            "687: 0.5201092958450317\n",
            "688: 0.5215809941291809\n",
            "689: 0.5039311051368713\n",
            "690: 0.45794105529785156\n",
            "691: 0.5067400932312012\n",
            "692: 0.48962846398353577\n",
            "693: 0.4794081747531891\n",
            "694: 0.48444104194641113\n",
            "695: 0.4981878995895386\n",
            "696: 0.4758646786212921\n",
            "697: 0.4735746681690216\n",
            "698: 0.5022588968276978\n",
            "699: 0.47412925958633423\n",
            "700: 0.5230857133865356\n",
            "input:   tensor([[4, 5, 2, 4, 3, 2, 5, 4]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 2, 4, 4, 5, 5, 2, 3]], device='cuda:0')\n",
            "incorrects: 6\n",
            "701: 0.4690108299255371\n",
            "702: 0.5207314491271973\n",
            "703: 0.49922293424606323\n",
            "704: 0.5272827744483948\n",
            "705: 0.5642198324203491\n",
            "706: 0.5321037769317627\n",
            "707: 0.5245819687843323\n",
            "708: 0.5309503674507141\n",
            "709: 0.609102725982666\n",
            "710: 0.49998772144317627\n",
            "711: 0.5125705599784851\n",
            "712: 0.51984703540802\n",
            "713: 0.5077192783355713\n",
            "714: 0.5123159289360046\n",
            "715: 0.5206529498100281\n",
            "716: 0.5222920775413513\n",
            "717: 0.5031166672706604\n",
            "718: 0.4657576382160187\n",
            "719: 0.5082393884658813\n",
            "720: 0.513706624507904\n",
            "721: 0.5330359935760498\n",
            "722: 0.5151532888412476\n",
            "723: 0.46886104345321655\n",
            "724: 0.5082370042800903\n",
            "725: 0.46404290199279785\n",
            "726: 0.45636412501335144\n",
            "727: 0.46794480085372925\n",
            "728: 0.4814063012599945\n",
            "729: 0.4728148281574249\n",
            "730: 0.4587176442146301\n",
            "731: 0.4685904085636139\n",
            "732: 0.46009984612464905\n",
            "733: 0.4599263668060303\n",
            "734: 0.44552215933799744\n",
            "735: 0.47546425461769104\n",
            "736: 0.4710434377193451\n",
            "737: 0.466185599565506\n",
            "738: 0.462164968252182\n",
            "739: 0.45097315311431885\n",
            "740: 0.460260808467865\n",
            "741: 0.4549756944179535\n",
            "742: 0.4312649369239807\n",
            "743: 0.4345684051513672\n",
            "744: 0.44366148114204407\n",
            "745: 0.47121644020080566\n",
            "746: 0.4554485082626343\n",
            "747: 0.4563206434249878\n",
            "748: 0.4378069341182709\n",
            "749: 0.44704777002334595\n",
            "750: 0.4485533535480499\n",
            "751: 0.4408023953437805\n",
            "752: 0.47073104977607727\n",
            "753: 0.4460103213787079\n",
            "754: 0.4581356346607208\n",
            "755: 0.4417744278907776\n",
            "756: 0.44437795877456665\n",
            "757: 0.4634987413883209\n",
            "758: 0.45168060064315796\n",
            "759: 0.5028865933418274\n",
            "760: 0.42590370774269104\n",
            "761: 0.48979294300079346\n",
            "762: 0.46387332677841187\n",
            "763: 0.458632230758667\n",
            "764: 0.5057194828987122\n",
            "765: 0.4356237053871155\n",
            "766: 0.4666415750980377\n",
            "767: 0.4538263976573944\n",
            "768: 0.46005675196647644\n",
            "769: 0.46565383672714233\n",
            "770: 0.46873703598976135\n",
            "771: 0.45896920561790466\n",
            "772: 0.4474802017211914\n",
            "773: 0.4833797216415405\n",
            "774: 0.44319862127304077\n",
            "775: 0.44555172324180603\n",
            "776: 0.44308480620384216\n",
            "777: 0.4277825951576233\n",
            "778: 0.46360689401626587\n",
            "779: 0.4373646080493927\n",
            "780: 0.43687665462493896\n",
            "781: 0.41155222058296204\n",
            "782: 0.4376404583454132\n",
            "783: 0.41371384263038635\n",
            "784: 0.4405437111854553\n",
            "785: 0.4499126970767975\n",
            "786: 0.3945116698741913\n",
            "787: 0.4281221330165863\n",
            "788: 0.41430169343948364\n",
            "789: 0.41720935702323914\n",
            "790: 0.4114287197589874\n",
            "791: 0.38673436641693115\n",
            "792: 0.4211530089378357\n",
            "793: 0.4184592664241791\n",
            "794: 0.4149544835090637\n",
            "795: 0.4484749436378479\n",
            "796: 0.41422975063323975\n",
            "797: 0.3811030089855194\n",
            "798: 0.4573453366756439\n",
            "799: 0.461932510137558\n",
            "800: 0.4858878552913666\n",
            "input:   tensor([[3, 5, 2, 5, 4, 3, 3, 2]], device='cuda:0')\n",
            "predicted output:   tensor([[5, 2, 3, 5, 3, 4, 2, 3]], device='cuda:0')\n",
            "incorrects: 7\n",
            "801: 0.46621930599212646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining:  80%|████████  | 803/1000 [00:40<00:09, 20.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "802: 0.4406333565711975\n",
            "803: 0.4151228070259094\n",
            "804: 0.4597623944282532\n",
            "805: 0.4236814081668854\n",
            "806: 0.4766072928905487\n",
            "807: 0.4499953091144562\n",
            "808: 0.4274060130119324\n",
            "809: 0.4987371861934662\n",
            "810: 0.4443860650062561\n",
            "811: 0.4724119305610657\n",
            "812: 0.4471132159233093\n",
            "813: 0.4212198257446289\n",
            "814: 0.42613548040390015\n",
            "815: 0.44065725803375244\n",
            "816: 0.46517860889434814\n",
            "817: 0.43049538135528564\n",
            "818: 0.4191420078277588\n",
            "819: 0.45147621631622314\n",
            "820: 0.4133729934692383\n",
            "821: 0.42965587973594666\n",
            "822: 0.4595978856086731\n",
            "823: 0.4216533303260803\n",
            "824: 0.46896892786026\n",
            "825: 0.4155671298503876\n",
            "826: 0.4050505459308624\n",
            "827: 0.43500420451164246\n",
            "828: 0.4535307288169861\n",
            "829: 0.4442615211009979\n",
            "830: 0.43516892194747925\n",
            "831: 0.43969064950942993\n",
            "832: 0.4111848771572113\n",
            "833: 0.43038082122802734\n",
            "834: 0.4109736680984497\n",
            "835: 0.39895129203796387\n",
            "836: 0.4246698021888733\n",
            "837: 0.4091208279132843\n",
            "838: 0.3573041558265686\n",
            "839: 0.3861424922943115\n",
            "840: 0.3991720378398895\n",
            "841: 0.40633293986320496\n",
            "842: 0.44375309348106384\n",
            "843: 0.39693260192871094\n",
            "844: 0.40511593222618103\n",
            "845: 0.41159018874168396\n",
            "846: 0.3868314027786255\n",
            "847: 0.4307376444339752\n",
            "848: 0.42106249928474426\n",
            "849: 0.4085467755794525\n",
            "850: 0.3979875147342682\n",
            "851: 0.39077433943748474\n",
            "852: 0.38467898964881897\n",
            "853: 0.39901039004325867\n",
            "854: 0.4191315174102783\n",
            "855: 0.3918965458869934\n",
            "856: 0.4237819015979767\n",
            "857: 0.3879696726799011\n",
            "858: 0.3932715356349945\n",
            "859: 0.3906579911708832\n",
            "860: 0.41038456559181213\n",
            "861: 0.4148511290550232\n",
            "862: 0.4091357886791229\n",
            "863: 0.398361474275589\n",
            "864: 0.42473092675209045\n",
            "865: 0.4128079414367676\n",
            "866: 0.38179922103881836\n",
            "867: 0.3945411145687103\n",
            "868: 0.37702876329421997\n",
            "869: 0.3876492977142334\n",
            "870: 0.37165364623069763\n",
            "871: 0.3782980740070343\n",
            "872: 0.3842464089393616\n",
            "873: 0.3846368193626404\n",
            "874: 0.37097305059432983\n",
            "875: 0.3477906584739685\n",
            "876: 0.3591427803039551\n",
            "877: 0.3825702667236328\n",
            "878: 0.3515380322933197\n",
            "879: 0.38083598017692566\n",
            "880: 0.36796149611473083\n",
            "881: 0.3437803089618683\n",
            "882: 0.3512135446071625\n",
            "883: 0.3673149645328522\n",
            "884: 0.3297977149486542\n",
            "885: 0.3540251851081848\n",
            "886: 0.36704641580581665\n",
            "887: 0.35549190640449524\n",
            "888: 0.41498953104019165\n",
            "889: 0.34582141041755676\n",
            "890: 0.3571717441082001\n",
            "891: 0.35529348254203796\n",
            "892: 0.32579949498176575\n",
            "893: 0.331342875957489\n",
            "894: 0.33950281143188477\n",
            "895: 0.3222270905971527\n",
            "896: 0.35274583101272583\n",
            "897: 0.38868993520736694\n",
            "898: 0.34222933650016785\n",
            "899: 0.3345840275287628\n",
            "900: 0.4242246448993683\n",
            "input:   tensor([[4, 3, 4, 5, 2, 4, 2, 3]], device='cuda:0')\n",
            "predicted output:   tensor([[4, 3, 4, 5, 2, 4, 3, 2]], device='cuda:0')\n",
            "incorrects: 2\n",
            "901: 0.37277427315711975\n",
            "902: 0.34808963537216187\n",
            "903: 0.3505910038948059\n",
            "904: 0.37970441579818726\n",
            "905: 0.44061198830604553\n",
            "906: 0.36029359698295593\n",
            "907: 0.363095760345459\n",
            "908: 0.41638678312301636\n",
            "909: 0.3951091170310974\n",
            "910: 0.4502706527709961\n",
            "911: 0.4363197684288025\n",
            "912: 0.3630933463573456\n",
            "913: 0.3799998462200165\n",
            "914: 0.37699320912361145\n",
            "915: 0.36793413758277893\n",
            "916: 0.36840522289276123\n",
            "917: 0.3477206826210022\n",
            "918: 0.37737753987312317\n",
            "919: 0.3629797399044037\n",
            "920: 0.34289076924324036\n",
            "921: 0.3812226355075836\n",
            "922: 0.3710188865661621\n",
            "923: 0.34757742285728455\n",
            "924: 0.41067856550216675\n",
            "925: 0.3546467125415802\n",
            "926: 0.4031204283237457\n",
            "927: 0.3343176543712616\n",
            "928: 0.37535685300827026\n",
            "929: 0.33057650923728943\n",
            "930: 0.3123563528060913\n",
            "931: 0.34635087847709656\n",
            "932: 0.2997106909751892\n",
            "933: 0.31059062480926514\n",
            "934: 0.3525005280971527\n",
            "935: 0.2861766219139099\n",
            "936: 0.32845306396484375\n",
            "937: 0.31555166840553284\n",
            "938: 0.3235345482826233\n",
            "939: 0.2753547728061676\n",
            "940: 0.29179468750953674\n",
            "941: 0.28958427906036377\n",
            "942: 0.32670676708221436\n",
            "943: 0.2916741967201233\n",
            "944: 0.3110687732696533\n",
            "945: 0.2899935245513916\n",
            "946: 0.2982631325721741\n",
            "947: 0.25538116693496704\n",
            "948: 0.27201294898986816\n",
            "949: 0.27381590008735657\n",
            "950: 0.2870347499847412\n",
            "951: 0.2532788813114166\n",
            "952: 0.27451273798942566\n",
            "953: 0.26374879479408264\n",
            "954: 0.25437402725219727\n",
            "955: 0.27994683384895325\n",
            "956: 0.3032417893409729\n",
            "957: 0.2417459338903427\n",
            "958: 0.2432926893234253\n",
            "959: 0.2800094783306122\n",
            "960: 0.24885042011737823\n",
            "961: 0.2694895565509796\n",
            "962: 0.2764378488063812\n",
            "963: 0.26022154092788696\n",
            "964: 0.2550514340400696\n",
            "965: 0.2389969378709793\n",
            "966: 0.24591906368732452\n",
            "967: 0.25670284032821655\n",
            "968: 0.24105732142925262\n",
            "969: 0.23831923305988312\n",
            "970: 0.2589503824710846\n",
            "971: 0.2615789771080017\n",
            "972: 0.22006773948669434\n",
            "973: 0.2504253387451172\n",
            "974: 0.25689855217933655\n",
            "975: 0.24655039608478546\n",
            "976: 0.24199330806732178\n",
            "977: 0.26535192131996155\n",
            "978: 0.22653481364250183\n",
            "979: 0.23548410832881927\n",
            "980: 0.22923439741134644\n",
            "981: 0.2721206843852997\n",
            "982: 0.26786646246910095\n",
            "983: 0.2339918613433838\n",
            "984: 0.2142859846353531\n",
            "985: 0.2495964914560318\n",
            "986: 0.22903373837471008\n",
            "987: 0.23627759516239166\n",
            "988: 0.21937055885791779\n",
            "989: 0.2157992422580719\n",
            "990: 0.2592354118824005\n",
            "991: 0.20859326422214508\n",
            "992: 0.22134733200073242\n",
            "993: 0.2270509898662567\n",
            "994: 0.20696917176246643\n",
            "995: 0.22441703081130981\n",
            "996: 0.24513235688209534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtraining: 100%|██████████| 1000/1000 [00:50<00:00, 19.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "997: 0.22514668107032776\n",
            "998: 0.20265790820121765\n",
            "999: 0.22559469938278198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy : {(len(src) - incorrects)/len(src)*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EiX_vLyQecS",
        "outputId": "e1aea3dc-7576-43e9-cd26-0cceadd9e57b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 93.75%\n"
          ]
        }
      ]
    }
  ]
}